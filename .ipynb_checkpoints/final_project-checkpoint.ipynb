{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#activity labels as defined in activity_labels.txt\n",
    "activity_labels = ['WALKING', 'WALKING_UPSTAIRS', 'WALKING_DOWNSTAIRS', 'SITTING', 'STANDING', 'LAYING', 'STAND_TO_SIT', 'SIT_TO_STAND', 'SIT_TO_LIE', 'LIE_TO_SIT', 'STAND_TO_LIE', 'LIE_TO_STAND']\n",
    "#activity_labels = {k:v for k,v in enumerate(activity_labels, start=1)}\n",
    "#print(activity_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshaping data...\n",
      "adjusting labels...\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "def load_data(path):\n",
    "    data = pd.read_csv(path, header=None, delim_whitespace=True)\n",
    "    return data.values\n",
    "\n",
    "def load_set(path, x, y):\n",
    "    data = load_data(path+x)\n",
    "    labels = load_data(path+y)\n",
    "    return data, labels\n",
    "\n",
    "#reduce the labels by 1 to match with the activity_labels and also to start labels at 0 to 11 instead of from 1 to 12\n",
    "def adjust_labels (labels):\n",
    "    for i in range(len(labels)-1):\n",
    "        labels[i][0] -= 1\n",
    "    return labels\n",
    "\n",
    "train_data, train_labels = load_set('HAPT Data Set/Train/', 'X_train.txt', 'y_train.txt')\n",
    "test_data, test_labels = load_set('HAPT Data Set/Test/', 'X_test.txt', 'y_test.txt')\n",
    "\n",
    "print('reshaping data...')\n",
    "#reshape the data to add a features dimension (features = 1)\n",
    "#https://stackoverflow.com/questions/43396572/dimension-of-shape-in-conv1d\n",
    "train_data = np.expand_dims(train_data, axis=2)\n",
    "test_data = np.expand_dims(test_data, axis=2)\n",
    "\n",
    "print('adjusting labels...')\n",
    "train_labels = adjust_labels(train_labels);\n",
    "test_labels = adjust_labels(test_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get time of epochs to record training time\n",
    "#https://stackoverflow.com/questions/43178668/record-the-computation-time-for-each-epoch-in-keras-during-model-fit\n",
    "class TimeHistory(callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out n number (pred_range) of predicted values and compare them with test labels\n",
    "def predict(pred_range, pred_outs, test_labels):\n",
    "    #test if the label matches the prediction\n",
    "    false_pred = 0\n",
    "    true_pred = 0\n",
    "    #look at predictions for the first 25 values\n",
    "    for i in range(pred_range):\n",
    "        if not (0 <= pred_outs[i] or pred_outs[i] <= 11):\n",
    "            print('prediction out of bounds')\n",
    "            break\n",
    "\n",
    "        print(f'Test label: {activity_labels[test_labels[i][0]]}')\n",
    "        print(f'Predicted label:{activity_labels[pred_outs[i]]}')\n",
    "\n",
    "        if pred_outs[i]==test_labels[i][0]:\n",
    "            print('true\\n')\n",
    "            true_pred += 1\n",
    "        else:\n",
    "            print('false\\n')\n",
    "            false_pred += 1\n",
    "    print(f'False predictions:{false_pred}')\n",
    "    print(f'True predictions:{true_pred}')\n",
    "    print(f'Prediction accuraccy for first 25 values: {true_pred/pred_range}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(test_data, test_labels, train_data, train_labels, filters, kernel_size, dropout, epochs, it='', predict=True):\n",
    "    save_path = f'filters-{filters}_kernel_size-{kernel_size}_dropout-{dropout}_epochs-{epochs}_it-{it}'\n",
    "    saved_model_path = f'saved_models\\\\{save_path}'\n",
    "    checkpoint_path = f'checkpoints\\\\{save_path}.ckpt'\n",
    "    training_time=-1\n",
    "    \n",
    "    current_directory = os.path.abspath(os.getcwd())\n",
    "    \n",
    "    if os.path.exists(os.path.join(current_directory,saved_model_path)) :\n",
    "        print(f'found saved model, loading from: {saved_model_path}')\n",
    "        model = models.load_model(saved_model_path)\n",
    "        test_loss,test_acc = model.evaluate( test_data, test_labels, verbose=2)\n",
    "    elif os.path.exists(os.path.join(current_directory,checkpoint_path+'.index')) :\n",
    "        print(f'found checkpoint for model, loading from :{checkpoint_path}')\n",
    "        model.load_weights(checkpoint_path)\n",
    "        test_loss,test_acc = model.evaluate( test_data, test_labels, verbose=2)\n",
    "    else:\n",
    "        #input shape\n",
    "        timesteps = train_data.shape[1] #561 timesteps\n",
    "        features = train_data.shape[2] #1 feature\n",
    "\n",
    "        #model\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Conv1D(filters=filters, kernel_size=kernel_size, strides=1, activation='relu', input_shape=(timesteps,features)))\n",
    "        model.add(layers.MaxPooling1D(pool_size=2))\n",
    "        model.add(layers.Conv1D(filters=filters, kernel_size=kernel_size, strides=1, activation='relu'))\n",
    "        model.add(layers.MaxPooling1D(pool_size=2))\n",
    "        model.add(layers.Dropout(dropout))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(64, activation='relu'))\n",
    "        model.add(layers.Dense(32, activation='relu'))\n",
    "        model.add(layers.Dense(12, activation='relu'))\n",
    "        model.summary()\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(optimizer='adam',\n",
    "                 loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                 metrics=['accuracy'])\n",
    "        #evaluate model\n",
    "        test_loss,test_acc = model.evaluate(test_data, test_labels, verbose=2)\n",
    "\n",
    "        if predict:\n",
    "            #predict\n",
    "            pred_outs = model.predict_classes(test_data)\n",
    "            #display predictions\n",
    "            predict(10, pred_outs, test_labels)\n",
    "\n",
    "        #train the model\n",
    "        #set up timing callback\n",
    "        time_callback = TimeHistory()\n",
    "        #setup checkpoint callback\n",
    "        cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                        save_weights_only=True,\n",
    "                                                        verbose=1)\n",
    "\n",
    "        model.fit(train_data, \n",
    "                  train_labels, \n",
    "                  epochs=epochs, \n",
    "                  validation_data=(test_data, test_labels),\n",
    "                callbacks=[time_callback, cp_callback])\n",
    "\n",
    "        test_loss,test_acc = model.evaluate( test_data, test_labels, verbose=2)\n",
    "\n",
    "        training_time = sum(time_callback.times)\n",
    "\n",
    "        model.save(saved_model_path)\n",
    "    \n",
    "    return test_loss, test_acc, training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_unit_string(time):\n",
    "    return f\"Total training time: {math.floor(time/1)}s {math.floor(time%1 * 1000)}ms {math.ceil(time%(1/1000)*1000)}us\"\n",
    "\n",
    "class RunTests: \n",
    "    n_tests = 10\n",
    "    d_epochs = 10\n",
    "    d_filters = 64\n",
    "    d_kernel_size=3\n",
    "    d_dropout=0.5\n",
    "    \n",
    "    def test_param(self, filters=d_filters, kernel_size=d_kernel_size, dropout=d_dropout, epochs=d_epochs):\n",
    "        if isinstance(filters,list):\n",
    "            data = filters\n",
    "            data_type = 'filters'\n",
    "        elif isinstance(kernel_size,list):\n",
    "            data = kernel_size\n",
    "            data_type = 'kernel_size'\n",
    "        elif isinstance(dropout,list):\n",
    "            data = dropout\n",
    "            data_type = 'dropout'\n",
    "        elif isinstance(epochs,list):\n",
    "            data = epochs\n",
    "            data_type = 'epochs'\n",
    "        else:\n",
    "            print('no data type selected, running default...')\n",
    "            data = [1]\n",
    "            data_type = 'default'\n",
    "        \n",
    "        model_test_data = []\n",
    "        for index, item in enumerate(data):\n",
    "            model_test_data.append([])\n",
    "            for i in range(0,self.n_tests):\n",
    "                if data_type == 'filters':\n",
    "                    loss, acc, time = run_model(test_data, test_labels, train_data, train_labels, predict=False,\n",
    "                                                kernel_size=kernel_size, \n",
    "                                                filters=item, \n",
    "                                                dropout=dropout,\n",
    "                                                epochs=epochs,\n",
    "                                                it=i)\n",
    "                elif data_type == 'kernel_size':\n",
    "                    loss, acc, time = run_model(test_data, test_labels, train_data, train_labels, predict=False,\n",
    "                                                kernel_size=item, \n",
    "                                                filters=filters, \n",
    "                                                dropout=dropout,  \n",
    "                                                epochs=epochs,\n",
    "                                                it=i)\n",
    "                elif data_type == 'dropout':\n",
    "                    loss, acc, time = run_model(test_data, test_labels, train_data, train_labels, predict=False,\n",
    "                                                kernel_size=kernel_size, \n",
    "                                                filters=filters, \n",
    "                                                dropout=item,  \n",
    "                                                epochs=epochs,\n",
    "                                                it=i)\n",
    "                elif data_type == 'epochs':\n",
    "                    loss, acc, time = run_model(test_data, test_labels, train_data, train_labels, predict=False,\n",
    "                                                kernel_size=kernel_size, \n",
    "                                                filters=filters, \n",
    "                                                dropout=dropout,  \n",
    "                                                epochs=item,\n",
    "                                                it=i)\n",
    "                else:\n",
    "                    loss, acc, time = run_model(test_data, test_labels, train_data, train_labels, predict=False,\n",
    "                                                kernel_size=kernel_size, \n",
    "                                                filters=filters, \n",
    "                                                dropout=dropout,  \n",
    "                                                epochs=epochs,\n",
    "                                                it=i)\n",
    "                test_output = {'loss': loss, 'acc': acc, 'time': time, 'test parameter': item}\n",
    "                model_test_data[index].append(test_output)\n",
    "        return model_test_data\n",
    "\n",
    "    #data is a two-dimensional list\n",
    "    def print_results(self,data, data_name):\n",
    "        print(f\"{data_name} test data:\")\n",
    "        for test in data:\n",
    "            for i in range(0,self.n_tests):\n",
    "                print(f\"{data_name}: {test[i].get('test parameter')}\")\n",
    "                print(f\"\\tloss: {test[i].get('loss')}\")\n",
    "                print(f\"\\taccuracy: {test[i].get('acc')}\")\n",
    "            print(\"\\n\")\n",
    "    \n",
    "    def plot_results(self, data, data_name):\n",
    "        loss=[]\n",
    "        acc=[]\n",
    "        param=[]\n",
    "        for index, test in enumerate(data):\n",
    "            param.append(test[0].get('test parameter'))\n",
    "            loss.append([])\n",
    "            acc.append([])\n",
    "            for i in range(0,self.n_tests):\n",
    "                loss[index].append(test[i].get('loss'))\n",
    "                acc[index].append(test[i].get('acc'))\n",
    "        \n",
    "        fig, axs = plt.subplots(2)\n",
    "        axs[0].set_title(f'{data_name} loss')\n",
    "        axs[0].set(xlabel=data_name, ylabel='Loss')\n",
    "        axs[0].boxplot(loss)\n",
    "        axs[0].set_xticklabels(param)\n",
    "        \n",
    "        axs[1].set_title(f'{data_name} accuracy')\n",
    "        axs[1].set(xlabel=data_name, ylabel='Accuracy')\n",
    "        axs[1].boxplot(acc)\n",
    "        axs[1].set_xticklabels(param)\n",
    "        \n",
    "        fig.subplots_adjust(hspace=0.8)\n",
    "        \n",
    "        plt.show\n",
    "        \n",
    "runner = RunTests() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 559, 32)           128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 279, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 277, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 138, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 138, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4416)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                282688    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 288,396\n",
      "Trainable params: 288,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 3s - loss: 2.4945 - accuracy: 0.0054\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 0.8601 - accuracy: 0.6893\n",
      "Epoch 00001: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-0.ckpt\n",
      "7767/7767 [==============================] - 3s 329us/sample - loss: 0.8520 - accuracy: 0.6916 - val_loss: 0.4370 - val_accuracy: 0.8469\n",
      "Epoch 2/10\n",
      "7520/7767 [============================>.] - ETA: 0s - loss: 0.3372 - accuracy: 0.8777\n",
      "Epoch 00002: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-0.ckpt\n",
      "7767/7767 [==============================] - 2s 250us/sample - loss: 0.3369 - accuracy: 0.8776 - val_loss: 0.2897 - val_accuracy: 0.9004\n",
      "Epoch 3/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 0.2502 - accuracy: 0.9082\n",
      "Epoch 00003: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-0.ckpt\n",
      "7767/7767 [==============================] - 2s 251us/sample - loss: 0.2488 - accuracy: 0.9088 - val_loss: 0.2799 - val_accuracy: 0.8858\n",
      "Epoch 4/10\n",
      "7584/7767 [============================>.] - ETA: 0s - loss: 0.2112 - accuracy: 0.9275\n",
      "Epoch 00004: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-0.ckpt\n",
      "7767/7767 [==============================] - 2s 251us/sample - loss: 0.2118 - accuracy: 0.9271 - val_loss: 0.2478 - val_accuracy: 0.9118\n",
      "Epoch 5/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.1971 - accuracy: 0.9319\n",
      "Epoch 00005: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-0.ckpt\n",
      "7767/7767 [==============================] - 2s 251us/sample - loss: 0.1981 - accuracy: 0.9312 - val_loss: 0.2491 - val_accuracy: 0.9070\n",
      "Epoch 6/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.1873 - accuracy: 0.9349\n",
      "Epoch 00006: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-0.ckpt\n",
      "7767/7767 [==============================] - 2s 250us/sample - loss: 0.1868 - accuracy: 0.9350 - val_loss: 0.2593 - val_accuracy: 0.9089\n",
      "Epoch 7/10\n",
      "7584/7767 [============================>.] - ETA: 0s - loss: 0.1678 - accuracy: 0.9403\n",
      "Epoch 00007: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-0.ckpt\n",
      "7767/7767 [==============================] - 2s 256us/sample - loss: 0.1675 - accuracy: 0.9404 - val_loss: 0.2195 - val_accuracy: 0.9250\n",
      "Epoch 8/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.1520 - accuracy: 0.9482\n",
      "Epoch 00008: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-0.ckpt\n",
      "7767/7767 [==============================] - 2s 272us/sample - loss: 0.1520 - accuracy: 0.9481 - val_loss: 0.2117 - val_accuracy: 0.9241\n",
      "Epoch 9/10\n",
      "7488/7767 [===========================>..] - ETA: 0s - loss: 0.1458 - accuracy: 0.9515\n",
      "Epoch 00009: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-0.ckpt\n",
      "7767/7767 [==============================] - 2s 283us/sample - loss: 0.1456 - accuracy: 0.9516 - val_loss: 0.2638 - val_accuracy: 0.9067\n",
      "Epoch 10/10\n",
      "7488/7767 [===========================>..] - ETA: 0s - loss: 0.1451 - accuracy: 0.9481\n",
      "Epoch 00010: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-0.ckpt\n",
      "7767/7767 [==============================] - 2s 255us/sample - loss: 0.1433 - accuracy: 0.9488 - val_loss: 0.2155 - val_accuracy: 0.9244\n",
      "3162/3162 - 0s - loss: 0.2155 - accuracy: 0.9244\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B372B14C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B372B14C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From C:\\Users\\enoch\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-0\\assets\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 559, 32)           128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 279, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 277, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 138, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 138, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4416)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                282688    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 288,396\n",
      "Trainable params: 288,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4820 - accuracy: 0.1278\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 0.8811 - accuracy: 0.6904\n",
      "Epoch 00001: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-1.ckpt\n",
      "7767/7767 [==============================] - 3s 323us/sample - loss: 0.8707 - accuracy: 0.6941 - val_loss: 0.4323 - val_accuracy: 0.8226\n",
      "Epoch 2/10\n",
      "7520/7767 [============================>.] - ETA: 0s - loss: 0.3506 - accuracy: 0.8739\n",
      "Epoch 00002: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-1.ckpt\n",
      "7767/7767 [==============================] - 2s 267us/sample - loss: 0.3507 - accuracy: 0.8733 - val_loss: 0.3475 - val_accuracy: 0.8719\n",
      "Epoch 3/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.2819 - accuracy: 0.8971\n",
      "Epoch 00003: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-1.ckpt\n",
      "7767/7767 [==============================] - 2s 251us/sample - loss: 0.2815 - accuracy: 0.8971 - val_loss: 0.3006 - val_accuracy: 0.8893\n",
      "Epoch 4/10\n",
      "7552/7767 [============================>.] - ETA: 0s - loss: 0.2464 - accuracy: 0.9142\n",
      "Epoch 00004: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-1.ckpt\n",
      "7767/7767 [==============================] - 2s 270us/sample - loss: 0.2465 - accuracy: 0.9139 - val_loss: 0.2659 - val_accuracy: 0.9083\n",
      "Epoch 5/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.2219 - accuracy: 0.9188\n",
      "Epoch 00005: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-1.ckpt\n",
      "7767/7767 [==============================] - 2s 263us/sample - loss: 0.2217 - accuracy: 0.9186 - val_loss: 0.3007 - val_accuracy: 0.8928\n",
      "Epoch 6/10\n",
      "7584/7767 [============================>.] - ETA: 0s - loss: 0.2070 - accuracy: 0.9241\n",
      "Epoch 00006: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-1.ckpt\n",
      "7767/7767 [==============================] - 2s 249us/sample - loss: 0.2058 - accuracy: 0.9246 - val_loss: 0.2566 - val_accuracy: 0.9058\n",
      "Epoch 7/10\n",
      "7552/7767 [============================>.] - ETA: 0s - loss: 0.1950 - accuracy: 0.9280\n",
      "Epoch 00007: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-1.ckpt\n",
      "7767/7767 [==============================] - 2s 261us/sample - loss: 0.1938 - accuracy: 0.9285 - val_loss: 0.2927 - val_accuracy: 0.9001\n",
      "Epoch 8/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.1795 - accuracy: 0.9370\n",
      "Epoch 00008: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-1.ckpt\n",
      "7767/7767 [==============================] - 2s 264us/sample - loss: 0.1788 - accuracy: 0.9374 - val_loss: 0.2582 - val_accuracy: 0.9130\n",
      "Epoch 9/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.1738 - accuracy: 0.9378\n",
      "Epoch 00009: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-1.ckpt\n",
      "7767/7767 [==============================] - 2s 269us/sample - loss: 0.1731 - accuracy: 0.9379 - val_loss: 0.2826 - val_accuracy: 0.9016\n",
      "Epoch 10/10\n",
      "7520/7767 [============================>.] - ETA: 0s - loss: 0.1714 - accuracy: 0.9371\n",
      "Epoch 00010: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-1.ckpt\n",
      "7767/7767 [==============================] - 2s 251us/sample - loss: 0.1684 - accuracy: 0.9383 - val_loss: 0.3336 - val_accuracy: 0.8861\n",
      "3162/3162 - 0s - loss: 0.3336 - accuracy: 0.8861\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B3410D0D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B3410D0D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-1\\assets\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_4 (Conv1D)            (None, 559, 32)           128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 279, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 277, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 138, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 138, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4416)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                282688    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 288,396\n",
      "Trainable params: 288,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 0s - loss: 2.4955 - accuracy: 0.0085\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 1.3405 - accuracy: 0.5079\n",
      "Epoch 00001: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 2s 315us/sample - loss: 1.3396 - accuracy: 0.5082 - val_loss: 1.0608 - val_accuracy: 0.5882\n",
      "Epoch 2/10\n",
      "7584/7767 [============================>.] - ETA: 0s - loss: 1.0687 - accuracy: 0.5832\n",
      "Epoch 00002: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 2s 262us/sample - loss: 1.0662 - accuracy: 0.5840 - val_loss: 1.0434 - val_accuracy: 0.5844\n",
      "Epoch 3/10\n",
      "7584/7767 [============================>.] - ETA: 0s - loss: 1.0320 - accuracy: 0.5912\n",
      "Epoch 00003: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 2s 254us/sample - loss: 1.0339 - accuracy: 0.5908 - val_loss: 1.1250 - val_accuracy: 0.5490\n",
      "Epoch 4/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 1.0259 - accuracy: 0.5945\n",
      "Epoch 00004: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 2s 248us/sample - loss: 1.0254 - accuracy: 0.5947 - val_loss: 1.0396 - val_accuracy: 0.5889\n",
      "Epoch 5/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 1.0148 - accuracy: 0.5966\n",
      "Epoch 00005: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 2s 255us/sample - loss: 1.0153 - accuracy: 0.5965 - val_loss: 1.0556 - val_accuracy: 0.5832\n",
      "Epoch 6/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 1.0136 - accuracy: 0.5968\n",
      "Epoch 00006: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 2s 251us/sample - loss: 1.0129 - accuracy: 0.5971 - val_loss: 1.0285 - val_accuracy: 0.5901\n",
      "Epoch 7/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 1.0069 - accuracy: 0.5979\n",
      "Epoch 00007: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 2s 259us/sample - loss: 1.0055 - accuracy: 0.5984 - val_loss: 1.0310 - val_accuracy: 0.5882\n",
      "Epoch 8/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 1.0020 - accuracy: 0.5993\n",
      "Epoch 00008: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 2s 262us/sample - loss: 1.0019 - accuracy: 0.5993 - val_loss: 1.0341 - val_accuracy: 0.5860\n",
      "Epoch 9/10\n",
      "7584/7767 [============================>.] - ETA: 0s - loss: 1.0017 - accuracy: 0.5993\n",
      "Epoch 00009: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 2s 263us/sample - loss: 1.0022 - accuracy: 0.5992 - val_loss: 1.0102 - val_accuracy: 0.5968\n",
      "Epoch 10/10\n",
      "7488/7767 [===========================>..] - ETA: 0s - loss: 1.0013 - accuracy: 0.5995\n",
      "Epoch 00010: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 2s 253us/sample - loss: 1.0027 - accuracy: 0.5989 - val_loss: 1.0572 - val_accuracy: 0.5765\n",
      "3162/3162 - 0s - loss: 1.0572 - accuracy: 0.5765\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B4D3C80D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B4D3C80D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-2\\assets\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 559, 32)           128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 279, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 277, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 138, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 138, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 4416)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                282688    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 288,396\n",
      "Trainable params: 288,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 0s - loss: 2.4922 - accuracy: 0.0702\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7552/7767 [============================>.] - ETA: 0s - loss: 1.3828 - accuracy: 0.5708\n",
      "Epoch 00001: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-3.ckpt\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 1.3721 - accuracy: 0.5746 - val_loss: 0.8570 - val_accuracy: 0.7397\n",
      "Epoch 2/10\n",
      "7584/7767 [============================>.] - ETA: 0s - loss: 0.8201 - accuracy: 0.7366\n",
      "Epoch 00002: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-3.ckpt\n",
      "7767/7767 [==============================] - 2s 266us/sample - loss: 0.8227 - accuracy: 0.7353 - val_loss: 0.7947 - val_accuracy: 0.7419\n",
      "Epoch 3/10\n",
      "7488/7767 [===========================>..] - ETA: 0s - loss: 0.7399 - accuracy: 0.7521\n",
      "Epoch 00003: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-3.ckpt\n",
      "7767/7767 [==============================] - 2s 261us/sample - loss: 0.7382 - accuracy: 0.7529 - val_loss: 0.7672 - val_accuracy: 0.7283\n",
      "Epoch 4/10\n",
      "7488/7767 [===========================>..] - ETA: 0s - loss: 0.7158 - accuracy: 0.7543\n",
      "Epoch 00004: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-3.ckpt\n",
      "7767/7767 [==============================] - 2s 255us/sample - loss: 0.7136 - accuracy: 0.7550 - val_loss: 0.7267 - val_accuracy: 0.7448\n",
      "Epoch 5/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.6818 - accuracy: 0.7572\n",
      "Epoch 00005: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-3.ckpt\n",
      "7767/7767 [==============================] - 2s 287us/sample - loss: 0.6829 - accuracy: 0.7565 - val_loss: 0.7285 - val_accuracy: 0.7407\n",
      "Epoch 6/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 0.6783 - accuracy: 0.7580\n",
      "Epoch 00006: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-3.ckpt\n",
      "7767/7767 [==============================] - 2s 287us/sample - loss: 0.6778 - accuracy: 0.7582 - val_loss: 0.7453 - val_accuracy: 0.7372\n",
      "Epoch 7/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.6616 - accuracy: 0.7616\n",
      "Epoch 00007: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-3.ckpt\n",
      "7767/7767 [==============================] - 2s 272us/sample - loss: 0.6624 - accuracy: 0.7612 - val_loss: 0.7044 - val_accuracy: 0.7426\n",
      "Epoch 8/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.6507 - accuracy: 0.7633\n",
      "Epoch 00008: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-3.ckpt\n",
      "7767/7767 [==============================] - 2s 251us/sample - loss: 0.6490 - accuracy: 0.7639 - val_loss: 0.7324 - val_accuracy: 0.7381\n",
      "Epoch 9/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 0.6491 - accuracy: 0.7625\n",
      "Epoch 00009: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-3.ckpt\n",
      "7767/7767 [==============================] - 2s 255us/sample - loss: 0.6500 - accuracy: 0.7622 - val_loss: 0.7013 - val_accuracy: 0.7404\n",
      "Epoch 10/10\n",
      "7552/7767 [============================>.] - ETA: 0s - loss: 0.6393 - accuracy: 0.7648\n",
      "Epoch 00010: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-3.ckpt\n",
      "7767/7767 [==============================] - 2s 257us/sample - loss: 0.6405 - accuracy: 0.7643 - val_loss: 0.6840 - val_accuracy: 0.7495\n",
      "3162/3162 - 0s - loss: 0.6840 - accuracy: 0.7495\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B9E8A3C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B9E8A3C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-3\\assets\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_8 (Conv1D)            (None, 559, 32)           128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 279, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 277, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 138, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 138, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 4416)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                282688    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 288,396\n",
      "Trainable params: 288,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 0s - loss: 2.4784 - accuracy: 0.1569\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 1.4428 - accuracy: 0.4957\n",
      "Epoch 00001: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-4.ckpt\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 1.4382 - accuracy: 0.4972 - val_loss: 1.1943 - val_accuracy: 0.5291\n",
      "Epoch 2/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 1.0834 - accuracy: 0.5864\n",
      "Epoch 00002: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-4.ckpt\n",
      "7767/7767 [==============================] - 2s 264us/sample - loss: 1.0827 - accuracy: 0.5866 - val_loss: 1.0739 - val_accuracy: 0.5848\n",
      "Epoch 3/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 1.0272 - accuracy: 0.6040\n",
      "Epoch 00003: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-4.ckpt\n",
      "7767/7767 [==============================] - 2s 279us/sample - loss: 1.0287 - accuracy: 0.6035 - val_loss: 1.0702 - val_accuracy: 0.6110\n",
      "Epoch 4/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.9915 - accuracy: 0.6166\n",
      "Epoch 00004: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-4.ckpt\n",
      "7767/7767 [==============================] - 2s 287us/sample - loss: 0.9921 - accuracy: 0.6163 - val_loss: 1.0187 - val_accuracy: 0.6132\n",
      "Epoch 5/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.9793 - accuracy: 0.6181\n",
      "Epoch 00005: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-4.ckpt\n",
      "7767/7767 [==============================] - 2s 275us/sample - loss: 0.9814 - accuracy: 0.6171 - val_loss: 1.0186 - val_accuracy: 0.6104\n",
      "Epoch 6/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 0.9638 - accuracy: 0.6218\n",
      "Epoch 00006: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-4.ckpt\n",
      "7767/7767 [==============================] - 2s 273us/sample - loss: 0.9636 - accuracy: 0.6220 - val_loss: 1.0062 - val_accuracy: 0.6161\n",
      "Epoch 7/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.9525 - accuracy: 0.6276\n",
      "Epoch 00007: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-4.ckpt\n",
      "7767/7767 [==============================] - 2s 291us/sample - loss: 0.9509 - accuracy: 0.6284 - val_loss: 1.0219 - val_accuracy: 0.6199\n",
      "Epoch 8/10\n",
      "7584/7767 [============================>.] - ETA: 0s - loss: 0.9551 - accuracy: 0.6250\n",
      "Epoch 00008: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-4.ckpt\n",
      "7767/7767 [==============================] - 2s 292us/sample - loss: 0.9528 - accuracy: 0.6259 - val_loss: 1.0273 - val_accuracy: 0.6208\n",
      "Epoch 9/10\n",
      "7520/7767 [============================>.] - ETA: 0s - loss: 0.9495 - accuracy: 0.6269\n",
      "Epoch 00009: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-4.ckpt\n",
      "7767/7767 [==============================] - 2s 275us/sample - loss: 0.9502 - accuracy: 0.6266 - val_loss: 1.0381 - val_accuracy: 0.6050\n",
      "Epoch 10/10\n",
      "7552/7767 [============================>.] - ETA: 0s - loss: 0.9415 - accuracy: 0.6298\n",
      "Epoch 00010: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-4.ckpt\n",
      "7767/7767 [==============================] - 2s 263us/sample - loss: 0.9415 - accuracy: 0.6298 - val_loss: 1.0180 - val_accuracy: 0.6078\n",
      "3162/3162 - 0s - loss: 1.0180 - accuracy: 0.6078\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B343A5CA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B343A5CA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-4\\assets\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 559, 32)           128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 279, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 277, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 138, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 138, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 4416)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 64)                282688    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 288,396\n",
      "Trainable params: 288,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 0s - loss: 2.4866 - accuracy: 0.1265\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7520/7767 [============================>.] - ETA: 0s - loss: 1.1099 - accuracy: 0.6707\n",
      "Epoch 00001: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-5.ckpt\n",
      "7767/7767 [==============================] - 3s 375us/sample - loss: 1.0988 - accuracy: 0.6736 - val_loss: 0.7620 - val_accuracy: 0.7745\n",
      "Epoch 2/10\n",
      "7552/7767 [============================>.] - ETA: 0s - loss: 0.7174 - accuracy: 0.7778\n",
      "Epoch 00002: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-5.ckpt\n",
      "7767/7767 [==============================] - 2s 303us/sample - loss: 0.7170 - accuracy: 0.7778 - val_loss: 0.6675 - val_accuracy: 0.7834\n",
      "Epoch 3/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.6435 - accuracy: 0.7921\n",
      "Epoch 00003: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-5.ckpt\n",
      "7767/7767 [==============================] - 2s 315us/sample - loss: 0.6448 - accuracy: 0.7917 - val_loss: 0.6912 - val_accuracy: 0.7694\n",
      "Epoch 4/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 0.6256 - accuracy: 0.7917\n",
      "Epoch 00004: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-5.ckpt\n",
      "7767/7767 [==============================] - 2s 304us/sample - loss: 0.6262 - accuracy: 0.7914 - val_loss: 0.6288 - val_accuracy: 0.7881\n",
      "Epoch 5/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 0.5979 - accuracy: 0.7954\n",
      "Epoch 00005: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-5.ckpt\n",
      "7767/7767 [==============================] - 3s 353us/sample - loss: 0.6004 - accuracy: 0.7952 - val_loss: 0.6097 - val_accuracy: 0.7884\n",
      "Epoch 6/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 0.5917 - accuracy: 0.7958\n",
      "Epoch 00006: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-5.ckpt\n",
      "7767/7767 [==============================] - 2s 296us/sample - loss: 0.5920 - accuracy: 0.7957 - val_loss: 0.6194 - val_accuracy: 0.7853\n",
      "Epoch 7/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.5819 - accuracy: 0.7977\n",
      "Epoch 00007: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-5.ckpt\n",
      "7767/7767 [==============================] - 2s 272us/sample - loss: 0.5793 - accuracy: 0.7985 - val_loss: 0.6297 - val_accuracy: 0.7900\n",
      "Epoch 8/10\n",
      "7520/7767 [============================>.] - ETA: 0s - loss: 0.5765 - accuracy: 0.7969\n",
      "Epoch 00008: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-5.ckpt\n",
      "7767/7767 [==============================] - 2s 254us/sample - loss: 0.5781 - accuracy: 0.7962 - val_loss: 0.6683 - val_accuracy: 0.7729\n",
      "Epoch 9/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 0.5642 - accuracy: 0.8002\n",
      "Epoch 00009: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-5.ckpt\n",
      "7767/7767 [==============================] - 2s 266us/sample - loss: 0.5650 - accuracy: 0.7997 - val_loss: 0.6111 - val_accuracy: 0.7859\n",
      "Epoch 10/10\n",
      "7552/7767 [============================>.] - ETA: 0s - loss: 0.5596 - accuracy: 0.8008\n",
      "Epoch 00010: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-5.ckpt\n",
      "7767/7767 [==============================] - 2s 264us/sample - loss: 0.5622 - accuracy: 0.8003 - val_loss: 0.6288 - val_accuracy: 0.7846\n",
      "3162/3162 - 0s - loss: 0.6288 - accuracy: 0.7846\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B372DEE58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B372DEE58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-5\\assets\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_12 (Conv1D)           (None, 559, 32)           128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 279, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 277, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 138, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 138, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 4416)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 64)                282688    \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 288,396\n",
      "Trainable params: 288,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 0s - loss: 2.4780 - accuracy: 0.1224\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7520/7767 [============================>.] - ETA: 0s - loss: 1.1250 - accuracy: 0.6144\n",
      "Epoch 00001: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-6.ckpt\n",
      "7767/7767 [==============================] - 2s 316us/sample - loss: 1.1178 - accuracy: 0.6174 - val_loss: 0.8071 - val_accuracy: 0.7552\n",
      "Epoch 2/10\n",
      "7552/7767 [============================>.] - ETA: 0s - loss: 0.7261 - accuracy: 0.8150\n",
      "Epoch 00002: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-6.ckpt\n",
      "7767/7767 [==============================] - 2s 248us/sample - loss: 0.7259 - accuracy: 0.8165 - val_loss: 0.7839 - val_accuracy: 0.7919\n",
      "Epoch 3/10\n",
      "7520/7767 [============================>.] - ETA: 0s - loss: 0.6577 - accuracy: 0.8705\n",
      "Epoch 00003: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-6.ckpt\n",
      "7767/7767 [==============================] - 2s 250us/sample - loss: 0.6565 - accuracy: 0.8703 - val_loss: 0.7086 - val_accuracy: 0.8735\n",
      "Epoch 4/10\n",
      "7488/7767 [===========================>..] - ETA: 0s - loss: 0.6270 - accuracy: 0.8925\n",
      "Epoch 00004: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-6.ckpt\n",
      "7767/7767 [==============================] - 2s 251us/sample - loss: 0.6278 - accuracy: 0.8917 - val_loss: 0.6803 - val_accuracy: 0.8533\n",
      "Epoch 5/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 0.6148 - accuracy: 0.9001\n",
      "Epoch 00005: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-6.ckpt\n",
      "7767/7767 [==============================] - 2s 270us/sample - loss: 0.6154 - accuracy: 0.9001 - val_loss: 0.6599 - val_accuracy: 0.8776\n",
      "Epoch 6/10\n",
      "7584/7767 [============================>.] - ETA: 0s - loss: 0.6039 - accuracy: 0.9066\n",
      "Epoch 00006: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-6.ckpt\n",
      "7767/7767 [==============================] - 2s 246us/sample - loss: 0.6019 - accuracy: 0.9068 - val_loss: 0.6828 - val_accuracy: 0.8779\n",
      "Epoch 7/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 0.6023 - accuracy: 0.9084\n",
      "Epoch 00007: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-6.ckpt\n",
      "7767/7767 [==============================] - 2s 248us/sample - loss: 0.5984 - accuracy: 0.9087 - val_loss: 0.7773 - val_accuracy: 0.8681\n",
      "Epoch 8/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.5939 - accuracy: 0.9106\n",
      "Epoch 00008: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-6.ckpt\n",
      "7767/7767 [==============================] - 2s 256us/sample - loss: 0.5911 - accuracy: 0.9110 - val_loss: 0.6737 - val_accuracy: 0.9023\n",
      "Epoch 9/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 0.5847 - accuracy: 0.9182\n",
      "Epoch 00009: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-6.ckpt\n",
      "7767/7767 [==============================] - 2s 252us/sample - loss: 0.5847 - accuracy: 0.9186 - val_loss: 0.6934 - val_accuracy: 0.8975\n",
      "Epoch 10/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.5762 - accuracy: 0.9200\n",
      "Epoch 00010: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-6.ckpt\n",
      "7767/7767 [==============================] - 2s 256us/sample - loss: 0.5759 - accuracy: 0.9197 - val_loss: 0.6670 - val_accuracy: 0.8893\n",
      "3162/3162 - 0s - loss: 0.6670 - accuracy: 0.8893\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B36A1DEE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B36A1DEE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-6\\assets\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_14 (Conv1D)           (None, 559, 32)           128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 279, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 277, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 138, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 138, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 4416)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 64)                282688    \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 288,396\n",
      "Trainable params: 288,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 0s - loss: 2.4932 - accuracy: 0.0585\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7488/7767 [===========================>..] - ETA: 0s - loss: 1.2066 - accuracy: 0.6313\n",
      "Epoch 00001: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-7.ckpt\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 1.1927 - accuracy: 0.6353 - val_loss: 0.7963 - val_accuracy: 0.7413\n",
      "Epoch 2/10\n",
      "7584/7767 [============================>.] - ETA: 0s - loss: 0.7689 - accuracy: 0.7480\n",
      "Epoch 00002: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-7.ckpt\n",
      "7767/7767 [==============================] - 2s 249us/sample - loss: 0.7706 - accuracy: 0.7471 - val_loss: 0.8087 - val_accuracy: 0.7261\n",
      "Epoch 3/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.7140 - accuracy: 0.7557\n",
      "Epoch 00003: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-7.ckpt\n",
      "7767/7767 [==============================] - 2s 251us/sample - loss: 0.7143 - accuracy: 0.7555 - val_loss: 0.9452 - val_accuracy: 0.6607\n",
      "Epoch 4/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.6886 - accuracy: 0.7584\n",
      "Epoch 00004: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-7.ckpt\n",
      "7767/7767 [==============================] - 2s 259us/sample - loss: 0.6881 - accuracy: 0.7586 - val_loss: 0.7320 - val_accuracy: 0.7347\n",
      "Epoch 5/10\n",
      "7584/7767 [============================>.] - ETA: 0s - loss: 0.6752 - accuracy: 0.7592\n",
      "Epoch 00005: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-7.ckpt\n",
      "7767/7767 [==============================] - 2s 272us/sample - loss: 0.6752 - accuracy: 0.7592 - val_loss: 0.7815 - val_accuracy: 0.7204\n",
      "Epoch 6/10\n",
      "7552/7767 [============================>.] - ETA: 0s - loss: 0.6597 - accuracy: 0.7619\n",
      "Epoch 00006: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-7.ckpt\n",
      "7767/7767 [==============================] - 2s 272us/sample - loss: 0.6631 - accuracy: 0.7605 - val_loss: 0.7194 - val_accuracy: 0.7413\n",
      "Epoch 7/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 0.6532 - accuracy: 0.7611\n",
      "Epoch 00007: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-7.ckpt\n",
      "7767/7767 [==============================] - 2s 267us/sample - loss: 0.6521 - accuracy: 0.7616 - val_loss: 0.6912 - val_accuracy: 0.7438\n",
      "Epoch 8/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.6478 - accuracy: 0.7624\n",
      "Epoch 00008: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-7.ckpt\n",
      "7767/7767 [==============================] - 2s 263us/sample - loss: 0.6468 - accuracy: 0.7630 - val_loss: 0.7244 - val_accuracy: 0.7356\n",
      "Epoch 9/10\n",
      "7520/7767 [============================>.] - ETA: 0s - loss: 0.6432 - accuracy: 0.7632\n",
      "Epoch 00009: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-7.ckpt\n",
      "7767/7767 [==============================] - 2s 271us/sample - loss: 0.6405 - accuracy: 0.7645 - val_loss: 0.7099 - val_accuracy: 0.7426\n",
      "Epoch 10/10\n",
      "7552/7767 [============================>.] - ETA: 0s - loss: 0.6390 - accuracy: 0.7626\n",
      "Epoch 00010: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-7.ckpt\n",
      "7767/7767 [==============================] - 2s 262us/sample - loss: 0.6368 - accuracy: 0.7636 - val_loss: 0.6989 - val_accuracy: 0.7407\n",
      "3162/3162 - 0s - loss: 0.6989 - accuracy: 0.7407\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B36EEC798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B36EEC798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-7\\assets\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_16 (Conv1D)           (None, 559, 32)           128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 279, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 277, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 138, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 138, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 4416)              0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 64)                282688    \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 288,396\n",
      "Trainable params: 288,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 0s - loss: 2.4955 - accuracy: 0.1401\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 1.7644 - accuracy: 0.4203\n",
      "Epoch 00001: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-8.ckpt\n",
      "7767/7767 [==============================] - 2s 319us/sample - loss: 1.7639 - accuracy: 0.4199 - val_loss: 1.5407 - val_accuracy: 0.4798\n",
      "Epoch 2/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 1.4974 - accuracy: 0.4711\n",
      "Epoch 00002: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-8.ckpt\n",
      "7767/7767 [==============================] - 2s 258us/sample - loss: 1.4960 - accuracy: 0.4716 - val_loss: 1.5153 - val_accuracy: 0.4794\n",
      "Epoch 3/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 1.4361 - accuracy: 0.4807\n",
      "Epoch 00003: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-8.ckpt\n",
      "7767/7767 [==============================] - 2s 249us/sample - loss: 1.4352 - accuracy: 0.4811 - val_loss: 1.4309 - val_accuracy: 0.4845\n",
      "Epoch 4/10\n",
      "7520/7767 [============================>.] - ETA: 0s - loss: 1.4069 - accuracy: 0.4819\n",
      "Epoch 00004: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-8.ckpt\n",
      "7767/7767 [==============================] - 2s 245us/sample - loss: 1.4089 - accuracy: 0.4810 - val_loss: 1.4299 - val_accuracy: 0.4820\n",
      "Epoch 5/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 1.3795 - accuracy: 0.4816\n",
      "Epoch 00005: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-8.ckpt\n",
      "7767/7767 [==============================] - 2s 257us/sample - loss: 1.3793 - accuracy: 0.4815 - val_loss: 1.4565 - val_accuracy: 0.4842\n",
      "Epoch 6/10\n",
      "7488/7767 [===========================>..] - ETA: 0s - loss: 1.3760 - accuracy: 0.4834\n",
      "Epoch 00006: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-8.ckpt\n",
      "7767/7767 [==============================] - 2s 247us/sample - loss: 1.3749 - accuracy: 0.4840 - val_loss: 1.4521 - val_accuracy: 0.4801\n",
      "Epoch 7/10\n",
      "7520/7767 [============================>.] - ETA: 0s - loss: 1.3676 - accuracy: 0.4848\n",
      "Epoch 00007: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-8.ckpt\n",
      "7767/7767 [==============================] - 2s 256us/sample - loss: 1.3666 - accuracy: 0.4850 - val_loss: 1.4180 - val_accuracy: 0.4744\n",
      "Epoch 8/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 1.3569 - accuracy: 0.4841\n",
      "Epoch 00008: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-8.ckpt\n",
      "7767/7767 [==============================] - 2s 250us/sample - loss: 1.3557 - accuracy: 0.4846 - val_loss: 1.3966 - val_accuracy: 0.4769\n",
      "Epoch 9/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 1.3536 - accuracy: 0.4842\n",
      "Epoch 00009: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-8.ckpt\n",
      "7767/7767 [==============================] - 2s 250us/sample - loss: 1.3514 - accuracy: 0.4851 - val_loss: 1.4258 - val_accuracy: 0.4867\n",
      "Epoch 10/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 1.3440 - accuracy: 0.4845\n",
      "Epoch 00010: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-8.ckpt\n",
      "7767/7767 [==============================] - 2s 294us/sample - loss: 1.3436 - accuracy: 0.4846 - val_loss: 1.3816 - val_accuracy: 0.4870\n",
      "3162/3162 - 0s - loss: 1.3816 - accuracy: 0.4870\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B4D332828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B4D332828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-8\\assets\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_18 (Conv1D)           (None, 559, 32)           128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 279, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 277, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 138, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 138, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 4416)              0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 64)                282688    \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 288,396\n",
      "Trainable params: 288,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4847 - accuracy: 0.1040\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7552/7767 [============================>.] - ETA: 0s - loss: 1.1692 - accuracy: 0.6078\n",
      "Epoch 00001: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-9.ckpt\n",
      "7767/7767 [==============================] - 3s 392us/sample - loss: 1.1504 - accuracy: 0.6139 - val_loss: 0.4658 - val_accuracy: 0.8393\n",
      "Epoch 2/10\n",
      "7584/7767 [============================>.] - ETA: 0s - loss: 0.3712 - accuracy: 0.8577\n",
      "Epoch 00002: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-9.ckpt\n",
      "7767/7767 [==============================] - 2s 270us/sample - loss: 0.3684 - accuracy: 0.8593 - val_loss: 0.4148 - val_accuracy: 0.8374\n",
      "Epoch 3/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 0.2828 - accuracy: 0.8971\n",
      "Epoch 00003: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-9.ckpt\n",
      "7767/7767 [==============================] - 2s 267us/sample - loss: 0.2841 - accuracy: 0.8962 - val_loss: 0.3169 - val_accuracy: 0.8839\n",
      "Epoch 4/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 0.2520 - accuracy: 0.9070\n",
      "Epoch 00004: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-9.ckpt\n",
      "7767/7767 [==============================] - 2s 267us/sample - loss: 0.2505 - accuracy: 0.9078 - val_loss: 0.3429 - val_accuracy: 0.8656\n",
      "Epoch 5/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.2334 - accuracy: 0.9116\n",
      "Epoch 00005: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-9.ckpt\n",
      "7767/7767 [==============================] - 2s 254us/sample - loss: 0.2335 - accuracy: 0.9114 - val_loss: 0.3217 - val_accuracy: 0.8751\n",
      "Epoch 6/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.2133 - accuracy: 0.9192\n",
      "Epoch 00006: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-9.ckpt\n",
      "7767/7767 [==============================] - 2s 255us/sample - loss: 0.2134 - accuracy: 0.9191 - val_loss: 0.3406 - val_accuracy: 0.8786\n",
      "Epoch 7/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.2068 - accuracy: 0.9233\n",
      "Epoch 00007: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-9.ckpt\n",
      "7767/7767 [==============================] - 2s 252us/sample - loss: 0.2067 - accuracy: 0.9234 - val_loss: 0.3512 - val_accuracy: 0.8805\n",
      "Epoch 8/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.2013 - accuracy: 0.9236\n",
      "Epoch 00008: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-9.ckpt\n",
      "7767/7767 [==============================] - 2s 260us/sample - loss: 0.2003 - accuracy: 0.9240 - val_loss: 0.2891 - val_accuracy: 0.8906\n",
      "Epoch 9/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.1996 - accuracy: 0.9247\n",
      "Epoch 00009: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-9.ckpt\n",
      "7767/7767 [==============================] - 2s 251us/sample - loss: 0.1999 - accuracy: 0.9246 - val_loss: 0.2705 - val_accuracy: 0.9013\n",
      "Epoch 10/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.1883 - accuracy: 0.9279\n",
      "Epoch 00010: saving model to checkpoints\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-9.ckpt\n",
      "7767/7767 [==============================] - 2s 246us/sample - loss: 0.1882 - accuracy: 0.9278 - val_loss: 0.2525 - val_accuracy: 0.9067\n",
      "3162/3162 - 0s - loss: 0.2525 - accuracy: 0.9067\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B902178B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B902178B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-9\\assets\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_20 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4869 - accuracy: 0.0073\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 1.0372 - accuracy: 0.6590\n",
      "Epoch 00001: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-0.ckpt\n",
      "7767/7767 [==============================] - 3s 435us/sample - loss: 1.0362 - accuracy: 0.6606 - val_loss: 0.8273 - val_accuracy: 0.7701\n",
      "Epoch 2/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.6769 - accuracy: 0.8392\n",
      "Epoch 00002: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-0.ckpt\n",
      "7767/7767 [==============================] - 3s 354us/sample - loss: 0.6773 - accuracy: 0.8402 - val_loss: 0.6495 - val_accuracy: 0.8868\n",
      "Epoch 3/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.6008 - accuracy: 0.8893\n",
      "Epoch 00003: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-0.ckpt\n",
      "7767/7767 [==============================] - 3s 371us/sample - loss: 0.6002 - accuracy: 0.8898 - val_loss: 0.6417 - val_accuracy: 0.8849\n",
      "Epoch 4/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.5765 - accuracy: 0.9133\n",
      "Epoch 00004: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-0.ckpt\n",
      "7767/7767 [==============================] - 3s 348us/sample - loss: 0.5769 - accuracy: 0.9140 - val_loss: 0.6021 - val_accuracy: 0.9228\n",
      "Epoch 5/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 0.5425 - accuracy: 0.9291\n",
      "Epoch 00005: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-0.ckpt\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 0.5448 - accuracy: 0.9288 - val_loss: 0.6334 - val_accuracy: 0.9102\n",
      "Epoch 6/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.5410 - accuracy: 0.9324\n",
      "Epoch 00006: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-0.ckpt\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.5397 - accuracy: 0.9331 - val_loss: 0.6137 - val_accuracy: 0.9067\n",
      "Epoch 7/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 0.5262 - accuracy: 0.9409\n",
      "Epoch 00007: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-0.ckpt\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.5279 - accuracy: 0.9409 - val_loss: 0.6592 - val_accuracy: 0.9187\n",
      "Epoch 8/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.5232 - accuracy: 0.9404\n",
      "Epoch 00008: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-0.ckpt\n",
      "7767/7767 [==============================] - 3s 339us/sample - loss: 0.5225 - accuracy: 0.9405 - val_loss: 0.6190 - val_accuracy: 0.9247\n",
      "Epoch 9/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.5238 - accuracy: 0.9406\n",
      "Epoch 00009: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-0.ckpt\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.5227 - accuracy: 0.9408 - val_loss: 0.6150 - val_accuracy: 0.9130\n",
      "Epoch 10/10\n",
      "7584/7767 [============================>.] - ETA: 0s - loss: 0.5102 - accuracy: 0.9515 ETA: 0s - loss: 0.5025 - accura\n",
      "Epoch 00010: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-0.ckpt\n",
      "7767/7767 [==============================] - 3s 340us/sample - loss: 0.5115 - accuracy: 0.9516 - val_loss: 0.6135 - val_accuracy: 0.9247\n",
      "3162/3162 - 0s - loss: 0.6135 - accuracy: 0.9247\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B36ED3048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B36ED3048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-0\\assets\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_22 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4952 - accuracy: 0.0066\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 1.0742 - accuracy: 0.6752\n",
      "Epoch 00001: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-1.ckpt\n",
      "7767/7767 [==============================] - 3s 397us/sample - loss: 1.0710 - accuracy: 0.6761 - val_loss: 0.7524 - val_accuracy: 0.7619\n",
      "Epoch 2/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.6811 - accuracy: 0.7853\n",
      "Epoch 00002: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-1.ckpt\n",
      "7767/7767 [==============================] - 3s 346us/sample - loss: 0.6806 - accuracy: 0.7855 - val_loss: 0.6671 - val_accuracy: 0.7666\n",
      "Epoch 3/10\n",
      "7584/7767 [============================>.] - ETA: 0s - loss: 0.6060 - accuracy: 0.7961\n",
      "Epoch 00003: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-1.ckpt\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.6027 - accuracy: 0.7973 - val_loss: 0.6193 - val_accuracy: 0.7774\n",
      "Epoch 4/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.5755 - accuracy: 0.7999\n",
      "Epoch 00004: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-1.ckpt\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.5758 - accuracy: 0.7999 - val_loss: 0.5897 - val_accuracy: 0.7862\n",
      "Epoch 5/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.5500 - accuracy: 0.8055\n",
      "Epoch 00005: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-1.ckpt\n",
      "7767/7767 [==============================] - 3s 354us/sample - loss: 0.5501 - accuracy: 0.8053 - val_loss: 0.6061 - val_accuracy: 0.7859\n",
      "Epoch 6/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.5329 - accuracy: 0.8074\n",
      "Epoch 00006: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-1.ckpt\n",
      "7767/7767 [==============================] - 3s 361us/sample - loss: 0.5314 - accuracy: 0.8082 - val_loss: 0.6247 - val_accuracy: 0.7818\n",
      "Epoch 7/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.5177 - accuracy: 0.8125\n",
      "Epoch 00007: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-1.ckpt\n",
      "7767/7767 [==============================] - 3s 345us/sample - loss: 0.5210 - accuracy: 0.8114 - val_loss: 0.5972 - val_accuracy: 0.7884\n",
      "Epoch 8/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.5141 - accuracy: 0.8122\n",
      "Epoch 00008: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-1.ckpt\n",
      "7767/7767 [==============================] - 3s 343us/sample - loss: 0.5131 - accuracy: 0.8128 - val_loss: 0.6131 - val_accuracy: 0.7865\n",
      "Epoch 9/10\n",
      "7552/7767 [============================>.] - ETA: 0s - loss: 0.5108 - accuracy: 0.8140\n",
      "Epoch 00009: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-1.ckpt\n",
      "7767/7767 [==============================] - 3s 340us/sample - loss: 0.5102 - accuracy: 0.8140 - val_loss: 0.5865 - val_accuracy: 0.7903\n",
      "Epoch 10/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 0.5036 - accuracy: 0.8126\n",
      "Epoch 00010: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-1.ckpt\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.5035 - accuracy: 0.8127 - val_loss: 0.5921 - val_accuracy: 0.7875\n",
      "3162/3162 - 0s - loss: 0.5921 - accuracy: 0.7875\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B902A0D38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B902A0D38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-1\\assets\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_24 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4805 - accuracy: 0.0658\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.6602 - accuracy: 0.7622\n",
      "Epoch 00001: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 3s 397us/sample - loss: 0.6552 - accuracy: 0.7640 - val_loss: 0.4329 - val_accuracy: 0.8352\n",
      "Epoch 2/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.2680 - accuracy: 0.9038\n",
      "Epoch 00002: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 3s 345us/sample - loss: 0.2675 - accuracy: 0.9040 - val_loss: 0.3315 - val_accuracy: 0.8697\n",
      "Epoch 3/10\n",
      "7584/7767 [============================>.] - ETA: 0s - loss: 0.2243 - accuracy: 0.9209\n",
      "Epoch 00003: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 3s 349us/sample - loss: 0.2228 - accuracy: 0.9216 - val_loss: 0.2811 - val_accuracy: 0.8950\n",
      "Epoch 4/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.1836 - accuracy: 0.9371\n",
      "Epoch 00004: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 3s 356us/sample - loss: 0.1824 - accuracy: 0.9374 - val_loss: 0.2575 - val_accuracy: 0.9051\n",
      "Epoch 5/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.1761 - accuracy: 0.9349\n",
      "Epoch 00005: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 3s 366us/sample - loss: 0.1761 - accuracy: 0.9351 - val_loss: 0.2429 - val_accuracy: 0.9130\n",
      "Epoch 6/10\n",
      "7552/7767 [============================>.] - ETA: 0s - loss: 0.1595 - accuracy: 0.9423\n",
      "Epoch 00006: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 3s 358us/sample - loss: 0.1598 - accuracy: 0.9421 - val_loss: 0.2302 - val_accuracy: 0.9222\n",
      "Epoch 7/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 0.1492 - accuracy: 0.9463\n",
      "Epoch 00007: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 3s 349us/sample - loss: 0.1498 - accuracy: 0.9461 - val_loss: 0.2749 - val_accuracy: 0.9010\n",
      "Epoch 8/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 0.1433 - accuracy: 0.9477\n",
      "Epoch 00008: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 3s 340us/sample - loss: 0.1435 - accuracy: 0.9476 - val_loss: 0.2983 - val_accuracy: 0.9042\n",
      "Epoch 9/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.1392 - accuracy: 0.9490\n",
      "Epoch 00009: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.1385 - accuracy: 0.9491 - val_loss: 0.2511 - val_accuracy: 0.9184\n",
      "Epoch 10/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 0.1345 - accuracy: 0.9517\n",
      "Epoch 00010: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 3s 342us/sample - loss: 0.1348 - accuracy: 0.9515 - val_loss: 0.2480 - val_accuracy: 0.9187\n",
      "3162/3162 - 0s - loss: 0.2480 - accuracy: 0.9187\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018BA1CCF948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018BA1CCF948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-2\\assets\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_26 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4781 - accuracy: 0.1610\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7584/7767 [============================>.] - ETA: 0s - loss: 1.2773 - accuracy: 0.5476\n",
      "Epoch 00001: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-3.ckpt\n",
      "7767/7767 [==============================] - 3s 392us/sample - loss: 1.2710 - accuracy: 0.5487 - val_loss: 0.9912 - val_accuracy: 0.6268\n",
      "Epoch 2/10\n",
      "7552/7767 [============================>.] - ETA: 0s - loss: 0.8934 - accuracy: 0.6597\n",
      "Epoch 00002: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-3.ckpt\n",
      "7767/7767 [==============================] - 3s 329us/sample - loss: 0.8954 - accuracy: 0.6588 - val_loss: 0.9365 - val_accuracy: 0.6455\n",
      "Epoch 3/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.8477 - accuracy: 0.6730\n",
      "Epoch 00003: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-3.ckpt\n",
      "7767/7767 [==============================] - 3s 339us/sample - loss: 0.8440 - accuracy: 0.6745 - val_loss: 0.9757 - val_accuracy: 0.6319\n",
      "Epoch 4/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 0.8160 - accuracy: 0.6839\n",
      "Epoch 00004: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-3.ckpt\n",
      "7767/7767 [==============================] - 3s 343us/sample - loss: 0.8157 - accuracy: 0.6839 - val_loss: 0.8808 - val_accuracy: 0.6626\n",
      "Epoch 5/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.8010 - accuracy: 0.6855\n",
      "Epoch 00005: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-3.ckpt\n",
      "7767/7767 [==============================] - 3s 331us/sample - loss: 0.7988 - accuracy: 0.6865 - val_loss: 0.8928 - val_accuracy: 0.6619\n",
      "Epoch 6/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.7903 - accuracy: 0.6916\n",
      "Epoch 00006: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-3.ckpt\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.7896 - accuracy: 0.6919 - val_loss: 0.8835 - val_accuracy: 0.6670\n",
      "Epoch 7/10\n",
      "7552/7767 [============================>.] - ETA: 0s - loss: 0.7856 - accuracy: 0.6911\n",
      "Epoch 00007: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-3.ckpt\n",
      "7767/7767 [==============================] - 3s 330us/sample - loss: 0.7853 - accuracy: 0.6915 - val_loss: 0.8706 - val_accuracy: 0.6689\n",
      "Epoch 8/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 0.7793 - accuracy: 0.6942\n",
      "Epoch 00008: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-3.ckpt\n",
      "7767/7767 [==============================] - 3s 329us/sample - loss: 0.7795 - accuracy: 0.6941 - val_loss: 0.8773 - val_accuracy: 0.6676\n",
      "Epoch 9/10\n",
      "7584/7767 [============================>.] - ETA: 0s - loss: 0.7686 - accuracy: 0.6966\n",
      "Epoch 00009: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-3.ckpt\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 0.7708 - accuracy: 0.6956 - val_loss: 0.8712 - val_accuracy: 0.6651\n",
      "Epoch 10/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.7633 - accuracy: 0.6974\n",
      "Epoch 00010: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-3.ckpt\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.7629 - accuracy: 0.6977 - val_loss: 0.9100 - val_accuracy: 0.6610\n",
      "3162/3162 - 0s - loss: 0.9100 - accuracy: 0.6610\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B903AF708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B903AF708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-3\\assets\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.5039 - accuracy: 0.0101\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 1.0898 - accuracy: 0.6460\n",
      "Epoch 00001: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-4.ckpt\n",
      "7767/7767 [==============================] - 3s 405us/sample - loss: 1.0842 - accuracy: 0.6490 - val_loss: 0.8507 - val_accuracy: 0.8276\n",
      "Epoch 2/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.7033 - accuracy: 0.8372\n",
      "Epoch 00002: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-4.ckpt\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.7008 - accuracy: 0.8382 - val_loss: 0.7250 - val_accuracy: 0.8855\n",
      "Epoch 3/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 0.6330 - accuracy: 0.8866\n",
      "Epoch 00003: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-4.ckpt\n",
      "7767/7767 [==============================] - 3s 347us/sample - loss: 0.6311 - accuracy: 0.8871 - val_loss: 0.6607 - val_accuracy: 0.8586\n",
      "Epoch 4/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.6030 - accuracy: 0.9018\n",
      "Epoch 00004: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-4.ckpt\n",
      "7767/7767 [==============================] - 3s 364us/sample - loss: 0.6054 - accuracy: 0.9018 - val_loss: 0.6859 - val_accuracy: 0.8811\n",
      "Epoch 5/10\n",
      "7552/7767 [============================>.] - ETA: 0s - loss: 0.6019 - accuracy: 0.9084\n",
      "Epoch 00005: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-4.ckpt\n",
      "7767/7767 [==============================] - 3s 348us/sample - loss: 0.5986 - accuracy: 0.9091 - val_loss: 0.7059 - val_accuracy: 0.8779\n",
      "Epoch 6/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 0.5816 - accuracy: 0.9160\n",
      "Epoch 00006: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-4.ckpt\n",
      "7767/7767 [==============================] - 3s 343us/sample - loss: 0.5816 - accuracy: 0.9157 - val_loss: 0.6507 - val_accuracy: 0.8703\n",
      "Epoch 7/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 0.5775 - accuracy: 0.9235\n",
      "Epoch 00007: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-4.ckpt\n",
      "7767/7767 [==============================] - 3s 365us/sample - loss: 0.5741 - accuracy: 0.9242 - val_loss: 0.6919 - val_accuracy: 0.8861\n",
      "Epoch 8/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.5685 - accuracy: 0.9244\n",
      "Epoch 00008: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-4.ckpt\n",
      "7767/7767 [==============================] - 3s 340us/sample - loss: 0.5669 - accuracy: 0.9247 - val_loss: 0.6434 - val_accuracy: 0.8953\n",
      "Epoch 9/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.5654 - accuracy: 0.9259\n",
      "Epoch 00009: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-4.ckpt\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.5657 - accuracy: 0.9253 - val_loss: 0.7192 - val_accuracy: 0.8700\n",
      "Epoch 10/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.5621 - accuracy: 0.9262\n",
      "Epoch 00010: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-4.ckpt\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 0.5612 - accuracy: 0.9258 - val_loss: 0.6608 - val_accuracy: 0.8877\n",
      "3162/3162 - 0s - loss: 0.6608 - accuracy: 0.8877\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B37273558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B37273558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-4\\assets\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_30 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4690 - accuracy: 0.1607\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7584/7767 [============================>.] - ETA: 0s - loss: 1.1463 - accuracy: 0.6344\n",
      "Epoch 00001: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-5.ckpt\n",
      "7767/7767 [==============================] - 3s 407us/sample - loss: 1.1383 - accuracy: 0.6367 - val_loss: 0.7420 - val_accuracy: 0.7587\n",
      "Epoch 2/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 0.7297 - accuracy: 0.7549\n",
      "Epoch 00002: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-5.ckpt\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.7294 - accuracy: 0.7550 - val_loss: 0.8038 - val_accuracy: 0.7170\n",
      "Epoch 3/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.6703 - accuracy: 0.7646\n",
      "Epoch 00003: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-5.ckpt\n",
      "7767/7767 [==============================] - 3s 343us/sample - loss: 0.6701 - accuracy: 0.7648 - val_loss: 0.7611 - val_accuracy: 0.7378\n",
      "Epoch 4/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 0.6564 - accuracy: 0.7660\n",
      "Epoch 00004: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-5.ckpt\n",
      "7767/7767 [==============================] - 3s 352us/sample - loss: 0.6568 - accuracy: 0.7655 - val_loss: 0.7135 - val_accuracy: 0.7511\n",
      "Epoch 5/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 0.6348 - accuracy: 0.7717\n",
      "Epoch 00005: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-5.ckpt\n",
      "7767/7767 [==============================] - 3s 403us/sample - loss: 0.6369 - accuracy: 0.7708 - val_loss: 0.6802 - val_accuracy: 0.7546\n",
      "Epoch 6/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.6286 - accuracy: 0.7710\n",
      "Epoch 00006: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-5.ckpt\n",
      "7767/7767 [==============================] - 3s 345us/sample - loss: 0.6278 - accuracy: 0.7713 - val_loss: 0.6658 - val_accuracy: 0.7581\n",
      "Epoch 7/10\n",
      "7552/7767 [============================>.] - ETA: 0s - loss: 0.6241 - accuracy: 0.7732\n",
      "Epoch 00007: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-5.ckpt\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.6251 - accuracy: 0.7729 - val_loss: 0.6840 - val_accuracy: 0.7505\n",
      "Epoch 8/10\n",
      "7552/7767 [============================>.] - ETA: 0s - loss: 0.6235 - accuracy: 0.7713\n",
      "Epoch 00008: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-5.ckpt\n",
      "7767/7767 [==============================] - 3s 340us/sample - loss: 0.6208 - accuracy: 0.7721 - val_loss: 0.6893 - val_accuracy: 0.7486\n",
      "Epoch 9/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 0.6087 - accuracy: 0.7735\n",
      "Epoch 00009: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-5.ckpt\n",
      "7767/7767 [==============================] - 3s 348us/sample - loss: 0.6082 - accuracy: 0.7737 - val_loss: 0.6840 - val_accuracy: 0.7486\n",
      "Epoch 10/10\n",
      "7584/7767 [============================>.] - ETA: 0s - loss: 0.6091 - accuracy: 0.7731\n",
      "Epoch 00010: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-5.ckpt\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.6084 - accuracy: 0.7731 - val_loss: 0.7964 - val_accuracy: 0.7239\n",
      "3162/3162 - 0s - loss: 0.7964 - accuracy: 0.7239\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B979AB5E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B979AB5E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-5\\assets\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_32 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4857 - accuracy: 0.1714\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 1.0094 - accuracy: 0.6502\n",
      "Epoch 00001: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-6.ckpt\n",
      "7767/7767 [==============================] - 3s 409us/sample - loss: 1.0007 - accuracy: 0.6528 - val_loss: 0.7051 - val_accuracy: 0.7527\n",
      "Epoch 2/10\n",
      "7552/7767 [============================>.] - ETA: 0s - loss: 0.6105 - accuracy: 0.7734\n",
      "Epoch 00002: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-6.ckpt\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 0.6107 - accuracy: 0.7733 - val_loss: 0.6515 - val_accuracy: 0.7666\n",
      "Epoch 3/10\n",
      "7584/7767 [============================>.] - ETA: 0s - loss: 0.5709 - accuracy: 0.7869\n",
      "Epoch 00003: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-6.ckpt\n",
      "7767/7767 [==============================] - 3s 357us/sample - loss: 0.5702 - accuracy: 0.7868 - val_loss: 0.6630 - val_accuracy: 0.7600\n",
      "Epoch 4/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.5425 - accuracy: 0.7950\n",
      "Epoch 00004: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-6.ckpt\n",
      "7767/7767 [==============================] - 3s 348us/sample - loss: 0.5415 - accuracy: 0.7952 - val_loss: 0.6074 - val_accuracy: 0.7761\n",
      "Epoch 5/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 0.5235 - accuracy: 0.7993\n",
      "Epoch 00005: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-6.ckpt\n",
      "7767/7767 [==============================] - 3s 350us/sample - loss: 0.5227 - accuracy: 0.7995 - val_loss: 0.6163 - val_accuracy: 0.7777\n",
      "Epoch 6/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.5066 - accuracy: 0.8046\n",
      "Epoch 00006: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-6.ckpt\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.5077 - accuracy: 0.8040 - val_loss: 0.6191 - val_accuracy: 0.7751\n",
      "Epoch 7/10\n",
      "7584/7767 [============================>.] - ETA: 0s - loss: 0.5040 - accuracy: 0.8059\n",
      "Epoch 00007: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-6.ckpt\n",
      "7767/7767 [==============================] - 3s 342us/sample - loss: 0.5029 - accuracy: 0.8062 - val_loss: 0.5976 - val_accuracy: 0.7796\n",
      "Epoch 8/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.4965 - accuracy: 0.8099\n",
      "Epoch 00008: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-6.ckpt\n",
      "7767/7767 [==============================] - 3s 341us/sample - loss: 0.4972 - accuracy: 0.8095 - val_loss: 0.6238 - val_accuracy: 0.7707\n",
      "Epoch 9/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 0.4997 - accuracy: 0.8046\n",
      "Epoch 00009: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-6.ckpt\n",
      "7767/7767 [==============================] - 3s 353us/sample - loss: 0.5002 - accuracy: 0.8047 - val_loss: 0.5921 - val_accuracy: 0.7805\n",
      "Epoch 10/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.4887 - accuracy: 0.8066\n",
      "Epoch 00010: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-6.ckpt\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 0.4867 - accuracy: 0.8074 - val_loss: 0.6462 - val_accuracy: 0.7612\n",
      "3162/3162 - 0s - loss: 0.6462 - accuracy: 0.7612\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B4A672168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B4A672168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-6\\assets\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_34 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.5032 - accuracy: 0.0092\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 1.4837 - accuracy: 0.5117\n",
      "Epoch 00001: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-7.ckpt\n",
      "7767/7767 [==============================] - 3s 410us/sample - loss: 1.4801 - accuracy: 0.5128 - val_loss: 1.1839 - val_accuracy: 0.6502\n",
      "Epoch 2/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 1.1329 - accuracy: 0.6712\n",
      "Epoch 00002: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-7.ckpt\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 1.1357 - accuracy: 0.6712 - val_loss: 1.1053 - val_accuracy: 0.7018\n",
      "Epoch 3/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 1.0779 - accuracy: 0.7104\n",
      "Epoch 00003: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-7.ckpt\n",
      "7767/7767 [==============================] - 3s 333us/sample - loss: 1.0773 - accuracy: 0.7102 - val_loss: 1.2073 - val_accuracy: 0.6284\n",
      "Epoch 4/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 1.0615 - accuracy: 0.7211\n",
      "Epoch 00004: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-7.ckpt\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 1.0572 - accuracy: 0.7215 - val_loss: 1.0846 - val_accuracy: 0.7192\n",
      "Epoch 5/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 1.0421 - accuracy: 0.7324\n",
      "Epoch 00005: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-7.ckpt\n",
      "7767/7767 [==============================] - 3s 332us/sample - loss: 1.0415 - accuracy: 0.7326 - val_loss: 1.1509 - val_accuracy: 0.6967\n",
      "Epoch 6/10\n",
      "7584/7767 [============================>.] - ETA: 0s - loss: 1.0283 - accuracy: 0.7343\n",
      "Epoch 00006: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-7.ckpt\n",
      "7767/7767 [==============================] - 3s 331us/sample - loss: 1.0303 - accuracy: 0.7339 - val_loss: 1.1080 - val_accuracy: 0.7179\n",
      "Epoch 7/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 1.0258 - accuracy: 0.7396\n",
      "Epoch 00007: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-7.ckpt\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 1.0240 - accuracy: 0.7407 - val_loss: 1.0600 - val_accuracy: 0.7135\n",
      "Epoch 8/10\n",
      "7584/7767 [============================>.] - ETA: 0s - loss: 1.0136 - accuracy: 0.7470\n",
      "Epoch 00008: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-7.ckpt\n",
      "7767/7767 [==============================] - 3s 333us/sample - loss: 1.0129 - accuracy: 0.7469 - val_loss: 1.1035 - val_accuracy: 0.7043\n",
      "Epoch 9/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 1.0080 - accuracy: 0.7471\n",
      "Epoch 00009: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-7.ckpt\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 1.0113 - accuracy: 0.7473 - val_loss: 1.0971 - val_accuracy: 0.7277\n",
      "Epoch 10/10\n",
      "7552/7767 [============================>.] - ETA: 0s - loss: 1.0075 - accuracy: 0.7495\n",
      "Epoch 00010: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-7.ckpt\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 1.0075 - accuracy: 0.7492 - val_loss: 1.0570 - val_accuracy: 0.7375\n",
      "3162/3162 - 0s - loss: 1.0570 - accuracy: 0.7375\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018BA1D3A1F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018BA1D3A1F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-7\\assets\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4886 - accuracy: 0.1009\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 1.4136 - accuracy: 0.5517\n",
      "Epoch 00001: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-8.ckpt\n",
      "7767/7767 [==============================] - 4s 460us/sample - loss: 1.4086 - accuracy: 0.5531 - val_loss: 1.1211 - val_accuracy: 0.6145\n",
      "Epoch 2/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 1.0675 - accuracy: 0.6307\n",
      "Epoch 00002: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-8.ckpt\n",
      "7767/7767 [==============================] - 3s 371us/sample - loss: 1.0704 - accuracy: 0.6298 - val_loss: 1.1110 - val_accuracy: 0.6173\n",
      "Epoch 3/10\n",
      "7584/7767 [============================>.] - ETA: 0s - loss: 1.0101 - accuracy: 0.6326\n",
      "Epoch 00003: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-8.ckpt\n",
      "7767/7767 [==============================] - 3s 344us/sample - loss: 1.0050 - accuracy: 0.6345 - val_loss: 1.0724 - val_accuracy: 0.6129\n",
      "Epoch 4/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.9913 - accuracy: 0.6351\n",
      "Epoch 00004: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-8.ckpt\n",
      "7767/7767 [==============================] - 3s 342us/sample - loss: 0.9920 - accuracy: 0.6347 - val_loss: 1.0452 - val_accuracy: 0.6170\n",
      "Epoch 5/10\n",
      "7584/7767 [============================>.] - ETA: 0s - loss: 0.9700 - accuracy: 0.6371\n",
      "Epoch 00005: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-8.ckpt\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.9713 - accuracy: 0.6369 - val_loss: 1.0720 - val_accuracy: 0.6107\n",
      "Epoch 6/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.9685 - accuracy: 0.6351\n",
      "Epoch 00006: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-8.ckpt\n",
      "7767/7767 [==============================] - 3s 340us/sample - loss: 0.9670 - accuracy: 0.6356 - val_loss: 1.0472 - val_accuracy: 0.6189\n",
      "Epoch 7/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 0.9538 - accuracy: 0.6379\n",
      "Epoch 00007: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-8.ckpt\n",
      "7767/7767 [==============================] - 3s 332us/sample - loss: 0.9555 - accuracy: 0.6372 - val_loss: 1.0307 - val_accuracy: 0.6208\n",
      "Epoch 8/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.9532 - accuracy: 0.6358\n",
      "Epoch 00008: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-8.ckpt\n",
      "7767/7767 [==============================] - 3s 341us/sample - loss: 0.9528 - accuracy: 0.6359 - val_loss: 1.0405 - val_accuracy: 0.6176\n",
      "Epoch 9/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 0.9559 - accuracy: 0.6369\n",
      "Epoch 00009: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-8.ckpt\n",
      "7767/7767 [==============================] - 3s 332us/sample - loss: 0.9588 - accuracy: 0.6359 - val_loss: 1.0375 - val_accuracy: 0.6145\n",
      "Epoch 10/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.9436 - accuracy: 0.6439\n",
      "Epoch 00010: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-8.ckpt\n",
      "7767/7767 [==============================] - 3s 333us/sample - loss: 0.9454 - accuracy: 0.6430 - val_loss: 1.0262 - val_accuracy: 0.6195\n",
      "3162/3162 - 0s - loss: 1.0262 - accuracy: 0.6195\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B337B68B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B337B68B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-8\\assets\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_38 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4856 - accuracy: 0.1186\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 0.6831 - accuracy: 0.7508\n",
      "Epoch 00001: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-9.ckpt\n",
      "7767/7767 [==============================] - 3s 409us/sample - loss: 0.6764 - accuracy: 0.7537 - val_loss: 0.3141 - val_accuracy: 0.9029\n",
      "Epoch 2/10\n",
      "7552/7767 [============================>.] - ETA: 0s - loss: 0.2574 - accuracy: 0.9121\n",
      "Epoch 00002: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-9.ckpt\n",
      "7767/7767 [==============================] - 3s 333us/sample - loss: 0.2552 - accuracy: 0.9128 - val_loss: 0.2455 - val_accuracy: 0.9175\n",
      "Epoch 3/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 0.2074 - accuracy: 0.9269\n",
      "Epoch 00003: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-9.ckpt\n",
      "7767/7767 [==============================] - 3s 340us/sample - loss: 0.2105 - accuracy: 0.9261 - val_loss: 0.2766 - val_accuracy: 0.9048\n",
      "Epoch 4/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 0.1785 - accuracy: 0.9401\n",
      "Epoch 00004: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-9.ckpt\n",
      "7767/7767 [==============================] - 3s 349us/sample - loss: 0.1789 - accuracy: 0.9400 - val_loss: 0.3547 - val_accuracy: 0.8729\n",
      "Epoch 5/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 0.1442 - accuracy: 0.9530\n",
      "Epoch 00005: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-9.ckpt\n",
      "7767/7767 [==============================] - 3s 342us/sample - loss: 0.1448 - accuracy: 0.9527 - val_loss: 0.3064 - val_accuracy: 0.9039\n",
      "Epoch 6/10\n",
      "7584/7767 [============================>.] - ETA: 0s - loss: 0.1372 - accuracy: 0.9521\n",
      "Epoch 00006: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-9.ckpt\n",
      "7767/7767 [==============================] - 3s 362us/sample - loss: 0.1372 - accuracy: 0.9521 - val_loss: 0.2571 - val_accuracy: 0.9149\n",
      "Epoch 7/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 0.1268 - accuracy: 0.9554\n",
      "Epoch 00007: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-9.ckpt\n",
      "7767/7767 [==============================] - 3s 354us/sample - loss: 0.1262 - accuracy: 0.9556 - val_loss: 0.2527 - val_accuracy: 0.9168\n",
      "Epoch 8/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.1179 - accuracy: 0.9568\n",
      "Epoch 00008: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-9.ckpt\n",
      "7767/7767 [==============================] - 3s 351us/sample - loss: 0.1173 - accuracy: 0.9571 - val_loss: 0.2362 - val_accuracy: 0.9225\n",
      "Epoch 9/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 0.1142 - accuracy: 0.9589\n",
      "Epoch 00009: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-9.ckpt\n",
      "7767/7767 [==============================] - 3s 340us/sample - loss: 0.1140 - accuracy: 0.9591 - val_loss: 0.2672 - val_accuracy: 0.9171\n",
      "Epoch 10/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.1057 - accuracy: 0.9607\n",
      "Epoch 00010: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-9.ckpt\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.1051 - accuracy: 0.9609 - val_loss: 0.2868 - val_accuracy: 0.9130\n",
      "3162/3162 - 0s - loss: 0.2868 - accuracy: 0.9130\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B9E8619D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B9E8619D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-9\\assets\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_40 (Conv1D)           (None, 559, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 279, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 277, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 138, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 138, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 17664)             0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 64)                1130560   \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 1,182,828\n",
      "Trainable params: 1,182,828\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4772 - accuracy: 0.1670\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.9916 - accuracy: 0.6905\n",
      "Epoch 00001: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-0.ckpt\n",
      "7767/7767 [==============================] - 5s 649us/sample - loss: 0.9872 - accuracy: 0.6916 - val_loss: 0.7192 - val_accuracy: 0.7552\n",
      "Epoch 2/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.6845 - accuracy: 0.7693\n",
      "Epoch 00002: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-0.ckpt\n",
      "7767/7767 [==============================] - 4s 563us/sample - loss: 0.6862 - accuracy: 0.7686 - val_loss: 0.6967 - val_accuracy: 0.7562\n",
      "Epoch 3/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.6365 - accuracy: 0.7783\n",
      "Epoch 00003: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-0.ckpt\n",
      "7767/7767 [==============================] - 4s 541us/sample - loss: 0.6361 - accuracy: 0.7783 - val_loss: 0.6646 - val_accuracy: 0.7694\n",
      "Epoch 4/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.6114 - accuracy: 0.7815\n",
      "Epoch 00004: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-0.ckpt\n",
      "7767/7767 [==============================] - 4s 540us/sample - loss: 0.6109 - accuracy: 0.7819 - val_loss: 0.7900 - val_accuracy: 0.7321\n",
      "Epoch 5/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.6095 - accuracy: 0.7797\n",
      "Epoch 00005: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-0.ckpt\n",
      "7767/7767 [==============================] - 4s 541us/sample - loss: 0.6086 - accuracy: 0.7801 - val_loss: 0.7036 - val_accuracy: 0.7536\n",
      "Epoch 6/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.5949 - accuracy: 0.7816\n",
      "Epoch 00006: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-0.ckpt\n",
      "7767/7767 [==============================] - 4s 539us/sample - loss: 0.5940 - accuracy: 0.7819 - val_loss: 0.6757 - val_accuracy: 0.7581\n",
      "Epoch 7/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.5878 - accuracy: 0.7832\n",
      "Epoch 00007: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-0.ckpt\n",
      "7767/7767 [==============================] - 4s 538us/sample - loss: 0.5884 - accuracy: 0.7829 - val_loss: 0.6557 - val_accuracy: 0.7663\n",
      "Epoch 8/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.5698 - accuracy: 0.7902\n",
      "Epoch 00008: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-0.ckpt\n",
      "7767/7767 [==============================] - 4s 540us/sample - loss: 0.5696 - accuracy: 0.7901 - val_loss: 0.6289 - val_accuracy: 0.7723\n",
      "Epoch 9/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.5574 - accuracy: 0.7915\n",
      "Epoch 00009: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-0.ckpt\n",
      "7767/7767 [==============================] - 4s 562us/sample - loss: 0.5568 - accuracy: 0.7917 - val_loss: 0.6264 - val_accuracy: 0.7723\n",
      "Epoch 10/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.5548 - accuracy: 0.7927\n",
      "Epoch 00010: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-0.ckpt\n",
      "7767/7767 [==============================] - 4s 555us/sample - loss: 0.5574 - accuracy: 0.7918 - val_loss: 0.6770 - val_accuracy: 0.7619\n",
      "3162/3162 - 1s - loss: 0.6770 - accuracy: 0.7619\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B9066E708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B9066E708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-0\\assets\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_42 (Conv1D)           (None, 559, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 279, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 277, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 138, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 138, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 17664)             0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 64)                1130560   \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 1,182,828\n",
      "Trainable params: 1,182,828\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4884 - accuracy: 0.0446\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 1.0474 - accuracy: 0.6639\n",
      "Epoch 00001: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-1.ckpt\n",
      "7767/7767 [==============================] - 5s 619us/sample - loss: 1.0452 - accuracy: 0.6645 - val_loss: 0.8131 - val_accuracy: 0.7223\n",
      "Epoch 2/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.7154 - accuracy: 0.7534\n",
      "Epoch 00002: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-1.ckpt\n",
      "7767/7767 [==============================] - 4s 561us/sample - loss: 0.7153 - accuracy: 0.7532 - val_loss: 0.7130 - val_accuracy: 0.7397\n",
      "Epoch 3/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.6630 - accuracy: 0.7617\n",
      "Epoch 00003: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-1.ckpt\n",
      "7767/7767 [==============================] - 4s 560us/sample - loss: 0.6655 - accuracy: 0.7607 - val_loss: 0.7033 - val_accuracy: 0.7451\n",
      "Epoch 4/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.6336 - accuracy: 0.7662\n",
      "Epoch 00004: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-1.ckpt\n",
      "7767/7767 [==============================] - 4s 559us/sample - loss: 0.6341 - accuracy: 0.7661 - val_loss: 0.6869 - val_accuracy: 0.7489\n",
      "Epoch 5/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.6341 - accuracy: 0.7652\n",
      "Epoch 00005: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-1.ckpt\n",
      "7767/7767 [==============================] - 4s 566us/sample - loss: 0.6331 - accuracy: 0.7655 - val_loss: 0.6746 - val_accuracy: 0.7460\n",
      "Epoch 6/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 0.6240 - accuracy: 0.7661\n",
      "Epoch 00006: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-1.ckpt\n",
      "7767/7767 [==============================] - 4s 561us/sample - loss: 0.6235 - accuracy: 0.7662 - val_loss: 0.7476 - val_accuracy: 0.7261\n",
      "Epoch 7/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.6247 - accuracy: 0.7642\n",
      "Epoch 00007: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-1.ckpt\n",
      "7767/7767 [==============================] - 4s 563us/sample - loss: 0.6233 - accuracy: 0.7646 - val_loss: 0.7194 - val_accuracy: 0.7372\n",
      "Epoch 8/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.6140 - accuracy: 0.7678\n",
      "Epoch 00008: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-1.ckpt\n",
      "7767/7767 [==============================] - 4s 548us/sample - loss: 0.6156 - accuracy: 0.7671 - val_loss: 0.7495 - val_accuracy: 0.7302\n",
      "Epoch 9/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.6146 - accuracy: 0.7680\n",
      "Epoch 00009: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-1.ckpt\n",
      "7767/7767 [==============================] - 4s 546us/sample - loss: 0.6125 - accuracy: 0.7688 - val_loss: 0.7037 - val_accuracy: 0.7413\n",
      "Epoch 10/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.6041 - accuracy: 0.7701\n",
      "Epoch 00010: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-1.ckpt\n",
      "7767/7767 [==============================] - 4s 541us/sample - loss: 0.6043 - accuracy: 0.7699 - val_loss: 0.6732 - val_accuracy: 0.7508\n",
      "3162/3162 - 1s - loss: 0.6732 - accuracy: 0.7508\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018BA1D0A318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018BA1D0A318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-1\\assets\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_44 (Conv1D)           (None, 559, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 279, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_45 (Conv1D)           (None, 277, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 138, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 138, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 17664)             0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 64)                1130560   \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 1,182,828\n",
      "Trainable params: 1,182,828\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4880 - accuracy: 0.0427\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 1.0681 - accuracy: 0.6670 ETA: 2s - loss: 1.370\n",
      "Epoch 00001: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 5s 658us/sample - loss: 1.0664 - accuracy: 0.6674 - val_loss: 0.7288 - val_accuracy: 0.7631\n",
      "Epoch 2/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.6672 - accuracy: 0.7754\n",
      "Epoch 00002: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 4s 556us/sample - loss: 0.6658 - accuracy: 0.7758 - val_loss: 0.6423 - val_accuracy: 0.7707\n",
      "Epoch 3/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.6122 - accuracy: 0.7840\n",
      "Epoch 00003: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 4s 566us/sample - loss: 0.6149 - accuracy: 0.7829 - val_loss: 0.6389 - val_accuracy: 0.7679\n",
      "Epoch 4/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.5936 - accuracy: 0.7854\n",
      "Epoch 00004: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 4s 574us/sample - loss: 0.5930 - accuracy: 0.7855 - val_loss: 0.6325 - val_accuracy: 0.7672\n",
      "Epoch 5/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.5834 - accuracy: 0.7866\n",
      "Epoch 00005: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 4s 554us/sample - loss: 0.5833 - accuracy: 0.7867 - val_loss: 0.6319 - val_accuracy: 0.7685\n",
      "Epoch 6/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.5796 - accuracy: 0.7867\n",
      "Epoch 00006: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 4s 551us/sample - loss: 0.5802 - accuracy: 0.7864 - val_loss: 0.6465 - val_accuracy: 0.7660\n",
      "Epoch 7/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.5685 - accuracy: 0.7883\n",
      "Epoch 00007: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 4s 546us/sample - loss: 0.5676 - accuracy: 0.7886 - val_loss: 0.6631 - val_accuracy: 0.7682\n",
      "Epoch 8/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.5580 - accuracy: 0.7895\n",
      "Epoch 00008: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 4s 562us/sample - loss: 0.5580 - accuracy: 0.7895 - val_loss: 0.6418 - val_accuracy: 0.7701\n",
      "Epoch 9/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.5551 - accuracy: 0.7906\n",
      "Epoch 00009: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 4s 550us/sample - loss: 0.5545 - accuracy: 0.7908 - val_loss: 0.6605 - val_accuracy: 0.7748\n",
      "Epoch 10/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.5555 - accuracy: 0.7898\n",
      "Epoch 00010: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 4s 544us/sample - loss: 0.5542 - accuracy: 0.7903 - val_loss: 0.6245 - val_accuracy: 0.7682\n",
      "3162/3162 - 1s - loss: 0.6245 - accuracy: 0.7682\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B907810D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B907810D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-2\\assets\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_46 (Conv1D)           (None, 559, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 279, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 277, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 138, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 138, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 17664)             0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 64)                1130560   \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 1,182,828\n",
      "Trainable params: 1,182,828\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4898 - accuracy: 0.0085\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 1.0614 - accuracy: 0.6441\n",
      "Epoch 00001: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-3.ckpt\n",
      "7767/7767 [==============================] - 5s 652us/sample - loss: 1.0602 - accuracy: 0.6445 - val_loss: 0.7339 - val_accuracy: 0.8052\n",
      "Epoch 2/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.6574 - accuracy: 0.8615\n",
      "Epoch 00002: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-3.ckpt\n",
      "7767/7767 [==============================] - 4s 561us/sample - loss: 0.6583 - accuracy: 0.8617 - val_loss: 0.6740 - val_accuracy: 0.8855\n",
      "Epoch 3/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.6108 - accuracy: 0.8996\n",
      "Epoch 00003: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-3.ckpt\n",
      "7767/7767 [==============================] - 4s 550us/sample - loss: 0.6106 - accuracy: 0.8996 - val_loss: 0.6525 - val_accuracy: 0.8858\n",
      "Epoch 4/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.5792 - accuracy: 0.9191\n",
      "Epoch 00004: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-3.ckpt\n",
      "7767/7767 [==============================] - 4s 558us/sample - loss: 0.5805 - accuracy: 0.9193 - val_loss: 0.6654 - val_accuracy: 0.8849\n",
      "Epoch 5/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.5673 - accuracy: 0.9270\n",
      "Epoch 00005: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-3.ckpt\n",
      "7767/7767 [==============================] - 4s 550us/sample - loss: 0.5660 - accuracy: 0.9273 - val_loss: 0.7060 - val_accuracy: 0.8773\n",
      "Epoch 6/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.5566 - accuracy: 0.9314 ETA: 0s - loss: 0.5480 - ac\n",
      "Epoch 00006: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-3.ckpt\n",
      "7767/7767 [==============================] - 4s 553us/sample - loss: 0.5588 - accuracy: 0.9315 - val_loss: 0.6806 - val_accuracy: 0.9042\n",
      "Epoch 7/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.5561 - accuracy: 0.9339\n",
      "Epoch 00007: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-3.ckpt\n",
      "7767/7767 [==============================] - 4s 569us/sample - loss: 0.5540 - accuracy: 0.9343 - val_loss: 0.6544 - val_accuracy: 0.9152\n",
      "Epoch 8/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.5455 - accuracy: 0.9379\n",
      "Epoch 00008: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-3.ckpt\n",
      "7767/7767 [==============================] - 4s 571us/sample - loss: 0.5478 - accuracy: 0.9373 - val_loss: 0.6497 - val_accuracy: 0.8903\n",
      "Epoch 9/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.5391 - accuracy: 0.9419\n",
      "Epoch 00009: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-3.ckpt\n",
      "7767/7767 [==============================] - 4s 543us/sample - loss: 0.5394 - accuracy: 0.9419 - val_loss: 0.6825 - val_accuracy: 0.9061\n",
      "Epoch 10/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.5350 - accuracy: 0.9441\n",
      "Epoch 00010: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-3.ckpt\n",
      "7767/7767 [==============================] - 4s 565us/sample - loss: 0.5349 - accuracy: 0.9439 - val_loss: 0.6810 - val_accuracy: 0.8899\n",
      "3162/3162 - 1s - loss: 0.6810 - accuracy: 0.8899\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B4D3BC708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B4D3BC708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-3\\assets\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_48 (Conv1D)           (None, 559, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 279, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 277, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 138, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 138, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_24 (Flatten)         (None, 17664)             0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 64)                1130560   \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 1,182,828\n",
      "Trainable params: 1,182,828\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4979 - accuracy: 0.1167\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.6641 - accuracy: 0.7614\n",
      "Epoch 00001: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-4.ckpt\n",
      "7767/7767 [==============================] - 5s 707us/sample - loss: 0.6592 - accuracy: 0.7625 - val_loss: 0.3752 - val_accuracy: 0.8552\n",
      "Epoch 2/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 0.2277 - accuracy: 0.9202 ETA: 1s - loss: 0.2441 - \n",
      "Epoch 00002: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-4.ckpt\n",
      "7767/7767 [==============================] - 5s 585us/sample - loss: 0.2272 - accuracy: 0.9204 - val_loss: 0.2484 - val_accuracy: 0.9064\n",
      "Epoch 3/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.1519 - accuracy: 0.9470\n",
      "Epoch 00003: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-4.ckpt\n",
      "7767/7767 [==============================] - 4s 577us/sample - loss: 0.1523 - accuracy: 0.9468 - val_loss: 0.1848 - val_accuracy: 0.9371\n",
      "Epoch 4/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.1291 - accuracy: 0.9549\n",
      "Epoch 00004: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-4.ckpt\n",
      "7767/7767 [==============================] - 4s 570us/sample - loss: 0.1296 - accuracy: 0.9547 - val_loss: 0.2125 - val_accuracy: 0.9295\n",
      "Epoch 5/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.1221 - accuracy: 0.9604\n",
      "Epoch 00005: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-4.ckpt\n",
      "7767/7767 [==============================] - 4s 568us/sample - loss: 0.1218 - accuracy: 0.9605 - val_loss: 0.1761 - val_accuracy: 0.9377\n",
      "Epoch 6/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.1111 - accuracy: 0.9616\n",
      "Epoch 00006: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-4.ckpt\n",
      "7767/7767 [==============================] - 5s 583us/sample - loss: 0.1120 - accuracy: 0.9614 - val_loss: 0.2333 - val_accuracy: 0.9203\n",
      "Epoch 7/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.1003 - accuracy: 0.9659\n",
      "Epoch 00007: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-4.ckpt\n",
      "7767/7767 [==============================] - 4s 554us/sample - loss: 0.0999 - accuracy: 0.9660 - val_loss: 0.2446 - val_accuracy: 0.9187\n",
      "Epoch 8/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.0872 - accuracy: 0.9699\n",
      "Epoch 00008: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-4.ckpt\n",
      "7767/7767 [==============================] - 4s 547us/sample - loss: 0.0868 - accuracy: 0.9701 - val_loss: 0.2395 - val_accuracy: 0.9241\n",
      "Epoch 9/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.0749 - accuracy: 0.9761\n",
      "Epoch 00009: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-4.ckpt\n",
      "7767/7767 [==============================] - 4s 549us/sample - loss: 0.0744 - accuracy: 0.9763 - val_loss: 0.2073 - val_accuracy: 0.9355\n",
      "Epoch 10/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.0737 - accuracy: 0.9734 ETA: 0s - loss: 0.0709 - ac\n",
      "Epoch 00010: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-4.ckpt\n",
      "7767/7767 [==============================] - 4s 561us/sample - loss: 0.0740 - accuracy: 0.9732 - val_loss: 0.1867 - val_accuracy: 0.9399\n",
      "3162/3162 - 1s - loss: 0.1867 - accuracy: 0.9399\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B9072DEE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B9072DEE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-4\\assets\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_50 (Conv1D)           (None, 559, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 279, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 277, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 138, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 138, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_25 (Flatten)         (None, 17664)             0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 64)                1130560   \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 1,182,828\n",
      "Trainable params: 1,182,828\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4760 - accuracy: 0.0629\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.6436 - accuracy: 0.7659\n",
      "Epoch 00001: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-5.ckpt\n",
      "7767/7767 [==============================] - 5s 643us/sample - loss: 0.6418 - accuracy: 0.7666 - val_loss: 0.3357 - val_accuracy: 0.8890\n",
      "Epoch 2/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.2278 - accuracy: 0.9214\n",
      "Epoch 00002: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-5.ckpt\n",
      "7767/7767 [==============================] - 4s 564us/sample - loss: 0.2284 - accuracy: 0.9211 - val_loss: 0.3307 - val_accuracy: 0.8805\n",
      "Epoch 3/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.1806 - accuracy: 0.9380\n",
      "Epoch 00003: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-5.ckpt\n",
      "7767/7767 [==============================] - 4s 568us/sample - loss: 0.1803 - accuracy: 0.9381 - val_loss: 0.2423 - val_accuracy: 0.9127\n",
      "Epoch 4/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.1411 - accuracy: 0.9514\n",
      "Epoch 00004: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-5.ckpt\n",
      "7767/7767 [==============================] - 4s 563us/sample - loss: 0.1404 - accuracy: 0.9517 - val_loss: 0.2617 - val_accuracy: 0.9130\n",
      "Epoch 5/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.1263 - accuracy: 0.9570\n",
      "Epoch 00005: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-5.ckpt\n",
      "7767/7767 [==============================] - 5s 606us/sample - loss: 0.1262 - accuracy: 0.9569 - val_loss: 0.2271 - val_accuracy: 0.9266\n",
      "Epoch 6/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 0.1154 - accuracy: 0.9585\n",
      "Epoch 00006: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-5.ckpt\n",
      "7767/7767 [==============================] - 5s 654us/sample - loss: 0.1162 - accuracy: 0.9584 - val_loss: 0.2941 - val_accuracy: 0.9080\n",
      "Epoch 7/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 0.0994 - accuracy: 0.9637\n",
      "Epoch 00007: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-5.ckpt\n",
      "7767/7767 [==============================] - 5s 623us/sample - loss: 0.0992 - accuracy: 0.9638 - val_loss: 0.2173 - val_accuracy: 0.9288\n",
      "Epoch 8/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.0904 - accuracy: 0.9665\n",
      "Epoch 00008: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-5.ckpt\n",
      "7767/7767 [==============================] - 4s 571us/sample - loss: 0.0905 - accuracy: 0.9664 - val_loss: 0.2326 - val_accuracy: 0.9288\n",
      "Epoch 9/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.0872 - accuracy: 0.9700\n",
      "Epoch 00009: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-5.ckpt\n",
      "7767/7767 [==============================] - 4s 544us/sample - loss: 0.0870 - accuracy: 0.9701 - val_loss: 0.2238 - val_accuracy: 0.9323\n",
      "Epoch 10/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.0714 - accuracy: 0.9750\n",
      "Epoch 00010: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-5.ckpt\n",
      "7767/7767 [==============================] - 4s 545us/sample - loss: 0.0710 - accuracy: 0.9752 - val_loss: 0.2326 - val_accuracy: 0.9326\n",
      "3162/3162 - 1s - loss: 0.2326 - accuracy: 0.9326\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B907F6F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B907F6F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-5\\assets\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_52 (Conv1D)           (None, 559, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 279, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 277, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 138, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 138, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_26 (Flatten)         (None, 17664)             0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 64)                1130560   \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 1,182,828\n",
      "Trainable params: 1,182,828\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4860 - accuracy: 0.0155\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.7955 - accuracy: 0.7122\n",
      "Epoch 00001: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-6.ckpt\n",
      "7767/7767 [==============================] - 5s 607us/sample - loss: 0.7881 - accuracy: 0.7148 - val_loss: 0.3901 - val_accuracy: 0.8590\n",
      "Epoch 2/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.2622 - accuracy: 0.9064\n",
      "Epoch 00002: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-6.ckpt\n",
      "7767/7767 [==============================] - 4s 563us/sample - loss: 0.2628 - accuracy: 0.9063 - val_loss: 0.3888 - val_accuracy: 0.8656\n",
      "Epoch 3/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.2180 - accuracy: 0.9212 ETA: 0s - loss: 0.2199 - accuracy: 0.92\n",
      "Epoch 00003: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-6.ckpt\n",
      "7767/7767 [==============================] - 4s 578us/sample - loss: 0.2168 - accuracy: 0.9217 - val_loss: 0.3337 - val_accuracy: 0.8710\n",
      "Epoch 4/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.1856 - accuracy: 0.9332\n",
      "Epoch 00004: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-6.ckpt\n",
      "7767/7767 [==============================] - 4s 573us/sample - loss: 0.1843 - accuracy: 0.9337 - val_loss: 0.2700 - val_accuracy: 0.9026\n",
      "Epoch 5/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 0.1680 - accuracy: 0.9388\n",
      "Epoch 00005: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-6.ckpt\n",
      "7767/7767 [==============================] - 4s 568us/sample - loss: 0.1676 - accuracy: 0.9390 - val_loss: 0.2539 - val_accuracy: 0.9124\n",
      "Epoch 6/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.1579 - accuracy: 0.9428\n",
      "Epoch 00006: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-6.ckpt\n",
      "7767/7767 [==============================] - 4s 563us/sample - loss: 0.1589 - accuracy: 0.9424 - val_loss: 0.3570 - val_accuracy: 0.8786\n",
      "Epoch 7/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.1627 - accuracy: 0.9389\n",
      "Epoch 00007: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-6.ckpt\n",
      "7767/7767 [==============================] - 4s 565us/sample - loss: 0.1625 - accuracy: 0.9390 - val_loss: 0.2798 - val_accuracy: 0.9013\n",
      "Epoch 8/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.1503 - accuracy: 0.9451\n",
      "Epoch 00008: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-6.ckpt\n",
      "7767/7767 [==============================] - 4s 554us/sample - loss: 0.1509 - accuracy: 0.9446 - val_loss: 0.2760 - val_accuracy: 0.9105\n",
      "Epoch 9/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.1420 - accuracy: 0.9483\n",
      "Epoch 00009: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-6.ckpt\n",
      "7767/7767 [==============================] - 4s 549us/sample - loss: 0.1423 - accuracy: 0.9482 - val_loss: 0.2292 - val_accuracy: 0.9181\n",
      "Epoch 10/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.1362 - accuracy: 0.9498\n",
      "Epoch 00010: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-6.ckpt\n",
      "7767/7767 [==============================] - 4s 548us/sample - loss: 0.1358 - accuracy: 0.9500 - val_loss: 0.2673 - val_accuracy: 0.9175\n",
      "3162/3162 - 1s - loss: 0.2673 - accuracy: 0.9175\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B90377168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B90377168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-6\\assets\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_54 (Conv1D)           (None, 559, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 279, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 277, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 138, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 138, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_27 (Flatten)         (None, 17664)             0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 64)                1130560   \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 1,182,828\n",
      "Trainable params: 1,182,828\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4836 - accuracy: 0.0655\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 1.9985 - accuracy: 0.3786\n",
      "Epoch 00001: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-7.ckpt\n",
      "7767/7767 [==============================] - 5s 619us/sample - loss: 1.9977 - accuracy: 0.3794 - val_loss: 1.9061 - val_accuracy: 0.4339\n",
      "Epoch 2/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 1.8558 - accuracy: 0.4353\n",
      "Epoch 00002: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-7.ckpt\n",
      "7767/7767 [==============================] - 4s 554us/sample - loss: 1.8554 - accuracy: 0.4356 - val_loss: 1.8721 - val_accuracy: 0.4412\n",
      "Epoch 3/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 1.8255 - accuracy: 0.4463\n",
      "Epoch 00003: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-7.ckpt\n",
      "7767/7767 [==============================] - 4s 545us/sample - loss: 1.8263 - accuracy: 0.4459 - val_loss: 1.8763 - val_accuracy: 0.4342\n",
      "Epoch 4/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 1.8065 - accuracy: 0.4528\n",
      "Epoch 00004: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-7.ckpt\n",
      "7767/7767 [==============================] - 4s 553us/sample - loss: 1.8057 - accuracy: 0.4531 - val_loss: 1.8497 - val_accuracy: 0.4428\n",
      "Epoch 5/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 1.7883 - accuracy: 0.4559\n",
      "Epoch 00005: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-7.ckpt\n",
      "7767/7767 [==============================] - 4s 547us/sample - loss: 1.7888 - accuracy: 0.4555 - val_loss: 1.8710 - val_accuracy: 0.4298\n",
      "Epoch 6/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 1.7899 - accuracy: 0.4547\n",
      "Epoch 00006: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-7.ckpt\n",
      "7767/7767 [==============================] - 4s 541us/sample - loss: 1.7906 - accuracy: 0.4550 - val_loss: 1.8598 - val_accuracy: 0.4358\n",
      "Epoch 7/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 1.7831 - accuracy: 0.4546\n",
      "Epoch 00007: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-7.ckpt\n",
      "7767/7767 [==============================] - 4s 546us/sample - loss: 1.7804 - accuracy: 0.4554 - val_loss: 1.8329 - val_accuracy: 0.4386\n",
      "Epoch 8/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 1.7817 - accuracy: 0.4549\n",
      "Epoch 00008: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-7.ckpt\n",
      "7767/7767 [==============================] - 4s 544us/sample - loss: 1.7805 - accuracy: 0.4559 - val_loss: 1.8293 - val_accuracy: 0.4437\n",
      "Epoch 9/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 1.7773 - accuracy: 0.4578\n",
      "Epoch 00009: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-7.ckpt\n",
      "7767/7767 [==============================] - 4s 542us/sample - loss: 1.7761 - accuracy: 0.4573 - val_loss: 1.8603 - val_accuracy: 0.4320\n",
      "Epoch 10/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 1.7707 - accuracy: 0.4572\n",
      "Epoch 00010: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-7.ckpt\n",
      "7767/7767 [==============================] - 4s 555us/sample - loss: 1.7695 - accuracy: 0.4578 - val_loss: 1.8709 - val_accuracy: 0.4307\n",
      "3162/3162 - 1s - loss: 1.8709 - accuracy: 0.4307\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B906FC678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B906FC678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-7\\assets\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_56 (Conv1D)           (None, 559, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 279, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 277, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 138, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 138, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_28 (Flatten)         (None, 17664)             0         \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 64)                1130560   \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 1,182,828\n",
      "Trainable params: 1,182,828\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4815 - accuracy: 0.2015\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 1.2529 - accuracy: 0.5985 ETA: 0s - loss: 1.2574 - accuracy: 0.\n",
      "Epoch 00001: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-8.ckpt\n",
      "7767/7767 [==============================] - 5s 643us/sample - loss: 1.2501 - accuracy: 0.6007 - val_loss: 1.0582 - val_accuracy: 0.7672\n",
      "Epoch 2/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.9737 - accuracy: 0.7530\n",
      "Epoch 00002: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-8.ckpt\n",
      "7767/7767 [==============================] - 4s 560us/sample - loss: 0.9740 - accuracy: 0.7529 - val_loss: 1.0122 - val_accuracy: 0.7609\n",
      "Epoch 3/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.9266 - accuracy: 0.7765 ETA: 0s - loss: 0.928\n",
      "Epoch 00003: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-8.ckpt\n",
      "7767/7767 [==============================] - 4s 558us/sample - loss: 0.9288 - accuracy: 0.7757 - val_loss: 0.9678 - val_accuracy: 0.7663\n",
      "Epoch 4/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 0.9111 - accuracy: 0.7873\n",
      "Epoch 00004: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-8.ckpt\n",
      "7767/7767 [==============================] - 4s 563us/sample - loss: 0.9108 - accuracy: 0.7873 - val_loss: 0.9684 - val_accuracy: 0.7774\n",
      "Epoch 5/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.9007 - accuracy: 0.7941\n",
      "Epoch 00005: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-8.ckpt\n",
      "7767/7767 [==============================] - 4s 551us/sample - loss: 0.9000 - accuracy: 0.7939 - val_loss: 0.9654 - val_accuracy: 0.7830\n",
      "Epoch 6/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.8872 - accuracy: 0.7995\n",
      "Epoch 00006: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-8.ckpt\n",
      "7767/7767 [==============================] - 4s 550us/sample - loss: 0.8874 - accuracy: 0.7995 - val_loss: 0.9643 - val_accuracy: 0.7821\n",
      "Epoch 7/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.8801 - accuracy: 0.8022\n",
      "Epoch 00007: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-8.ckpt\n",
      "7767/7767 [==============================] - 4s 572us/sample - loss: 0.8809 - accuracy: 0.8016 - val_loss: 1.0075 - val_accuracy: 0.7552\n",
      "Epoch 8/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.8790 - accuracy: 0.8054\n",
      "Epoch 00008: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-8.ckpt\n",
      "7767/7767 [==============================] - 4s 569us/sample - loss: 0.8738 - accuracy: 0.8067 - val_loss: 0.9524 - val_accuracy: 0.7824\n",
      "Epoch 9/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.8723 - accuracy: 0.8073\n",
      "Epoch 00009: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-8.ckpt\n",
      "7767/7767 [==============================] - 5s 599us/sample - loss: 0.8734 - accuracy: 0.8069 - val_loss: 0.9488 - val_accuracy: 0.7865\n",
      "Epoch 10/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.8683 - accuracy: 0.8084\n",
      "Epoch 00010: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-8.ckpt\n",
      "7767/7767 [==============================] - 4s 546us/sample - loss: 0.8699 - accuracy: 0.8082 - val_loss: 0.9894 - val_accuracy: 0.7685\n",
      "3162/3162 - 1s - loss: 0.9894 - accuracy: 0.7685\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B369E8438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B369E8438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-8\\assets\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_58 (Conv1D)           (None, 559, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 279, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 277, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 138, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 138, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_29 (Flatten)         (None, 17664)             0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 64)                1130560   \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 1,182,828\n",
      "Trainable params: 1,182,828\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4827 - accuracy: 0.1629\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 0.6252 - accuracy: 0.7645 ETA: 0s - loss: 0.6547 - accura\n",
      "Epoch 00001: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-9.ckpt\n",
      "7767/7767 [==============================] - 5s 623us/sample - loss: 0.6248 - accuracy: 0.7646 - val_loss: 0.3781 - val_accuracy: 0.8438\n",
      "Epoch 2/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.2389 - accuracy: 0.9130\n",
      "Epoch 00002: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-9.ckpt\n",
      "7767/7767 [==============================] - 4s 569us/sample - loss: 0.2407 - accuracy: 0.9123 - val_loss: 0.4562 - val_accuracy: 0.8409\n",
      "Epoch 3/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 0.1909 - accuracy: 0.9314\n",
      "Epoch 00003: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-9.ckpt\n",
      "7767/7767 [==============================] - 4s 568us/sample - loss: 0.1912 - accuracy: 0.9312 - val_loss: 0.2485 - val_accuracy: 0.9184\n",
      "Epoch 4/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.1763 - accuracy: 0.9389\n",
      "Epoch 00004: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-9.ckpt\n",
      "7767/7767 [==============================] - 4s 579us/sample - loss: 0.1763 - accuracy: 0.9390 - val_loss: 0.2578 - val_accuracy: 0.9083\n",
      "Epoch 5/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.1558 - accuracy: 0.9428\n",
      "Epoch 00005: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-9.ckpt\n",
      "7767/7767 [==============================] - 5s 584us/sample - loss: 0.1551 - accuracy: 0.9431 - val_loss: 0.2598 - val_accuracy: 0.9152\n",
      "Epoch 6/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 0.1368 - accuracy: 0.9512\n",
      "Epoch 00006: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-9.ckpt\n",
      "7767/7767 [==============================] - 5s 588us/sample - loss: 0.1364 - accuracy: 0.9513 - val_loss: 0.2307 - val_accuracy: 0.9228\n",
      "Epoch 7/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.1306 - accuracy: 0.9549\n",
      "Epoch 00007: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-9.ckpt\n",
      "7767/7767 [==============================] - 5s 586us/sample - loss: 0.1305 - accuracy: 0.9549 - val_loss: 0.2544 - val_accuracy: 0.9171\n",
      "Epoch 8/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.1254 - accuracy: 0.9559 ETA: 0s - loss: 0.1315 - accura - ETA: 0s - loss: 0.1280 \n",
      "Epoch 00008: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-9.ckpt\n",
      "7767/7767 [==============================] - 5s 584us/sample - loss: 0.1263 - accuracy: 0.9557 - val_loss: 0.2489 - val_accuracy: 0.9194\n",
      "Epoch 9/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.1288 - accuracy: 0.9567\n",
      "Epoch 00009: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-9.ckpt\n",
      "7767/7767 [==============================] - 5s 597us/sample - loss: 0.1285 - accuracy: 0.9570 - val_loss: 0.2409 - val_accuracy: 0.9254\n",
      "Epoch 10/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.1125 - accuracy: 0.9621\n",
      "Epoch 00010: saving model to checkpoints\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-9.ckpt\n",
      "7767/7767 [==============================] - 5s 593us/sample - loss: 0.1126 - accuracy: 0.9620 - val_loss: 0.3629 - val_accuracy: 0.9010\n",
      "3162/3162 - 1s - loss: 0.3629 - accuracy: 0.9010\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B906EC4C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B906EC4C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-9\\assets\n"
     ]
    }
   ],
   "source": [
    "filters_data = runner.test_param(filters=[32, 64, 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAfWUlEQVR4nO3defxcdX3v8debEAgGEHITlT2ALIFUEHMRKldZyhWUpa16BYUWjaVoCddWXGqsQjVXb7FaDF5TFYgLDVLUliouiEEMFiUgWwQsIpCwSCCBENYkvO8f50THH7/lJL/fzJmZ834+HvPIzNnmM7/JOZ/5Luf7lW0iIqK5Nqk7gIiIqFcSQUREwyURREQ0XBJBRETDJRFERDRcEkFERMMlEURfkrSXpJ9LelzSGZLmSfq7ct2hkpbVFNdZkr5ax3tHDGXTugOIaJP3AVfZfvlIG0q6G3iH7R+0PaqILpQSQfSrXYAl7X4TFXIeRU/Lf+DoO5J+CBwGnCdptaQ9Jc2X9LFBtv0KsDPwH+W27yuXHyTpJ5IelXSTpENb9rlK0hxJ1wBPArtJOkXSXWVV1K8lvbVirMdJWlK+z1WSprWse7+k+8pj3iHpiHL5gZIWS1ol6TeSPrXxf62IJILoQ7YPB34MnG57S9u/HGbbk4F7gWPLbf9B0g7At4GPAZOAM4GvS5rSsuvJwKnAVsBy4DPA0ba3Av4QuHGkOCXtCSwA3g1MAS6nSEibSdoLOB347+UxXwvcXe56LnCu7a2B3YFLRvyjRAwjiSDi+U4CLrd9ue3nbF8BLAZe17LNfNtLbK8F1gLPAdMlbWH7AdtVqqXeDHzb9hW21wCfBLagSCTrgM2BfSSNt3237V+V+60BXippsu3Vtq8dk08djZVEEPF8uwBvKqtrHpX0KHAIsF3LNkvXP7H9BMVF/TTgAUnflrR3hffZHrin5TjPlcfdwfadFCWFs4CHJF0safty05nAnsDtkq6TdMzGfcyIQhJBBAwcgncp8BXb27Q8Jtr+xFD72P6e7SMpksXtwBcqvO/9FEkHKBqegZ2A+8pj/ovtQ8ptDPzfcvl/2T4ReFG57FJJE6t/3Ijfl0QQAb8Bdmt5/VXgWEmvlTRO0oTy3oMdB9tZ0ovLRt+JwDPAaoqqnZFcArxe0hGSxgPvKff/SXkfxOGSNgeeBp5af0xJJ0maUpYgHi2PVeX9IgaVRBABHwc+VFYDnWl7KXA88EGKhuClwHsZ+nzZhOIifj+wAngN8K6R3tT2HRTtEXOBh4FjKRqtn6VoH/hEufxBil//Hyx3PQpYImk1RcPxCbaf3tAPHbGeMjFNRESzpUQQEdFwSQQREQ2XRBAR0XBJBBERDddzo49OnjzZU6dOrTuMiIiecv311z9se8pg63ouEUydOpXFixfXHUZE9IkFCxYwZ84cbrvtNqZNm8bs2bM58cQT6w5rzEm6Z6h1PZcIIiLGyoIFC5g9ezbnn38+hxxyCIsWLWLmzJkAfZkMhtJz9xHMmDHDKRFExFiYPn06c+fO5bDDDvvtsoULFzJr1ixuvfXWGiMbe5Kutz1j0HVJBBHRVOPGjePpp59m/Pjxv122Zs0aJkyYwLp1/TVqx3CJIL2GIqKxpk2bxqJFi35v2aJFi5g2bdoQe/SnJIKIaKzZs2czc+ZMFi5cyJo1a1i4cCEzZ85k9uzZdYfWUWksjojGWt8gPGvWrN/2GpozZ06jGoohbQQREY2QNoKIiBhSEkFERMMlEURENFwSQUREwyURREQ0XBJBRETDJRFERDRc2xKBpAskPSRp0JGbJB0q6TFJN5aPD7crloiIGFo77yyeD5wHfHmYbX5s+5g2xhARESNoW4nA9tXAinYdPyIixkbdbQQHS7pJ0nck7TvURpJOlbRY0uLly5d3Mr6IiL5XZyK4AdjF9n7AXODfhtrQ9udtz7A9Y8qUQafcjIiIjVRbIrC9yvbq8vnlwHhJk+uKJyKiqWpLBJJeIknl8wPLWB6pK56IiKZqW68hSQuAQ4HJkpYBHwHGA9ieB7wReKektcBTwAnutTGxIyL6QNsSge1hZ3awfR5F99JGKQtBo5J8GRFjKTOUddhIF3FJudBHREfV3X00IiJqlkQQEdFwSQQREQ2XRBAR0XBJBBERDVcpEUiaKGmT8vmeko6TNL69oUVERCdULRFcDUyQtANwJfA2imGmIyKix1VNBLL9JPCnwFzbfwLs076wIiKiUyonAkkHA28Fvl0uy81oERF9oGoieDfwt8A3bS+RtBuwsG1RRUREx1T6VW/7R8CPAMpG44dtn9HOwCIiojOq9hr6F0lbS5oI/AK4Q9J7R9hnpMnrJekzku6UdLOkAzY8/IiIGK2qVUP72F4F/DFwObAzcPII+8wHjhpm/dHAHuXjVOBzFWOJqIWkMXlEdJuqiWB8ed/AHwP/bnsNMOwQmRUmrz8e+LIL1wLbSNquYjwRHWd7xEeV7SK6TdVE8M/A3cBE4GpJuwCrRvneOwBLW14vK5c9Tyavj4hon0qJwPZnbO9g+3XlL/h7gMNG+d6DlZEH/bmUyesjYrRStTe0Sr2GJL2QYqrJV5eLfgT8PfDYKN57GbBTy+sdgftHcbyIiCFlUqihVa0augB4HPhf5WMVcOEo3/sy4M/K3kMHAY/ZfmCUx6zVpEmTxuTXxmiPMWnSpJr/EhHRS6reHby77Te0vD5b0o3D7VBh8vrLgdcBdwJPUoxf1NNWrlzZFb8o+rX4GhHtUTURPCXpENuLACS9CnhquB0qTF5v4K8qvn9E202aNImVK1eO+jijScTbbrstK1YM19kuYuxVTQSnAV8u2woAVgJ/3p6QIurRDSW6lOaiDlWHmLgJ2E/S1uXrVZLeDdzcxtgiIqIDNmiGMturyjuMAf6mDfFERESHjWaqypRhIyL6wGgSQf3dYyIiYtSGbSOQ9DiDX/AFbNGWiCIioqOGTQS2t+pUIBERUY/RVA1FREQfyLzDY8gf2RrOeuHIG3YijogG6YabAaF3bwhMIhhDOntV7TckQTl41ll1R9F7uiGRJ4lvnBVnrAO64W+3ru4ANoq64cK1IWbMmOHFixfXHcagumX0wm6Jo9d0w9+tG2LoRd3yd+uWOAYj6XrbMwZblxJBRIu6h3jYdttta33/aKa2NhZLOkrSHeUE9R8YZP2hkh6TdGP5+HA744kYTpWpKMdiqsrhHr1Yvxy9r20lAknjgM8CR1JMQnOdpMts/2LApj+2fUy74oiIiOG1s0RwIHCn7btsPwtcTDFhfUREdJF2JoKqk9MfLOkmSd+RtO9gB8rk9RER7dPORFBlcvobgF1s7wfMBf5tsANl8vqIiPZpZyIYcXL6cljr1eXzy4Hxkia3MaaIiBignYngOmAPSbtK2gw4gWLC+t+S9BKV/fUkHVjG80gbY4qIiAHa1mvI9lpJpwPfA8YBF9heIum0cv084I3AOyWtpZgD+QR3690YFdXdDx3SFz0iNkzuLO4y3XxnYows3189uuXv3i1xDGa4O4sz+mhERMMlEURENFwSQUREw2XQuYjoC+mosfGSCCKi541FA203N/S2WxJBREVVf3GOtF1TLzbRvZIIOqzKxSQXku6Uv3v0qySCDsvFJKIeY/EjDPrzHE4iiIhG6McL+FhJ99GIiIZLIoiIaLieG2tI0nLgnrrjaKPJwMN1BxEbLd9f7+r3724X24NO6NJziaDfSVo81MBQ0f3y/fWuJn93qRqKiGi4JIKIiIZLIug+n687gBiVfH+9q7HfXdoIIiIaLiWCiIiGSyKIiGi4JIKaSJog6WeSbpK0RNLZ5fJzJN0u6WZJ35S0Tc2hxhAkbSPp0vL7uk3SwS3rzpRkSZPrjDF+R9IFkh6SdGvLskHPN0njJX1J0i3ld/u3tQXeAUkE9XkGONz2fsD+wFGSDgKuAKbbfhnwS6Cv/wP2uHOB79reG9gPuA1A0k7AkcC9NcYWzzcfOGrAsqHOtzcBm9v+A+AVwF9KmtqhODsuiaAmLqwuX44vH7b9fdtry+XXAjvWEmAMS9LWwKuB8wFsP2v70XL1p4H3AemJ0UVsXw2sGLBsqPPNwERJmwJbAM8CqzoVa6clEdRI0jhJNwIPAVfY/umATd4OfKfjgUUVuwHLgQsl/VzSFyVNlHQccJ/tm2qOLzZc6/l2KfAE8ABFye6TtlcMtWOvSyKoke11tven+BVyoKTp69dJmg2sBS6qKbwY3qbAAcDnbL+c4qJxFjAb+HCNccVGGOR8OxBYB2wP7Aq8R9JuNYXXdkkEXaCsUriKsv5S0p8DxwBvdW706FbLgGUtpbhLKRLDrsBNku6mSPA3SHpJPSFGFUOcb2+haP9ZY/sh4Bqgb8chSiKoiaQpLT0UtgD+CLhd0lHA+4HjbD9ZY4gxDNsPAksl7VUuOgK4wfaLbE+1PZUiWRxQbhtdaJjz7V7gcBUmAgcBt9cRYydkhrL6bAd8SdI4ioR8ie1vSboT2By4opw271rbp9UYZwxtFnCRpM2Au4C31RxPDEPSAuBQYLKkZcBHKHoJDXa+fRa4ELgVEHCh7ZvriLsTMsRERETDpWooIqLhkggiIhouiSAiouGSCCIiGi6JICKi4ZIIIgYh6Yxy1MmVkj5QLjtL0pnl81MkbV9vlBFjI/cRRAzuXcDRtn89xPpTKPqY31/1gJI2bRngLKJrJBFEDCBpHsWgcpdJugDY3fbpLevfSDHcwEWSngIOBvYBPgVsCTwMnGL7AUlXAT8BXlUe716KG5nWAY/ZfnXnPlnE4JIIIgawfVo59MBhFGPQDFx/qaTTgTNtL5Y0HpgLHG97uaQ3A3MoRrME2Mb2awAk3QK81vZ9mXQoukUSQcTo7QVM53fDFIyjGL54va+1PL8GmC/pEuAbHYswYhhJBBGjJ2CJ7YOHWP/E+idlaeOVwOuBGyXtb/uRTgQZMZT0GorYOI8DW5XP7wCmrJ+zuJzvdt/BdpK0u+2f2v4wRVvCTh2JNmIYKRFEbJz5wLyWxuI3Ap+R9EKK8+qfgCWD7HeOpD0oShFXApnJLGqX0UcjIhouVUMREQ2XRBAR0XBJBBERDZdEEBHRcEkEERENl0QQEdFwSQQREQ2XRBAR0XBJBBERDZdEEBHRcEkEERENl0QQEdFwSQQREQ2XRBAR0XBJBBERDZdEEBHRcEkE0ZUk7SXp55Iel3SGpHmS/q5cd6ikZXXHGNEvMlVldKv3AVfZfvlIG0q6G3iH7R+0PaqIPpQSQXSrXRh8zt8xpULPnAeS8uMtxlzPnADRHJJ+CBwGnCdptaQ9Jc2X9LFBtv0KsDPwH+W27yuXHyTpJ5IelXSTpENb9rlK0hxJ1wBPArtJOkXSXWVV1K8lvXWI2A6U9J/lcR+QdJ6kzVrW7yvpCkkrJP1G0gfL5eMkfVDSr8r3uF7STpKmSnLrBb6M7x3l81MkXSPp05JWAGdJ2l3SDyU9IulhSRdJ2qZl/50kfUPS8nKb8yRtXsb0By3bvUjSU5KmbMz3FP0jiSC6ju3DgR8Dp9ve0vYvh9n2ZOBe4Nhy23+QtAPwbeBjwCTgTODrAy54JwOnAlsBy4HPAEfb3gr4Q+DGId5yHfDXwGTgYOAI4F0AkrYCfgB8F9geeClwZbnf3wAnAq8DtgbeTpGEqnglcBfwImAOIODj5XtMA3YCzipjGAd8C7gHmArsAFxs+xngYuCkluOeCPzA9vKKcUSfSiKIfnQScLnty20/Z/sKYDHFRXi9+baX2F4LrAWeA6ZL2sL2A7YHrZayfb3ta22vtX038M/Aa8rVxwAP2v5H20/bftz2T8t17wA+ZPsOF26y/UjFz3O/7bnlez5l+07bV9h+pryIf6olhgMpEsR7bT9RxrGoXPcl4C0tVWEnA1+pGEP0sSSC6Ee7AG8qq28elfQocAiwXcs2S9c/sf0E8GbgNOABSd+WtPdgBy6rqb4l6UFJq4D/Q1E6gOKX+a+GiGm4dSNZ2vqirNK5WNJ9ZQxfHRDDPWWC+z1lUnoCeE35+V4KXLaRMUUfSSKIfuABr5cCX7G9Tctjou1PDLWP7e/ZPpIiWdwOfGGI9/pcuX4P21sDH6Soqln/vrsPsd9Q654o/31By7KXDNhm4Of7eLnsZWUMJw2IYedhGpW/VG5/MnCp7aeH2C4aJIkg+sFvgN1aXn8VOFbSa8tG2gnlvQc7DrazpBdLOk7SROAZYDVFW8BgtgJWAavLX9XvbFn3LeAlkt5dNs5uJemV5bovAh+VtEfZU+llkv5bWbVzH3BSGevbGTqZtMawGni0bA95b8u6nwEPAJ+QNLH87K9qWf8V4E8oksGXR3ifaIgkgugHHwc+VFYDnWl7KXA8xa/15RS/kt/L0P/fNwHeA9wPrKCob3/XENueCbwFeJyi1PC19StsPw4cCRwLPAj8F0XvJyjq8S8Bvk+RSM4HtijX/UUZ3yPAvsBPRvi8ZwMHAI9RNIp/oyWGdeX7v5SiEX0ZRbXX+vXLgBsoShQ/HuF9oiFkDyx1RkQ/k3QBRQP0h+qOJbpDbk6JaBBJU4E/BUa8YzuaI1VDEQ0h6aPArcA5tn9ddzzRPVI1FBHRcCkRREQ0XM+1EUyePNlTp06tO4yIiJ5y/fXXP2x70HGlei4RTJ06lcWLF9cdRkRET5F0z1DrUjUUEdFwSQQREQ3Xc1VDEREbQ9LIG1XQjz0tkwgiohFGuoBL6suLfBVJBB02Fr9KmvqftW75RRn9Komgw/KrpHdV+V7y/dVj0qRJrFy5ctTHGW2y33bbbVmxYsWo4+i0JIKIUjdcTHr1QlK3lStXdkUCHqtSY6clEUSUuuFi0qsXkuht6T4aEdFwSQRjaNKkSUga1QMY9TEmTZpU818iInpJqobGUDdULUCqFyJiw6REEBHRcEkEERENl0QQEdFwSQQREQ2XRBAR0XBJBBERDTdi91FJxwCX236uA/FERGwwf2RrOOuFdYdRxNGDqtxHcAJwrqSvAxfavq3qwSUdBZwLjAO+aPsTA9a/EPgqsHMZyydtX1j1+BERADp7Vdfcw+Oz6o5iw41YNWT7JODlwK+ACyX9p6RTJW013H6SxgGfBY4G9gFOlLTPgM3+CviF7f2AQ4F/lLTZhn+MiIjYWJXaCGyvAr4OXAxsB/wJcIOkWcPsdiBwp+27bD9b7nv8wEMDW6m4FXZLYAWwdsM+QkREjMaIiUDSsZK+CfwQGA8caPtoYD/gzGF23QFY2vJ6Wbms1XnANOB+4Bbgfw/WFlGWQBZLWrx8+fKRQo6IiA1QpUTwJuDTtl9m+xzbDwHYfhJ4+zD7DTbgzcBKvNcCNwLbA/sD50l6XmuL7c/bnmF7xpQpUyqEHBERVVVJBB8Bfrb+haQtJE0FsH3lMPstA3Zqeb0jxS//Vm8DvuHCncCvgb0rxBQREWOkSiL4V6C1umZduWwk1wF7SNq1bAA+AbhswDb3AkcASHoxsBdwV4VjR0TEGKnSfXTTsrEXANvPVunZY3utpNOB71F0H73A9hJJp5Xr5wEfBeZLuoWiKun9th/emA8SMVrd0Be9V/uhR29ThcnUrwDm2r6sfH08cIbtIzoQ3/PMmDHDixcvruOtR9YFN7T81lmP1R1Bz+mGiee7IYZe1C1zcHTznNOSrrc9Y7B1VUoEpwEXSTqP4lf7UuDPxjC+vpGbWiLqMRbnXZOT8IiJwPavgIMkbUlRgni8/WFFRIytKqWGKtv0Y7KoNFWlpNcD+wIT1v+hbP99G+OKiBhT/XgBHytVbiibB7wZmEVRNfQmYJc2xxURER1SpfvoH9r+M2Cl7bOBg/n9+wMi+oakWh/bbrtt3X+CaKAqVUNPl/8+KWl74BFg1/aFFFGPNDhGU1VJBP8haRvgHOAGimEivtDOoCIionOGTQSSNgGutP0o8HVJ3wIm2E4n9YiIPjFsG0E5Eug/trx+JkkgIqK/VGks/r6kN6hbbt2LiIgxVaWN4G+AicBaSU9TdCG17QyKEhHRB6rcWTzslJQREdHbRkwEkl492HLbV499OBER0WlVqobe2/J8AsVcxNcDh7clooiI6KgqVUPHtr6WtBPwD22LKCIiOqpKr6GBlgHTxzqQiIioR5U2grn8btL5TSgmmb+pjTH1tG7oZZvxaiJiQ1RpI2idDmwtsMD2NW2Kp6dlrJqI6EVVEsGlwNO21wFIGifpBbafbG9oERHRCVXaCK4Etmh5vQXwgyoHl3SUpDsk3SnpA0Nsc6ikGyUtkfSjKseNqEOVYaSrbBfRbaqUCCbYXr3+he3Vkl4w0k6SxgGfBY6kaGC+TtJltn/Rss02wP8DjrJ9r6QXbegHiOiUVNlFv6pSInhC0gHrX0h6BfBUhf0OBO60fZftZ4GLgeMHbPMW4Bu27wWw/VC1sCMiYqxUKRG8G/hXSfeXr7ejmLpyJDsAS1teLwNeOWCbPYHxkq4CtgLOtf3lgQeSdCpwKsDOO+9c4a0jIqKqKjeUXSdpb2AvigHnbre9psKxB6sMHVi23hR4BXAERdvDf0q61vYvB8TweeDzADNmzEj5PCJiDFWZvP6vgIm2b7V9C7ClpHdVOPYyfn9u4x2B+wfZ5ru2n7D9MHA1sF+10CMiYixUaSP4i3KGMgBsrwT+osJ+1wF7SNpV0mbACcBlA7b5d+B/SNq0bIB+JXBbpcgjImJMVGkj2ESSXHaZKHsDbTbSTrbXSjod+B4wDrjA9hJJp5Xr59m+TdJ3gZuB54Av2r51Yz9MRERsuCqJ4HvAJZLmUdTxnwZ8p8rBbV8OXD5g2bwBr88BzqkUbUREjLkqieD9FD123knRAPxzip5DERHRB0ZsIygnsL8WuAuYQdHDJ/X4ERF9YsgSgaQ9KRp4TwQeAb4GYPuwzoQWERGdMFzV0O3Aj4Fjbd8JIOmvOxJVRER0zHBVQ28AHgQWSvqCpCMY/CaxiIjoYUMmAtvftP1mYG/gKuCvgRdL+pyk/9mh+CIios2qNBY/Yfsi28dQ3B18IzDokNIREdF7NmjOYtsrbP+z7cPbFVBERHTWxkxeHxERfaTKDWUxhqrMUDXSNpkgJSLGUhJBh+UiHhHdJlVDERENl0QQEdFwSQQREQ2XRBARjbZgwQKmT5/OuHHjmD59OgsWLKg7pI5LY3FENNaCBQuYPXs2559/PocccgiLFi1i5syZAJx44ok1R9c56rVeLDNmzPDixYvrDiMi+sD06dOZO3cuhx32u0GVFy5cyKxZs7j11v6aLFHS9bZnDLouiSAimmrcuHE8/fTTjB8//rfL1qxZw4QJE1i3bl2NkY294RJB2ggiorGmTZvGokWLfm/ZokWLmDZtWk0R1SOJICIaa/bs2cycOZOFCxeyZs0aFi5cyMyZM5k9e3bdoXVUGosjorHWNwjPmjWL2267jWnTpjFnzpxGNRRDD7YRSFoO3FN3HG00GXi47iBio+X76139/t3tYnvKYCt6LhH0O0mLh2rQie6X7693Nfm7SxtBRETDJRFERDRcEkH3+XzdAcSo5PvrXY397tJGEBHRcCkRREQ0XBJBRETDJRHURNIEST+TdJOkJZLOLpefI+l2STdL+qakbWoONYYgaRtJl5bf122SDm5Zd6YkS5pcZ4zxO5IukPSQpFtblg16vkkaL+lLkm4pv9u/rS3wDkgiqM8zwOG29wP2B46SdBBwBTDd9suAXwJ9/R+wx50LfNf23sB+wG0AknYCjgTurTG2eL75wFEDlg11vr0J2Nz2HwCvAP5S0tQOxdlxSQQ1cWF1+XJ8+bDt79teWy6/FtixlgBjWJK2Bl4NnA9g+1nbj5arPw28D0hPjC5i+2pgxYBlQ51vBiZK2hTYAngWWNWpWDstiaBGksZJuhF4CLjC9k8HbPJ24DsdDyyq2A1YDlwo6eeSvihpoqTjgPts31RzfLHhWs+3S4EngAcoSnaftL1iqB17XRJBjWyvs70/xa+QAyVNX79O0mxgLXBRTeHF8DYFDgA+Z/vlFBeNs4DZwIdrjCs2wiDn24HAOmB7YFfgPZJ2qym8tksi6AJllcJVlPWXkv4cOAZ4q3OjR7daBixrKcVdSpEYdgVuknQ3RYK/QdJL6gkxqhjifHsLRfvPGtsPAdcAfTsOURJBTSRNaemhsAXwR8Dtko4C3g8cZ/vJGkOMYdh+EFgqaa9y0RHADbZfZHuq7akUyeKActvoQsOcb/cCh6swETgIuL2OGDsh8xHUZzvgS5LGUSTkS2x/S9KdwObAFZIArrV9Wo1xxtBmARdJ2gy4C3hbzfHEMCQtAA4FJktaBnyEopfQYOfbZ4ELgVsBARfavrmOuDshQ0xERDRcqoYiIhouiSAiouGSCCIiGi6JICKi4ZIIIiIaLokgYhCSzihHnVwp6QPlsrMknVk+P0XS9vVGGTE2ch9BxODeBRxt+9dDrD+Foo/5/VUPKGnTlgHOIrpGEkHEAJLmUQwqd5mkC4DdbZ/esv6NFMMNXCTpKeBgYB/gU8CWwMPAKbYfkHQV8BPgVeXx7qW4kWkd8JjtV3fuk0UMLokgYgDbp5VDDxxGMQbNwPWXSjodONP2YknjgbnA8baXS3ozMIdiNEuAbWy/BkDSLcBrbd+XSYeiWyQRRIzeXsB0fjdMwTiK4YvX+1rL82uA+ZIuAb7RsQgjhpFEEDF6ApbYPniI9U+sf1KWNl4JvB64UdL+th/pRJARQ0mvoYiN8ziwVfn8DmDK+jmLy/lu9x1sJ0m72/6p7Q9TtCXs1JFoI4aREkHExpkPzGtpLH4j8BlJL6Q4r/4JWDLIfudI2oOiFHElkJnMonYZfTQiouFSNRQR0XBJBBERDZdEEBHRcEkEERENl0QQEdFwSQQREQ2XRBAR0XD/H3BjHR8zTg69AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#runner.print_results(filters_data, 'filters')\n",
    "runner.plot_results(filters_data, 'filters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_30 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4776 - accuracy: 0.1803\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 0.6946 - accuracy: 0.7601\n",
      "Epoch 00001: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-0.ckpt\n",
      "7767/7767 [==============================] - 3s 402us/sample - loss: 0.6929 - accuracy: 0.7607 - val_loss: 0.3431 - val_accuracy: 0.8741\n",
      "Epoch 2/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 0.2353 - accuracy: 0.9170\n",
      "Epoch 00002: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-0.ckpt\n",
      "7767/7767 [==============================] - 3s 346us/sample - loss: 0.2350 - accuracy: 0.9171 - val_loss: 0.3038 - val_accuracy: 0.8817\n",
      "Epoch 3/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.1791 - accuracy: 0.9362\n",
      "Epoch 00003: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-0.ckpt\n",
      "7767/7767 [==============================] - 3s 362us/sample - loss: 0.1780 - accuracy: 0.9367 - val_loss: 0.3256 - val_accuracy: 0.8805\n",
      "Epoch 4/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.1381 - accuracy: 0.9512\n",
      "Epoch 00004: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-0.ckpt\n",
      "7767/7767 [==============================] - 3s 345us/sample - loss: 0.1372 - accuracy: 0.9513 - val_loss: 0.2549 - val_accuracy: 0.9102\n",
      "Epoch 5/10\n",
      "7584/7767 [============================>.] - ETA: 0s - loss: 0.1391 - accuracy: 0.9475\n",
      "Epoch 00005: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-0.ckpt\n",
      "7767/7767 [==============================] - 3s 347us/sample - loss: 0.1385 - accuracy: 0.9479 - val_loss: 0.3005 - val_accuracy: 0.8931\n",
      "Epoch 6/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 0.1132 - accuracy: 0.9582\n",
      "Epoch 00006: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-0.ckpt\n",
      "7767/7767 [==============================] - 3s 359us/sample - loss: 0.1132 - accuracy: 0.9582 - val_loss: 0.2217 - val_accuracy: 0.9219\n",
      "Epoch 7/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 0.1035 - accuracy: 0.9615\n",
      "Epoch 00007: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-0.ckpt\n",
      "7767/7767 [==============================] - 3s 358us/sample - loss: 0.1050 - accuracy: 0.9610 - val_loss: 0.2386 - val_accuracy: 0.9219\n",
      "Epoch 8/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 0.0926 - accuracy: 0.9659\n",
      "Epoch 00008: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-0.ckpt\n",
      "7767/7767 [==============================] - 3s 359us/sample - loss: 0.0925 - accuracy: 0.9659 - val_loss: 0.2228 - val_accuracy: 0.9276\n",
      "Epoch 9/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.0933 - accuracy: 0.9639\n",
      "Epoch 00009: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-0.ckpt\n",
      "7767/7767 [==============================] - 3s 353us/sample - loss: 0.0938 - accuracy: 0.9637 - val_loss: 0.2436 - val_accuracy: 0.9241\n",
      "Epoch 10/10\n",
      "7584/7767 [============================>.] - ETA: 0s - loss: 0.0865 - accuracy: 0.9676\n",
      "Epoch 00010: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-0.ckpt\n",
      "7767/7767 [==============================] - 3s 343us/sample - loss: 0.0873 - accuracy: 0.9674 - val_loss: 0.3003 - val_accuracy: 0.9010\n",
      "3162/3162 - 0s - loss: 0.3003 - accuracy: 0.9010\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B9076D558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B9076D558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0_epochs-10_it-0\\assets\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_62 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_31 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4815 - accuracy: 0.0787\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 1.0045 - accuracy: 0.6960\n",
      "Epoch 00001: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-1.ckpt\n",
      "7767/7767 [==============================] - 3s 397us/sample - loss: 1.0033 - accuracy: 0.6964 - val_loss: 0.7781 - val_accuracy: 0.7274\n",
      "Epoch 2/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.6601 - accuracy: 0.7767\n",
      "Epoch 00002: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-1.ckpt\n",
      "7767/7767 [==============================] - 3s 359us/sample - loss: 0.6613 - accuracy: 0.7762 - val_loss: 0.6904 - val_accuracy: 0.7530\n",
      "Epoch 3/10\n",
      "7584/7767 [============================>.] - ETA: 0s - loss: 0.6143 - accuracy: 0.7814\n",
      "Epoch 00003: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-1.ckpt\n",
      "7767/7767 [==============================] - 3s 382us/sample - loss: 0.6134 - accuracy: 0.7816 - val_loss: 0.7551 - val_accuracy: 0.7356\n",
      "Epoch 4/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.5827 - accuracy: 0.7846\n",
      "Epoch 00004: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-1.ckpt\n",
      "7767/7767 [==============================] - 3s 350us/sample - loss: 0.5845 - accuracy: 0.7840 - val_loss: 0.6882 - val_accuracy: 0.7521\n",
      "Epoch 5/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.5704 - accuracy: 0.7837\n",
      "Epoch 00005: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-1.ckpt\n",
      "7767/7767 [==============================] - 3s 403us/sample - loss: 0.5705 - accuracy: 0.7840 - val_loss: 0.6649 - val_accuracy: 0.7634\n",
      "Epoch 6/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 0.5680 - accuracy: 0.7853\n",
      "Epoch 00006: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-1.ckpt\n",
      "7767/7767 [==============================] - 3s 349us/sample - loss: 0.5677 - accuracy: 0.7854 - val_loss: 0.7433 - val_accuracy: 0.7429\n",
      "Epoch 7/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.5584 - accuracy: 0.7858\n",
      "Epoch 00007: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-1.ckpt\n",
      "7767/7767 [==============================] - 3s 354us/sample - loss: 0.5572 - accuracy: 0.7864 - val_loss: 0.6981 - val_accuracy: 0.7603\n",
      "Epoch 8/10\n",
      "7584/7767 [============================>.] - ETA: 0s - loss: 0.5540 - accuracy: 0.7856\n",
      "Epoch 00008: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-1.ckpt\n",
      "7767/7767 [==============================] - 3s 362us/sample - loss: 0.5510 - accuracy: 0.7868 - val_loss: 0.8936 - val_accuracy: 0.7587\n",
      "Epoch 9/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.5543 - accuracy: 0.7850\n",
      "Epoch 00009: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-1.ckpt\n",
      "7767/7767 [==============================] - 3s 395us/sample - loss: 0.5528 - accuracy: 0.7856 - val_loss: 0.6748 - val_accuracy: 0.7593\n",
      "Epoch 10/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.5523 - accuracy: 0.7841\n",
      "Epoch 00010: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-1.ckpt\n",
      "7767/7767 [==============================] - 3s 354us/sample - loss: 0.5532 - accuracy: 0.7837 - val_loss: 0.6750 - val_accuracy: 0.7634\n",
      "3162/3162 - 0s - loss: 0.6750 - accuracy: 0.7634\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B9076D1F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000018B9076D1F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0_epochs-10_it-1\\assets\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_64 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_32 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4795 - accuracy: 0.1366\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 1.0557 - accuracy: 0.6209\n",
      "Epoch 00001: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 3s 395us/sample - loss: 1.0554 - accuracy: 0.6208 - val_loss: 0.8290 - val_accuracy: 0.6755\n",
      "Epoch 2/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.6854 - accuracy: 0.7289\n",
      "Epoch 00002: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 3s 340us/sample - loss: 0.6837 - accuracy: 0.7296 - val_loss: 0.7071 - val_accuracy: 0.7255\n",
      "Epoch 3/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.6351 - accuracy: 0.7509\n",
      "Epoch 00003: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 3s 351us/sample - loss: 0.6349 - accuracy: 0.7510 - val_loss: 0.7537 - val_accuracy: 0.7116\n",
      "Epoch 4/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.6131 - accuracy: 0.7568\n",
      "Epoch 00004: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 3s 342us/sample - loss: 0.6123 - accuracy: 0.7572 - val_loss: 0.7204 - val_accuracy: 0.7255\n",
      "Epoch 5/10\n",
      "7552/7767 [============================>.] - ETA: 0s - loss: 0.6038 - accuracy: 0.7590\n",
      "Epoch 00005: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.6023 - accuracy: 0.7598 - val_loss: 0.7140 - val_accuracy: 0.7287\n",
      "Epoch 6/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.5888 - accuracy: 0.7654\n",
      "Epoch 00006: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.5908 - accuracy: 0.7645 - val_loss: 0.6884 - val_accuracy: 0.7375\n",
      "Epoch 7/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 0.5907 - accuracy: 0.7644\n",
      "Epoch 00007: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.5904 - accuracy: 0.7646 - val_loss: 0.6938 - val_accuracy: 0.7350\n",
      "Epoch 8/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.5827 - accuracy: 0.7689\n",
      "Epoch 00008: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-2.ckpt\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Failed to rename: checkpoints\\checkpoint.tmp2d53b9e727f04fceb0948ecd331d9ce4 to: checkpoints\\checkpoint : Access is denied.\r\n; Input/output error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-3a538fe117fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdropout_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrunner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_param\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdropout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-544eae209a68>\u001b[0m in \u001b[0;36mtest_param\u001b[1;34m(self, filters, kernel_size, dropout, epochs)\u001b[0m\n\u001b[0;32m     51\u001b[0m                                                 \u001b[0mdropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m                                                 \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m                                                 it=i)\n\u001b[0m\u001b[0;32m     54\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mdata_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'epochs'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m                     loss, acc, time = run_model(test_data, test_labels, train_data, train_labels, predict=False,\n",
      "\u001b[1;32m<ipython-input-7-86e5126bfb3e>\u001b[0m in \u001b[0;36mrun_model\u001b[1;34m(test_data, test_labels, train_data, train_labels, filters, kernel_size, dropout, epochs, it, predict)\u001b[0m\n\u001b[0;32m     54\u001b[0m                   \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m                   \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m                 callbacks=[time_callback, cp_callback])\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    395\u001b[0m                       total_epochs=1)\n\u001b[0;32m    396\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[1;32m--> 397\u001b[1;33m                                  prefix='val_')\n\u001b[0m\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mon_epoch\u001b[1;34m(self, epoch, mode)\u001b[0m\n\u001b[0;32m    769\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m         \u001b[1;31m# Epochs only apply to `fit`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 771\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    772\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m       \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    990\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    991\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 992\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    993\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    994\u001b[0m       \u001b[1;31m# For multi-worker training, back up the weights and current training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   1036\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\nEpoch %05d: saving model to %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1037\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights_only\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1038\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1039\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36msave_weights\u001b[1;34m(self, filepath, overwrite, save_format)\u001b[0m\n\u001b[0;32m   1127\u001b[0m           \u001b[0mmodel_checkpoint_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m           \u001b[0msave_relative_paths\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1129\u001b[1;33m           all_model_checkpoint_paths=[filepath])\n\u001b[0m\u001b[0;32m   1130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskip_mismatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\training\\checkpoint_management.py\u001b[0m in \u001b[0;36mupdate_checkpoint_state_internal\u001b[1;34m(save_dir, model_checkpoint_path, all_model_checkpoint_paths, latest_filename, save_relative_paths, all_model_checkpoint_timestamps, last_preserved_timestamp)\u001b[0m\n\u001b[0;32m    239\u001b[0m   \u001b[1;31m# file.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m   file_io.atomic_write_string_to_file(coord_checkpoint_filename,\n\u001b[1;32m--> 241\u001b[1;33m                                       text_format.MessageToString(ckpt))\n\u001b[0m\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36matomic_write_string_to_file\u001b[1;34m(filename, contents, overwrite)\u001b[0m\n\u001b[0;32m    540\u001b[0m   \u001b[0mwrite_string_to_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_pathname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m     \u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_pathname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[0mdelete_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_pathname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mrename\u001b[1;34m(oldname, newname, overwrite)\u001b[0m\n\u001b[0;32m    502\u001b[0m     \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moperation\u001b[0m \u001b[0mfails\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m   \"\"\"\n\u001b[1;32m--> 504\u001b[1;33m   \u001b[0mrename_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moldname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    505\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mrename_v2\u001b[1;34m(src, dst, overwrite)\u001b[0m\n\u001b[0;32m    519\u001b[0m   \"\"\"\n\u001b[0;32m    520\u001b[0m   pywrap_tensorflow.RenameFile(\n\u001b[1;32m--> 521\u001b[1;33m       compat.as_bytes(src), compat.as_bytes(dst), overwrite)\n\u001b[0m\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: Failed to rename: checkpoints\\checkpoint.tmp2d53b9e727f04fceb0948ecd331d9ce4 to: checkpoints\\checkpoint : Access is denied.\r\n; Input/output error"
     ]
    }
   ],
   "source": [
    "dropout_data = runner.test_param(dropout = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runner.print_results(dropout_data, 'dropout')\n",
    "runner.plot_results(dropout_data, 'dropout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kernel_size_data = runner.test_param(kernel_size = [2,3,5,7,9,11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runner.print_results(kernel_size_data, 'kernel_size')\n",
    "runner.plot_results(kernel_size_data, 'kernel_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_data = runner.test_param()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.plot_results(default_data, 'default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
