{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#activity labels as defined in activity_labels.txt\n",
    "activity_labels = ['WALKING', 'WALKING_UPSTAIRS', 'WALKING_DOWNSTAIRS', 'SITTING', 'STANDING', 'LAYING', 'STAND_TO_SIT', 'SIT_TO_STAND', 'SIT_TO_LIE', 'LIE_TO_SIT', 'STAND_TO_LIE', 'LIE_TO_STAND']\n",
    "#activity_labels = {k:v for k,v in enumerate(activity_labels, start=1)}\n",
    "#print(activity_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshaping data...\n",
      "adjusting labels...\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "def load_data(path):\n",
    "    data = pd.read_csv(path, header=None, delim_whitespace=True)\n",
    "    return data.values\n",
    "\n",
    "def load_set(path, x, y):\n",
    "    data = load_data(path+x)\n",
    "    labels = load_data(path+y)\n",
    "    return data, labels\n",
    "\n",
    "#reduce the labels by 1 to match with the activity_labels and also to start labels at 0 to 11 instead of from 1 to 12\n",
    "def adjust_labels (labels):\n",
    "    for i in range(len(labels)-1):\n",
    "        labels[i][0] -= 1\n",
    "    return labels\n",
    "\n",
    "train_data, train_labels = load_set('HAPT Data Set/Train/', 'X_train.txt', 'y_train.txt')\n",
    "test_data, test_labels = load_set('HAPT Data Set/Test/', 'X_test.txt', 'y_test.txt')\n",
    "\n",
    "print('reshaping data...')\n",
    "#reshape the data to add a features dimension (features = 1)\n",
    "#https://stackoverflow.com/questions/43396572/dimension-of-shape-in-conv1d\n",
    "train_data = np.expand_dims(train_data, axis=2)\n",
    "test_data = np.expand_dims(test_data, axis=2)\n",
    "\n",
    "print('adjusting labels...')\n",
    "train_labels = adjust_labels(train_labels);\n",
    "test_labels = adjust_labels(test_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get time of epochs to record training time\n",
    "#https://stackoverflow.com/questions/43178668/record-the-computation-time-for-each-epoch-in-keras-during-model-fit\n",
    "class TimeHistory(callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out n number (pred_range) of predicted values and compare them with test labels\n",
    "def predict(pred_range, pred_outs, test_labels):\n",
    "    #test if the label matches the prediction\n",
    "    false_pred = 0\n",
    "    true_pred = 0\n",
    "    #look at predictions for the first 25 values\n",
    "    for i in range(pred_range):\n",
    "        if not (0 <= pred_outs[i] or pred_outs[i] <= 11):\n",
    "            print('prediction out of bounds')\n",
    "            break\n",
    "\n",
    "        print(f'Test label: {activity_labels[test_labels[i][0]]}')\n",
    "        print(f'Predicted label:{activity_labels[pred_outs[i]]}')\n",
    "\n",
    "        if pred_outs[i]==test_labels[i][0]:\n",
    "            print('true\\n')\n",
    "            true_pred += 1\n",
    "        else:\n",
    "            print('false\\n')\n",
    "            false_pred += 1\n",
    "    print(f'False predictions:{false_pred}')\n",
    "    print(f'True predictions:{true_pred}')\n",
    "    print(f'Prediction accuraccy for first 25 values: {true_pred/pred_range}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(test_data, test_labels, train_data, train_labels, filters, kernel_size, dropout, epochs, it='', predict=True):\n",
    "    save_path = f'filters-{filters}_kernel_size-{kernel_size}_dropout-{dropout}_epochs-{epochs}_it-{it}'\n",
    "    saved_model_path = f'saved_models\\\\{save_path}'\n",
    "    current_directory = os.path.abspath(os.getcwd())\n",
    "    training_time=-1   #denotes pre-trained model being loaded froms saved data\n",
    "    \n",
    "    if os.path.exists(os.path.join(current_directory,saved_model_path)) :\n",
    "        print(f'found saved model, loading from: {saved_model_path}')\n",
    "        model = models.load_model(saved_model_path)\n",
    "        test_loss,test_acc = model.evaluate( test_data, test_labels, verbose=2)\n",
    "    else:\n",
    "        #input shape\n",
    "        timesteps = train_data.shape[1] #561 timesteps\n",
    "        features = train_data.shape[2] #1 feature\n",
    "\n",
    "        #model\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Conv1D(filters=filters, kernel_size=kernel_size, strides=1, activation='relu', input_shape=(timesteps,features)))\n",
    "        model.add(layers.MaxPooling1D(pool_size=2))\n",
    "        model.add(layers.Conv1D(filters=filters, kernel_size=kernel_size, strides=1, activation='relu'))\n",
    "        model.add(layers.MaxPooling1D(pool_size=2))\n",
    "        model.add(layers.Dropout(dropout))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(64, activation='relu'))\n",
    "        model.add(layers.Dense(32, activation='relu'))\n",
    "        model.add(layers.Dense(12, activation='relu'))\n",
    "        model.summary()\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(optimizer='adam',\n",
    "                 loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                 metrics=['accuracy'])\n",
    "        #evaluate model\n",
    "        test_loss,test_acc = model.evaluate(test_data, test_labels, verbose=2)\n",
    "\n",
    "        if predict:\n",
    "            #predict\n",
    "            pred_outs = model.predict_classes(test_data)\n",
    "            #display predictions\n",
    "            predict(10, pred_outs, test_labels)\n",
    "\n",
    "        #train the model\n",
    "        #set up timing callback\n",
    "        time_callback = TimeHistory()\n",
    "\n",
    "        model.fit(train_data, \n",
    "                  train_labels, \n",
    "                  epochs=epochs, \n",
    "                  validation_data=(test_data, test_labels),\n",
    "                callbacks=[time_callback])\n",
    "\n",
    "        test_loss,test_acc = model.evaluate( test_data, test_labels, verbose=2)\n",
    "\n",
    "        training_time = sum(time_callback.times)\n",
    "\n",
    "        model.save(saved_model_path)\n",
    "    \n",
    "    return test_loss, test_acc, training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_unit_string(time):\n",
    "    return f\"Total training time: {math.floor(time/1)}s {math.floor(time%1 * 1000)}ms {math.ceil(time%(1/1000)*1000)}us\"\n",
    "\n",
    "class RunTests: \n",
    "    n_tests = 10\n",
    "    d_epochs = 10\n",
    "    d_filters = 64\n",
    "    d_kernel_size=3\n",
    "    d_dropout=0.5\n",
    "    \n",
    "    def test_param(self, filters=d_filters, kernel_size=d_kernel_size, dropout=d_dropout, epochs=d_epochs):\n",
    "        if isinstance(filters,list):\n",
    "            data = filters\n",
    "            data_type = 'filters'\n",
    "        elif isinstance(kernel_size,list):\n",
    "            data = kernel_size\n",
    "            data_type = 'kernel_size'\n",
    "        elif isinstance(dropout,list):\n",
    "            data = dropout\n",
    "            data_type = 'dropout'\n",
    "        elif isinstance(epochs,list):\n",
    "            data = epochs\n",
    "            data_type = 'epochs'\n",
    "        else:\n",
    "            print('no data type selected, running default...')\n",
    "            data = [1]\n",
    "            data_type = 'default'\n",
    "        \n",
    "        model_test_data = []\n",
    "        for index, item in enumerate(data):\n",
    "            model_test_data.append([])\n",
    "            for i in range(0,self.n_tests):\n",
    "                if data_type == 'filters':\n",
    "                    loss, acc, time = run_model(test_data, test_labels, train_data, train_labels, predict=False,\n",
    "                                                kernel_size=kernel_size, \n",
    "                                                filters=item, \n",
    "                                                dropout=dropout,\n",
    "                                                epochs=epochs,\n",
    "                                                it=i)\n",
    "                elif data_type == 'kernel_size':\n",
    "                    loss, acc, time = run_model(test_data, test_labels, train_data, train_labels, predict=False,\n",
    "                                                kernel_size=item, \n",
    "                                                filters=filters, \n",
    "                                                dropout=dropout,  \n",
    "                                                epochs=epochs,\n",
    "                                                it=i)\n",
    "                elif data_type == 'dropout':\n",
    "                    loss, acc, time = run_model(test_data, test_labels, train_data, train_labels, predict=False,\n",
    "                                                kernel_size=kernel_size, \n",
    "                                                filters=filters, \n",
    "                                                dropout=item,  \n",
    "                                                epochs=epochs,\n",
    "                                                it=i)\n",
    "                elif data_type == 'epochs':\n",
    "                    loss, acc, time = run_model(test_data, test_labels, train_data, train_labels, predict=False,\n",
    "                                                kernel_size=kernel_size, \n",
    "                                                filters=filters, \n",
    "                                                dropout=dropout,  \n",
    "                                                epochs=item,\n",
    "                                                it=i)\n",
    "                else:\n",
    "                    loss, acc, time = run_model(test_data, test_labels, train_data, train_labels, predict=False,\n",
    "                                                kernel_size=kernel_size, \n",
    "                                                filters=filters, \n",
    "                                                dropout=dropout,  \n",
    "                                                epochs=epochs,\n",
    "                                                it=i)\n",
    "                test_output = {'loss': loss, 'acc': acc, 'time': time, 'test parameter': item}\n",
    "                model_test_data[index].append(test_output)\n",
    "        return model_test_data\n",
    "\n",
    "    #data is a two-dimensional list\n",
    "    def print_results(self,data, data_name):\n",
    "        print(f\"{data_name} test data:\")\n",
    "        for test in data:\n",
    "            for i in range(0,self.n_tests):\n",
    "                print(f\"{data_name}: {test[i].get('test parameter')}\")\n",
    "                print(f\"\\tloss: {test[i].get('loss')}\")\n",
    "                print(f\"\\taccuracy: {test[i].get('acc')}\")\n",
    "            print(\"\\n\")\n",
    "    \n",
    "    def plot_results(self, data, data_name):\n",
    "        loss=[]\n",
    "        acc=[]\n",
    "        param=[]\n",
    "        for index, test in enumerate(data):\n",
    "            param.append(test[0].get('test parameter'))\n",
    "            loss.append([])\n",
    "            acc.append([])\n",
    "            for i in range(0,self.n_tests):\n",
    "                loss[index].append(test[i].get('loss'))\n",
    "                acc[index].append(test[i].get('acc'))\n",
    "        \n",
    "        fig, axs = plt.subplots(2)\n",
    "        axs[0].set_title(f'{data_name} loss')\n",
    "        axs[0].set(xlabel=data_name, ylabel='Loss')\n",
    "        axs[0].boxplot(loss)\n",
    "        axs[0].set_xticklabels(param)\n",
    "        \n",
    "        axs[1].set_title(f'{data_name} accuracy')\n",
    "        axs[1].set(xlabel=data_name, ylabel='Accuracy')\n",
    "        axs[1].boxplot(acc)\n",
    "        axs[1].set_xticklabels(param)\n",
    "        \n",
    "        fig.subplots_adjust(hspace=0.8)\n",
    "        \n",
    "        plt.show\n",
    "        \n",
    "runner = RunTests() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found saved model, loading from: saved_models\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-0\n",
      "3162/3162 - 0s - loss: 0.2155 - accuracy: 0.9244\n",
      "found saved model, loading from: saved_models\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-1\n",
      "3162/3162 - 0s - loss: 0.3336 - accuracy: 0.8861\n",
      "found saved model, loading from: saved_models\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-2\n",
      "3162/3162 - 0s - loss: 1.0572 - accuracy: 0.5765\n",
      "found saved model, loading from: saved_models\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-3\n",
      "3162/3162 - 0s - loss: 0.6840 - accuracy: 0.7495\n",
      "found saved model, loading from: saved_models\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-4\n",
      "3162/3162 - 0s - loss: 1.0180 - accuracy: 0.6078\n",
      "found saved model, loading from: saved_models\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-5\n",
      "3162/3162 - 0s - loss: 0.6288 - accuracy: 0.7846\n",
      "found saved model, loading from: saved_models\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-6\n",
      "3162/3162 - 0s - loss: 0.6670 - accuracy: 0.8893\n",
      "found saved model, loading from: saved_models\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-7\n",
      "3162/3162 - 0s - loss: 0.6989 - accuracy: 0.7407\n",
      "found saved model, loading from: saved_models\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-8\n",
      "3162/3162 - 0s - loss: 1.3816 - accuracy: 0.4870\n",
      "found saved model, loading from: saved_models\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-9\n",
      "3162/3162 - 0s - loss: 0.2525 - accuracy: 0.9067\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-0\n",
      "3162/3162 - 1s - loss: 0.6135 - accuracy: 0.9247\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-1\n",
      "3162/3162 - 1s - loss: 0.5921 - accuracy: 0.7875\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-2\n",
      "3162/3162 - 1s - loss: 0.2480 - accuracy: 0.9187\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-3\n",
      "3162/3162 - 1s - loss: 0.9100 - accuracy: 0.6610\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-4\n",
      "3162/3162 - 1s - loss: 0.6608 - accuracy: 0.8877\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-5\n",
      "3162/3162 - 1s - loss: 0.7964 - accuracy: 0.7239\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-6\n",
      "3162/3162 - 1s - loss: 0.6462 - accuracy: 0.7612\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-7\n",
      "3162/3162 - 1s - loss: 1.0570 - accuracy: 0.7375\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-8\n",
      "3162/3162 - 1s - loss: 1.0262 - accuracy: 0.6195\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-9\n",
      "3162/3162 - 1s - loss: 0.2868 - accuracy: 0.9130\n",
      "found saved model, loading from: saved_models\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-0\n",
      "3162/3162 - 1s - loss: 0.6770 - accuracy: 0.7619\n",
      "found saved model, loading from: saved_models\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-1\n",
      "3162/3162 - 1s - loss: 0.6732 - accuracy: 0.7508\n",
      "found saved model, loading from: saved_models\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-2\n",
      "3162/3162 - 1s - loss: 0.6245 - accuracy: 0.7682\n",
      "found saved model, loading from: saved_models\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-3\n",
      "3162/3162 - 1s - loss: 0.6810 - accuracy: 0.8899\n",
      "found saved model, loading from: saved_models\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-4\n",
      "3162/3162 - 1s - loss: 0.1867 - accuracy: 0.9399\n",
      "found saved model, loading from: saved_models\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-5\n",
      "3162/3162 - 1s - loss: 0.2326 - accuracy: 0.9326\n",
      "found saved model, loading from: saved_models\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-6\n",
      "3162/3162 - 1s - loss: 0.2673 - accuracy: 0.9175\n",
      "found saved model, loading from: saved_models\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-7\n",
      "3162/3162 - 1s - loss: 1.8709 - accuracy: 0.4307\n",
      "found saved model, loading from: saved_models\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-8\n",
      "3162/3162 - 1s - loss: 0.9894 - accuracy: 0.7685\n",
      "found saved model, loading from: saved_models\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-9\n",
      "3162/3162 - 1s - loss: 0.3629 - accuracy: 0.9010\n"
     ]
    }
   ],
   "source": [
    "filters_data = runner.test_param(filters=[32, 64, 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#runner.print_results(filters_data, 'filters')\n",
    "runner.plot_results(filters_data, 'filters')\n",
    "plt.savefig(\"plots/filters-32-64-128.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0_epochs-10_it-0\n",
      "3162/3162 - 1s - loss: 0.3003 - accuracy: 0.9010\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0_epochs-10_it-1\n",
      "3162/3162 - 1s - loss: 0.6750 - accuracy: 0.7634\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0_epochs-10_it-2\n",
      "3162/3162 - 1s - loss: 0.7303 - accuracy: 0.7375\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0_epochs-10_it-3\n",
      "3162/3162 - 1s - loss: 0.7088 - accuracy: 0.7641\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0_epochs-10_it-4\n",
      "3162/3162 - 1s - loss: 0.2099 - accuracy: 0.9355\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0_epochs-10_it-5\n",
      "3162/3162 - 1s - loss: 0.6161 - accuracy: 0.9263\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0_epochs-10_it-6\n",
      "3162/3162 - 1s - loss: 0.6994 - accuracy: 0.7793\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0_epochs-10_it-7\n",
      "3162/3162 - 1s - loss: 0.7376 - accuracy: 0.7372\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0_epochs-10_it-8\n",
      "3162/3162 - 1s - loss: 0.7711 - accuracy: 0.7192\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_16 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4828 - accuracy: 0.1142\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 396us/sample - loss: 1.1265 - accuracy: 0.6551 - val_loss: 0.7645 - val_accuracy: 0.7451\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.4720 - accuracy: 0.8425 - val_loss: 0.4668 - val_accuracy: 0.8441\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 351us/sample - loss: 0.2003 - accuracy: 0.9298 - val_loss: 0.2809 - val_accuracy: 0.8978\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 349us/sample - loss: 0.1698 - accuracy: 0.9388 - val_loss: 0.3421 - val_accuracy: 0.8786\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 353us/sample - loss: 0.1492 - accuracy: 0.9459 - val_loss: 0.2941 - val_accuracy: 0.8991\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 342us/sample - loss: 0.1449 - accuracy: 0.9473 - val_loss: 0.4169 - val_accuracy: 0.8631\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 350us/sample - loss: 0.1279 - accuracy: 0.9530 - val_loss: 0.3105 - val_accuracy: 0.9023\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 0.1272 - accuracy: 0.9517 - val_loss: 0.2958 - val_accuracy: 0.9089\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 0.1196 - accuracy: 0.9542 - val_loss: 0.2899 - val_accuracy: 0.9102\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 331us/sample - loss: 0.1183 - accuracy: 0.9551 - val_loss: 0.2978 - val_accuracy: 0.9099\n",
      "3162/3162 - 0s - loss: 0.2978 - accuracy: 0.9099\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000022397B97B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000022397B97B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0_epochs-10_it-9\\assets\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_18 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4942 - accuracy: 0.0092\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 406us/sample - loss: 1.3502 - accuracy: 0.5178 - val_loss: 1.2826 - val_accuracy: 0.5266\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 341us/sample - loss: 1.0191 - accuracy: 0.6076 - val_loss: 1.0662 - val_accuracy: 0.6116\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 354us/sample - loss: 0.9680 - accuracy: 0.6250 - val_loss: 1.0480 - val_accuracy: 0.6066\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 348us/sample - loss: 0.9394 - accuracy: 0.6332 - val_loss: 1.0944 - val_accuracy: 0.5908\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 354us/sample - loss: 0.9350 - accuracy: 0.6336 - val_loss: 1.0394 - val_accuracy: 0.6056\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 358us/sample - loss: 0.9176 - accuracy: 0.6385 - val_loss: 1.0505 - val_accuracy: 0.6139\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 350us/sample - loss: 0.9066 - accuracy: 0.6414 - val_loss: 1.0745 - val_accuracy: 0.6082\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 347us/sample - loss: 0.9037 - accuracy: 0.6426 - val_loss: 1.0663 - val_accuracy: 0.6164\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 340us/sample - loss: 0.8992 - accuracy: 0.6428 - val_loss: 1.0264 - val_accuracy: 0.6110\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.9049 - accuracy: 0.6414 - val_loss: 1.0936 - val_accuracy: 0.6040\n",
      "3162/3162 - 0s - loss: 1.0936 - accuracy: 0.6040\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000022397B49B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000022397B49B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.1_epochs-10_it-0\\assets\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_20 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4932 - accuracy: 0.0089\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 406us/sample - loss: 0.7326 - accuracy: 0.7267 - val_loss: 0.3591 - val_accuracy: 0.8624\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 353us/sample - loss: 0.2819 - accuracy: 0.8967 - val_loss: 0.2931 - val_accuracy: 0.9029\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 356us/sample - loss: 0.2075 - accuracy: 0.9240 - val_loss: 0.3227 - val_accuracy: 0.8719\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 356us/sample - loss: 0.1689 - accuracy: 0.9369 - val_loss: 0.2431 - val_accuracy: 0.9080\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 351us/sample - loss: 0.1461 - accuracy: 0.9437 - val_loss: 0.2268 - val_accuracy: 0.9175\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 370us/sample - loss: 0.1397 - accuracy: 0.9461 - val_loss: 0.2764 - val_accuracy: 0.8991\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 376us/sample - loss: 0.1329 - accuracy: 0.9500 - val_loss: 0.2332 - val_accuracy: 0.9171\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 348us/sample - loss: 0.1248 - accuracy: 0.9522 - val_loss: 0.2694 - val_accuracy: 0.9073\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.1159 - accuracy: 0.9562 - val_loss: 0.2401 - val_accuracy: 0.9159\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 355us/sample - loss: 0.1178 - accuracy: 0.9544 - val_loss: 0.2954 - val_accuracy: 0.8963\n",
      "3162/3162 - 0s - loss: 0.2954 - accuracy: 0.8963\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002239FDD9B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002239FDD9B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.1_epochs-10_it-1\\assets\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_22 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.5111 - accuracy: 0.0155\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 420us/sample - loss: 1.3836 - accuracy: 0.5433 - val_loss: 1.1626 - val_accuracy: 0.5879\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 353us/sample - loss: 1.0901 - accuracy: 0.6116 - val_loss: 1.1142 - val_accuracy: 0.5996\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 358us/sample - loss: 1.0518 - accuracy: 0.6147 - val_loss: 1.1762 - val_accuracy: 0.5974\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 358us/sample - loss: 1.0229 - accuracy: 0.6162 - val_loss: 1.1221 - val_accuracy: 0.5993\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 358us/sample - loss: 0.9957 - accuracy: 0.6220 - val_loss: 1.0867 - val_accuracy: 0.6006\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 396us/sample - loss: 0.9881 - accuracy: 0.6213 - val_loss: 1.0960 - val_accuracy: 0.5999\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 397us/sample - loss: 0.9869 - accuracy: 0.6194 - val_loss: 1.1391 - val_accuracy: 0.5952\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 383us/sample - loss: 0.9879 - accuracy: 0.6171 - val_loss: 1.2566 - val_accuracy: 0.5797\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 363us/sample - loss: 0.9698 - accuracy: 0.6233 - val_loss: 1.1192 - val_accuracy: 0.6018\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 373us/sample - loss: 0.9614 - accuracy: 0.6228 - val_loss: 1.1746 - val_accuracy: 0.5971\n",
      "3162/3162 - 0s - loss: 1.1746 - accuracy: 0.5971\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002239FFD6B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002239FFD6B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.1_epochs-10_it-2\\assets\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_24 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4959 - accuracy: 0.1448\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 409us/sample - loss: 1.4017 - accuracy: 0.4911 - val_loss: 1.2001 - val_accuracy: 0.5237\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 371us/sample - loss: 1.0311 - accuracy: 0.5979 - val_loss: 1.1199 - val_accuracy: 0.5595\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 331us/sample - loss: 0.9697 - accuracy: 0.6157 - val_loss: 1.0450 - val_accuracy: 0.6053\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.9454 - accuracy: 0.6237 - val_loss: 1.0221 - val_accuracy: 0.6053\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 339us/sample - loss: 0.9364 - accuracy: 0.6274 - val_loss: 1.0332 - val_accuracy: 0.6018\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 344us/sample - loss: 0.9260 - accuracy: 0.6293 - val_loss: 1.0129 - val_accuracy: 0.6066\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 333us/sample - loss: 0.9185 - accuracy: 0.6340 - val_loss: 1.0309 - val_accuracy: 0.6097\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 331us/sample - loss: 0.9166 - accuracy: 0.6346 - val_loss: 1.0185 - val_accuracy: 0.6053\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 331us/sample - loss: 0.9033 - accuracy: 0.6368 - val_loss: 1.0436 - val_accuracy: 0.6040\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 344us/sample - loss: 0.9057 - accuracy: 0.6380 - val_loss: 1.0850 - val_accuracy: 0.5949\n",
      "3162/3162 - 0s - loss: 1.0850 - accuracy: 0.5949\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002239FE7CB88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002239FE7CB88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.1_epochs-10_it-3\\assets\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_26 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4730 - accuracy: 0.1768\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 410us/sample - loss: 0.9790 - accuracy: 0.6568 - val_loss: 0.6608 - val_accuracy: 0.7559\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 342us/sample - loss: 0.5563 - accuracy: 0.7916 - val_loss: 0.6054 - val_accuracy: 0.7891\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 329us/sample - loss: 0.5046 - accuracy: 0.8089 - val_loss: 0.5793 - val_accuracy: 0.7903\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.4916 - accuracy: 0.8109 - val_loss: 0.5867 - val_accuracy: 0.7891\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 329us/sample - loss: 0.4691 - accuracy: 0.8185 - val_loss: 0.6046 - val_accuracy: 0.7887\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.4600 - accuracy: 0.8213 - val_loss: 0.6306 - val_accuracy: 0.7770\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 346us/sample - loss: 0.4508 - accuracy: 0.8234 - val_loss: 0.6185 - val_accuracy: 0.7789\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 350us/sample - loss: 0.4628 - accuracy: 0.8208 - val_loss: 0.6149 - val_accuracy: 0.7859\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 352us/sample - loss: 0.4403 - accuracy: 0.8270 - val_loss: 0.5931 - val_accuracy: 0.7916\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.4445 - accuracy: 0.8245 - val_loss: 0.6103 - val_accuracy: 0.7906\n",
      "3162/3162 - 1s - loss: 0.6103 - accuracy: 0.7906\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223A03B7B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223A03B7B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.1_epochs-10_it-4\\assets\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.5000 - accuracy: 0.0076\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 389us/sample - loss: 1.0765 - accuracy: 0.6703 - val_loss: 0.7834 - val_accuracy: 0.7296\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 0.6909 - accuracy: 0.7686 - val_loss: 0.7995 - val_accuracy: 0.7122\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 367us/sample - loss: 0.6399 - accuracy: 0.7755 - val_loss: 0.6681 - val_accuracy: 0.7657\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 346us/sample - loss: 0.5973 - accuracy: 0.7852 - val_loss: 0.7038 - val_accuracy: 0.7540\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 353us/sample - loss: 0.5878 - accuracy: 0.7856 - val_loss: 0.7087 - val_accuracy: 0.7483\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 343us/sample - loss: 0.5880 - accuracy: 0.7854 - val_loss: 0.6934 - val_accuracy: 0.7524\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 329us/sample - loss: 0.5751 - accuracy: 0.7841 - val_loss: 0.6583 - val_accuracy: 0.7666\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.5680 - accuracy: 0.7865 - val_loss: 0.7069 - val_accuracy: 0.7508\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.5605 - accuracy: 0.7864 - val_loss: 0.6959 - val_accuracy: 0.7536\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 330us/sample - loss: 0.5536 - accuracy: 0.7878 - val_loss: 0.6883 - val_accuracy: 0.7505\n",
      "3162/3162 - 0s - loss: 0.6883 - accuracy: 0.7505\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223A04B4B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223A04B4B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.1_epochs-10_it-5\\assets\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_30 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4880 - accuracy: 0.1082\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 391us/sample - loss: 1.0745 - accuracy: 0.6616 - val_loss: 0.7986 - val_accuracy: 0.7296\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 344us/sample - loss: 0.6972 - accuracy: 0.7573 - val_loss: 0.7370 - val_accuracy: 0.7356\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.6493 - accuracy: 0.7627 - val_loss: 0.7035 - val_accuracy: 0.7435\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 339us/sample - loss: 0.6230 - accuracy: 0.7662 - val_loss: 0.7211 - val_accuracy: 0.7388\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 341us/sample - loss: 0.6214 - accuracy: 0.7646 - val_loss: 0.6890 - val_accuracy: 0.7514\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 329us/sample - loss: 0.6158 - accuracy: 0.7683 - val_loss: 0.7278 - val_accuracy: 0.7328\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 332us/sample - loss: 0.6033 - accuracy: 0.7688 - val_loss: 0.7571 - val_accuracy: 0.7283\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 0.6046 - accuracy: 0.7659 - val_loss: 0.7009 - val_accuracy: 0.7378\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 340us/sample - loss: 0.6058 - accuracy: 0.7653 - val_loss: 0.7231 - val_accuracy: 0.7369\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 364us/sample - loss: 0.5952 - accuracy: 0.7695 - val_loss: 0.7233 - val_accuracy: 0.7315\n",
      "3162/3162 - 0s - loss: 0.7233 - accuracy: 0.7315\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223A4D21B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223A4D21B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.1_epochs-10_it-6\\assets\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_32 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4855 - accuracy: 0.1502\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 401us/sample - loss: 1.5626 - accuracy: 0.4381 - val_loss: 1.4278 - val_accuracy: 0.4466\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 347us/sample - loss: 1.3703 - accuracy: 0.4634 - val_loss: 1.3917 - val_accuracy: 0.4551\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 366us/sample - loss: 1.3454 - accuracy: 0.4661 - val_loss: 1.4586 - val_accuracy: 0.4453\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 341us/sample - loss: 1.3392 - accuracy: 0.4663 - val_loss: 1.4047 - val_accuracy: 0.4570\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 344us/sample - loss: 1.3333 - accuracy: 0.4665 - val_loss: 1.3844 - val_accuracy: 0.4579\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 1.3310 - accuracy: 0.4665 - val_loss: 1.4013 - val_accuracy: 0.4485\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 331us/sample - loss: 1.3349 - accuracy: 0.4654 - val_loss: 1.4134 - val_accuracy: 0.4466\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 1.3268 - accuracy: 0.4667 - val_loss: 1.3974 - val_accuracy: 0.4491\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 343us/sample - loss: 1.3293 - accuracy: 0.4665 - val_loss: 1.3837 - val_accuracy: 0.4560\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 340us/sample - loss: 1.3275 - accuracy: 0.4667 - val_loss: 1.3903 - val_accuracy: 0.4513\n",
      "3162/3162 - 0s - loss: 1.3903 - accuracy: 0.4513\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223A4F16B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223A4F16B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.1_epochs-10_it-7\\assets\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_34 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4877 - accuracy: 0.0547\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 398us/sample - loss: 0.6572 - accuracy: 0.7648 - val_loss: 0.3189 - val_accuracy: 0.8782\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 349us/sample - loss: 0.2464 - accuracy: 0.9096 - val_loss: 0.2775 - val_accuracy: 0.8994\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 330us/sample - loss: 0.2121 - accuracy: 0.9234 - val_loss: 0.3341 - val_accuracy: 0.8707\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.1787 - accuracy: 0.9324 - val_loss: 0.2419 - val_accuracy: 0.9105\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.1562 - accuracy: 0.9409 - val_loss: 0.2985 - val_accuracy: 0.8956\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 344us/sample - loss: 0.1518 - accuracy: 0.9436 - val_loss: 0.2546 - val_accuracy: 0.9086\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 340us/sample - loss: 0.1561 - accuracy: 0.9403 - val_loss: 0.2574 - val_accuracy: 0.9077\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 332us/sample - loss: 0.1454 - accuracy: 0.9426 - val_loss: 0.3188 - val_accuracy: 0.8937\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 330us/sample - loss: 0.1376 - accuracy: 0.9477 - val_loss: 0.2556 - val_accuracy: 0.9080\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.1320 - accuracy: 0.9488 - val_loss: 0.3282 - val_accuracy: 0.8922\n",
      "3162/3162 - 0s - loss: 0.3282 - accuracy: 0.8922\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223A5167B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223A5167B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.1_epochs-10_it-8\\assets\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4953 - accuracy: 0.0073\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 422us/sample - loss: 0.9144 - accuracy: 0.6672 - val_loss: 0.6436 - val_accuracy: 0.7732\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 358us/sample - loss: 0.5684 - accuracy: 0.7847 - val_loss: 0.7971 - val_accuracy: 0.7470\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 343us/sample - loss: 0.5196 - accuracy: 0.7989 - val_loss: 0.5927 - val_accuracy: 0.7793\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 0.4893 - accuracy: 0.8087 - val_loss: 0.6189 - val_accuracy: 0.7657\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 383us/sample - loss: 0.4787 - accuracy: 0.8122 - val_loss: 0.5833 - val_accuracy: 0.7843\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 357us/sample - loss: 0.4724 - accuracy: 0.8137 - val_loss: 0.6097 - val_accuracy: 0.7856\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 378us/sample - loss: 0.4649 - accuracy: 0.8151 - val_loss: 0.5863 - val_accuracy: 0.7840\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 368us/sample - loss: 0.4646 - accuracy: 0.8160 - val_loss: 0.6294 - val_accuracy: 0.7780\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 395us/sample - loss: 0.4564 - accuracy: 0.8182 - val_loss: 0.6098 - val_accuracy: 0.7856\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 380us/sample - loss: 0.4509 - accuracy: 0.8195 - val_loss: 0.6314 - val_accuracy: 0.7796\n",
      "3162/3162 - 0s - loss: 0.6314 - accuracy: 0.7796\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223892841F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223892841F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.1_epochs-10_it-9\\assets\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_38 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.5237 - accuracy: 0.0076\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 409us/sample - loss: 1.0380 - accuracy: 0.6587 - val_loss: 0.3634 - val_accuracy: 0.8744\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 359us/sample - loss: 0.2770 - accuracy: 0.9011 - val_loss: 0.3193 - val_accuracy: 0.8808\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 352us/sample - loss: 0.2027 - accuracy: 0.9321 - val_loss: 0.2563 - val_accuracy: 0.9133\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 345us/sample - loss: 0.1705 - accuracy: 0.9427 - val_loss: 0.2655 - val_accuracy: 0.9133\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 342us/sample - loss: 0.1509 - accuracy: 0.9486 - val_loss: 0.2601 - val_accuracy: 0.9162\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 339us/sample - loss: 0.1388 - accuracy: 0.9542 - val_loss: 0.2477 - val_accuracy: 0.9213\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 347us/sample - loss: 0.1304 - accuracy: 0.9573 - val_loss: 0.2886 - val_accuracy: 0.9096\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 345us/sample - loss: 0.1229 - accuracy: 0.9579 - val_loss: 0.2844 - val_accuracy: 0.9149\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 351us/sample - loss: 0.1180 - accuracy: 0.9589 - val_loss: 0.2446 - val_accuracy: 0.9206\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 341us/sample - loss: 0.1122 - accuracy: 0.9602 - val_loss: 0.2434 - val_accuracy: 0.9225\n",
      "3162/3162 - 0s - loss: 0.2434 - accuracy: 0.9225\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000022387C18678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000022387C18678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.2_epochs-10_it-0\\assets\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_40 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4817 - accuracy: 0.0202\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 407us/sample - loss: 0.6061 - accuracy: 0.7867 - val_loss: 0.3676 - val_accuracy: 0.8675\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 340us/sample - loss: 0.2600 - accuracy: 0.9127 - val_loss: 0.3745 - val_accuracy: 0.8713\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 342us/sample - loss: 0.1937 - accuracy: 0.9363 - val_loss: 0.2837 - val_accuracy: 0.9023\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 354us/sample - loss: 0.1789 - accuracy: 0.9397 - val_loss: 0.2896 - val_accuracy: 0.9051\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 358us/sample - loss: 0.1586 - accuracy: 0.9462 - val_loss: 0.3018 - val_accuracy: 0.9039\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 348us/sample - loss: 0.1341 - accuracy: 0.9544 - val_loss: 0.3035 - val_accuracy: 0.9039\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 348us/sample - loss: 0.1256 - accuracy: 0.9576 - val_loss: 0.2730 - val_accuracy: 0.9105\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.1240 - accuracy: 0.9582 - val_loss: 0.2949 - val_accuracy: 0.9051\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.1140 - accuracy: 0.9584 - val_loss: 0.2728 - val_accuracy: 0.9140\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.1136 - accuracy: 0.9602 - val_loss: 0.2993 - val_accuracy: 0.9114\n",
      "3162/3162 - 0s - loss: 0.2993 - accuracy: 0.9114\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000022399BEF5E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000022399BEF5E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.2_epochs-10_it-1\\assets\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_42 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4729 - accuracy: 0.1673\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 408us/sample - loss: 0.6318 - accuracy: 0.7664 - val_loss: 0.3431 - val_accuracy: 0.8776\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 345us/sample - loss: 0.2434 - accuracy: 0.9090 - val_loss: 0.3222 - val_accuracy: 0.8820\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 342us/sample - loss: 0.2066 - accuracy: 0.9207 - val_loss: 0.2825 - val_accuracy: 0.8975\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 353us/sample - loss: 0.1779 - accuracy: 0.9342 - val_loss: 0.3217 - val_accuracy: 0.8899\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 339us/sample - loss: 0.1646 - accuracy: 0.9387 - val_loss: 0.2918 - val_accuracy: 0.8956\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.1577 - accuracy: 0.9401 - val_loss: 0.3873 - val_accuracy: 0.8719\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 350us/sample - loss: 0.1549 - accuracy: 0.9403 - val_loss: 0.2687 - val_accuracy: 0.9070\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 346us/sample - loss: 0.1423 - accuracy: 0.9448 - val_loss: 0.2912 - val_accuracy: 0.9013\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 350us/sample - loss: 0.1408 - accuracy: 0.9455 - val_loss: 0.2665 - val_accuracy: 0.9023\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 369us/sample - loss: 0.1373 - accuracy: 0.9450 - val_loss: 0.3216 - val_accuracy: 0.8963\n",
      "3162/3162 - 0s - loss: 0.3216 - accuracy: 0.8963\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002238AC2A3A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002238AC2A3A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.2_epochs-10_it-2\\assets\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_44 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_45 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4855 - accuracy: 0.0142\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 416us/sample - loss: 1.1009 - accuracy: 0.6006 - val_loss: 0.8792 - val_accuracy: 0.6524\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 343us/sample - loss: 0.7079 - accuracy: 0.7233 - val_loss: 0.7391 - val_accuracy: 0.7106\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 370us/sample - loss: 0.6341 - accuracy: 0.7522 - val_loss: 0.7175 - val_accuracy: 0.7255\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 350us/sample - loss: 0.6093 - accuracy: 0.7636 - val_loss: 0.6613 - val_accuracy: 0.7394\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 353us/sample - loss: 0.5930 - accuracy: 0.7648 - val_loss: 0.6730 - val_accuracy: 0.7362\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 404us/sample - loss: 0.5756 - accuracy: 0.7711 - val_loss: 0.6897 - val_accuracy: 0.7331\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 382us/sample - loss: 0.5691 - accuracy: 0.7731 - val_loss: 0.7234 - val_accuracy: 0.7226\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 387us/sample - loss: 0.5633 - accuracy: 0.7775 - val_loss: 0.6460 - val_accuracy: 0.7489\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 365us/sample - loss: 0.5523 - accuracy: 0.7788 - val_loss: 0.6706 - val_accuracy: 0.7416\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 364us/sample - loss: 0.5523 - accuracy: 0.7800 - val_loss: 0.6568 - val_accuracy: 0.7498\n",
      "3162/3162 - 1s - loss: 0.6568 - accuracy: 0.7498\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223A4D87AF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223A4D87AF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.2_epochs-10_it-3\\assets\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_46 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4732 - accuracy: 0.1584\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 423us/sample - loss: 0.6605 - accuracy: 0.7495 - val_loss: 0.3652 - val_accuracy: 0.8574\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 332us/sample - loss: 0.2522 - accuracy: 0.9095 - val_loss: 0.3933 - val_accuracy: 0.8466\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 345us/sample - loss: 0.2030 - accuracy: 0.9298 - val_loss: 0.2834 - val_accuracy: 0.8909\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 341us/sample - loss: 0.1789 - accuracy: 0.9373 - val_loss: 0.3858 - val_accuracy: 0.8719\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 0.1637 - accuracy: 0.9409 - val_loss: 0.2851 - val_accuracy: 0.8956\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 339us/sample - loss: 0.1489 - accuracy: 0.9448 - val_loss: 0.2766 - val_accuracy: 0.9054\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 349us/sample - loss: 0.1431 - accuracy: 0.9488 - val_loss: 0.3189 - val_accuracy: 0.8941\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 348us/sample - loss: 0.1392 - accuracy: 0.9495 - val_loss: 0.2807 - val_accuracy: 0.9039\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 333us/sample - loss: 0.1314 - accuracy: 0.9508 - val_loss: 0.2691 - val_accuracy: 0.9102\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 333us/sample - loss: 0.1297 - accuracy: 0.9515 - val_loss: 0.2927 - val_accuracy: 0.9058\n",
      "3162/3162 - 0s - loss: 0.2927 - accuracy: 0.9058\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223A4D87798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223A4D87798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.2_epochs-10_it-4\\assets\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_48 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_24 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4875 - accuracy: 0.0082\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 422us/sample - loss: 1.2362 - accuracy: 0.5872 - val_loss: 1.0141 - val_accuracy: 0.7400\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.9192 - accuracy: 0.7693 - val_loss: 0.9614 - val_accuracy: 0.7938\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 343us/sample - loss: 0.8774 - accuracy: 0.8015 - val_loss: 1.0234 - val_accuracy: 0.7818\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 0.8459 - accuracy: 0.8181 - val_loss: 0.9292 - val_accuracy: 0.7963\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 365us/sample - loss: 0.8322 - accuracy: 0.8227 - val_loss: 0.9133 - val_accuracy: 0.8004\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 402us/sample - loss: 0.8114 - accuracy: 0.8322 - val_loss: 0.9349 - val_accuracy: 0.8042\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 355us/sample - loss: 0.8033 - accuracy: 0.8360 - val_loss: 0.9317 - val_accuracy: 0.8023\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 351us/sample - loss: 0.7979 - accuracy: 0.8371 - val_loss: 0.9342 - val_accuracy: 0.8065\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 379us/sample - loss: 0.8063 - accuracy: 0.8346 - val_loss: 0.9234 - val_accuracy: 0.8036\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 360us/sample - loss: 0.7901 - accuracy: 0.8407 - val_loss: 0.9442 - val_accuracy: 0.8014\n",
      "3162/3162 - 1s - loss: 0.9442 - accuracy: 0.8014\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223A4D87708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223A4D87708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.2_epochs-10_it-5\\assets\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_50 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_25 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4919 - accuracy: 0.1338\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 400us/sample - loss: 1.0576 - accuracy: 0.6750 - val_loss: 0.7359 - val_accuracy: 0.7581\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 359us/sample - loss: 0.6874 - accuracy: 0.7679 - val_loss: 0.7021 - val_accuracy: 0.7527\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 357us/sample - loss: 0.6368 - accuracy: 0.7757 - val_loss: 0.7053 - val_accuracy: 0.7498\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 410us/sample - loss: 0.6200 - accuracy: 0.7774 - val_loss: 0.6736 - val_accuracy: 0.7631\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 348us/sample - loss: 0.6093 - accuracy: 0.7766 - val_loss: 0.6822 - val_accuracy: 0.7533\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 354us/sample - loss: 0.5909 - accuracy: 0.7807 - val_loss: 0.6813 - val_accuracy: 0.7590\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 339us/sample - loss: 0.5937 - accuracy: 0.7805 - val_loss: 0.6742 - val_accuracy: 0.7574\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 344us/sample - loss: 0.5771 - accuracy: 0.7823 - val_loss: 0.6772 - val_accuracy: 0.7574\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.5733 - accuracy: 0.7820 - val_loss: 0.6864 - val_accuracy: 0.7511\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 325us/sample - loss: 0.5721 - accuracy: 0.7815 - val_loss: 0.7450 - val_accuracy: 0.7362\n",
      "3162/3162 - 0s - loss: 0.7450 - accuracy: 0.7362\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223974C40D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223974C40D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.2_epochs-10_it-6\\assets\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_52 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_26 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4498 - accuracy: 0.1626\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 391us/sample - loss: 1.0628 - accuracy: 0.6726 - val_loss: 0.7582 - val_accuracy: 0.7536\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.6578 - accuracy: 0.7778 - val_loss: 0.6884 - val_accuracy: 0.7571\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 339us/sample - loss: 0.6051 - accuracy: 0.7837 - val_loss: 0.7492 - val_accuracy: 0.7438\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 325us/sample - loss: 0.5857 - accuracy: 0.7867 - val_loss: 0.6405 - val_accuracy: 0.7710\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 324us/sample - loss: 0.5634 - accuracy: 0.7908 - val_loss: 0.6286 - val_accuracy: 0.7682\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.5515 - accuracy: 0.7910 - val_loss: 0.7050 - val_accuracy: 0.7492\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 343us/sample - loss: 0.5424 - accuracy: 0.7937 - val_loss: 0.7066 - val_accuracy: 0.7536\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.5423 - accuracy: 0.7928 - val_loss: 0.6911 - val_accuracy: 0.7555\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 345us/sample - loss: 0.5345 - accuracy: 0.7943 - val_loss: 0.6427 - val_accuracy: 0.7691\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 398us/sample - loss: 0.5358 - accuracy: 0.7948 - val_loss: 0.6602 - val_accuracy: 0.7587\n",
      "3162/3162 - 0s - loss: 0.6602 - accuracy: 0.7587\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002238AC48EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002238AC48EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.2_epochs-10_it-7\\assets\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_54 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_27 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4846 - accuracy: 0.1344\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 423us/sample - loss: 0.8146 - accuracy: 0.7334 - val_loss: 0.3232 - val_accuracy: 0.8941\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 360us/sample - loss: 0.2296 - accuracy: 0.9194 - val_loss: 0.2594 - val_accuracy: 0.9001\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 347us/sample - loss: 0.1751 - accuracy: 0.9368 - val_loss: 0.4286 - val_accuracy: 0.8393\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 347us/sample - loss: 0.1522 - accuracy: 0.9443 - val_loss: 0.2211 - val_accuracy: 0.9171\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 352us/sample - loss: 0.1288 - accuracy: 0.9520 - val_loss: 0.4380 - val_accuracy: 0.8656\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 359us/sample - loss: 0.1262 - accuracy: 0.9520 - val_loss: 0.2960 - val_accuracy: 0.9051\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.1086 - accuracy: 0.9591 - val_loss: 0.2782 - val_accuracy: 0.9077\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 339us/sample - loss: 0.1208 - accuracy: 0.9544 - val_loss: 0.2975 - val_accuracy: 0.9010\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 332us/sample - loss: 0.0957 - accuracy: 0.9643 - val_loss: 0.2506 - val_accuracy: 0.9235\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 344us/sample - loss: 0.0884 - accuracy: 0.9670 - val_loss: 0.2940 - val_accuracy: 0.9250\n",
      "3162/3162 - 1s - loss: 0.2940 - accuracy: 0.9250\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002238AC48F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002238AC48F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.2_epochs-10_it-8\\assets\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_56 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_28 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.5036 - accuracy: 0.0070\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 4s 457us/sample - loss: 0.9591 - accuracy: 0.6736 - val_loss: 0.7145 - val_accuracy: 0.7454 1\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 400us/sample - loss: 0.5742 - accuracy: 0.7834 - val_loss: 0.6222 - val_accuracy: 0.7720\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 356us/sample - loss: 0.5282 - accuracy: 0.7993 - val_loss: 0.6533 - val_accuracy: 0.7581\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 367us/sample - loss: 0.5157 - accuracy: 0.8025 - val_loss: 0.5940 - val_accuracy: 0.7793\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 376us/sample - loss: 0.4953 - accuracy: 0.8074 - val_loss: 0.6192 - val_accuracy: 0.7713\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 347us/sample - loss: 0.4882 - accuracy: 0.8098 - val_loss: 0.6080 - val_accuracy: 0.7767\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 346us/sample - loss: 0.4945 - accuracy: 0.8078 - val_loss: 0.6084 - val_accuracy: 0.7812\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 347us/sample - loss: 0.4806 - accuracy: 0.8120 - val_loss: 0.7288 - val_accuracy: 0.7603\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 376us/sample - loss: 0.4835 - accuracy: 0.8115 - val_loss: 0.6132 - val_accuracy: 0.7726\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 413us/sample - loss: 0.4683 - accuracy: 0.8155 - val_loss: 0.6048 - val_accuracy: 0.7770\n",
      "3162/3162 - 1s - loss: 0.6048 - accuracy: 0.7770\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002238B1F68B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002238B1F68B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.2_epochs-10_it-9\\assets\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_58 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_29 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4906 - accuracy: 0.0089\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 417us/sample - loss: 1.0212 - accuracy: 0.6883 - val_loss: 0.8211 - val_accuracy: 0.7362\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 344us/sample - loss: 0.6630 - accuracy: 0.7894 - val_loss: 0.6529 - val_accuracy: 0.7849\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 367us/sample - loss: 0.6111 - accuracy: 0.7966 - val_loss: 0.6439 - val_accuracy: 0.7894\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 388us/sample - loss: 0.5731 - accuracy: 0.8034 - val_loss: 0.6603 - val_accuracy: 0.7834\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 0.5605 - accuracy: 0.8021 - val_loss: 0.6543 - val_accuracy: 0.7884\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 339us/sample - loss: 0.5468 - accuracy: 0.8082 - val_loss: 0.7162 - val_accuracy: 0.7644\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 339us/sample - loss: 0.5293 - accuracy: 0.8079 - val_loss: 0.6095 - val_accuracy: 0.7891\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 348us/sample - loss: 0.5158 - accuracy: 0.8111 - val_loss: 0.6810 - val_accuracy: 0.7827\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 330us/sample - loss: 0.5096 - accuracy: 0.8119 - val_loss: 0.6288 - val_accuracy: 0.7840\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 358us/sample - loss: 0.5134 - accuracy: 0.8100 - val_loss: 0.6058 - val_accuracy: 0.7973\n",
      "3162/3162 - 0s - loss: 0.6058 - accuracy: 0.7973\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223DF22EF78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223DF22EF78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.3_epochs-10_it-0\\assets\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_30 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4788 - accuracy: 0.1724\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 446us/sample - loss: 0.8631 - accuracy: 0.7081 - val_loss: 0.3720 - val_accuracy: 0.8852\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 364us/sample - loss: 0.2755 - accuracy: 0.9032 - val_loss: 0.2715 - val_accuracy: 0.9023\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 347us/sample - loss: 0.2008 - accuracy: 0.9323 - val_loss: 0.2944 - val_accuracy: 0.8985\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 347us/sample - loss: 0.1868 - accuracy: 0.9323 - val_loss: 0.3268 - val_accuracy: 0.8786\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 364us/sample - loss: 0.1593 - accuracy: 0.9422 - val_loss: 0.3975 - val_accuracy: 0.8744\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 344us/sample - loss: 0.1474 - accuracy: 0.9466 - val_loss: 0.2622 - val_accuracy: 0.9089\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 360us/sample - loss: 0.1439 - accuracy: 0.9468 - val_loss: 0.3016 - val_accuracy: 0.9007\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 363us/sample - loss: 0.1358 - accuracy: 0.9479 - val_loss: 0.3269 - val_accuracy: 0.8918\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 379us/sample - loss: 0.1319 - accuracy: 0.9524 - val_loss: 0.3524 - val_accuracy: 0.8975\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 350us/sample - loss: 0.1215 - accuracy: 0.9539 - val_loss: 0.3194 - val_accuracy: 0.9048\n",
      "3162/3162 - 0s - loss: 0.3194 - accuracy: 0.9048\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223DF5D03A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223DF5D03A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.3_epochs-10_it-1\\assets\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_62 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_31 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4928 - accuracy: 0.0073\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 433us/sample - loss: 0.6892 - accuracy: 0.7525 - val_loss: 0.3676 - val_accuracy: 0.8548\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 393us/sample - loss: 0.2414 - accuracy: 0.9141 - val_loss: 0.2784 - val_accuracy: 0.8909\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.1757 - accuracy: 0.9378 - val_loss: 0.2975 - val_accuracy: 0.8944\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 331us/sample - loss: 0.1472 - accuracy: 0.9470 - val_loss: 0.2453 - val_accuracy: 0.9156\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 353us/sample - loss: 0.1337 - accuracy: 0.9537 - val_loss: 0.2184 - val_accuracy: 0.9254\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 342us/sample - loss: 0.1219 - accuracy: 0.9591 - val_loss: 0.2018 - val_accuracy: 0.9288\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 385us/sample - loss: 0.1297 - accuracy: 0.9530 - val_loss: 0.2207 - val_accuracy: 0.9263\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 352us/sample - loss: 0.1008 - accuracy: 0.9645 - val_loss: 0.2190 - val_accuracy: 0.9273\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 371us/sample - loss: 0.0989 - accuracy: 0.9660 - val_loss: 0.2891 - val_accuracy: 0.9118\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 378us/sample - loss: 0.0947 - accuracy: 0.9668 - val_loss: 0.2504 - val_accuracy: 0.9209\n",
      "3162/3162 - 1s - loss: 0.2504 - accuracy: 0.9209\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223DF40E3A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223DF40E3A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.3_epochs-10_it-2\\assets\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_64 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_32 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4837 - accuracy: 0.2324\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 394us/sample - loss: 0.7025 - accuracy: 0.7551 - val_loss: 0.4220 - val_accuracy: 0.8444\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 348us/sample - loss: 0.2598 - accuracy: 0.9100 - val_loss: 0.3065 - val_accuracy: 0.8874\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 348us/sample - loss: 0.1892 - accuracy: 0.9337 - val_loss: 0.2453 - val_accuracy: 0.9146\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.1812 - accuracy: 0.9363 - val_loss: 0.3217 - val_accuracy: 0.8915\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 332us/sample - loss: 0.1576 - accuracy: 0.9445 - val_loss: 0.2293 - val_accuracy: 0.9209\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.1396 - accuracy: 0.9503 - val_loss: 0.2882 - val_accuracy: 0.9032\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 324us/sample - loss: 0.1365 - accuracy: 0.9504 - val_loss: 0.2663 - val_accuracy: 0.9061\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 360us/sample - loss: 0.1368 - accuracy: 0.9486 - val_loss: 0.2371 - val_accuracy: 0.9171\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 341us/sample - loss: 0.1399 - accuracy: 0.9480 - val_loss: 0.2819 - val_accuracy: 0.9042\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 358us/sample - loss: 0.1220 - accuracy: 0.9543 - val_loss: 0.2353 - val_accuracy: 0.9200\n",
      "3162/3162 - 1s - loss: 0.2353 - accuracy: 0.9200\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223DFA1D3A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223DFA1D3A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.3_epochs-10_it-3\\assets\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_66 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_33 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4742 - accuracy: 0.1312\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 4s 451us/sample - loss: 0.8289 - accuracy: 0.7177 - val_loss: 0.3804 - val_accuracy: 0.8725\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 346us/sample - loss: 0.2646 - accuracy: 0.9092 - val_loss: 0.2911 - val_accuracy: 0.8994\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.2022 - accuracy: 0.9291 - val_loss: 0.3876 - val_accuracy: 0.8510\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.1776 - accuracy: 0.9373 - val_loss: 0.2749 - val_accuracy: 0.8969\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 333us/sample - loss: 0.1486 - accuracy: 0.9470 - val_loss: 0.2329 - val_accuracy: 0.9156\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 331us/sample - loss: 0.1329 - accuracy: 0.9527 - val_loss: 0.2495 - val_accuracy: 0.9111\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.1196 - accuracy: 0.9564 - val_loss: 0.3949 - val_accuracy: 0.8830\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 339us/sample - loss: 0.1092 - accuracy: 0.9598 - val_loss: 0.2584 - val_accuracy: 0.9114\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.1093 - accuracy: 0.9585 - val_loss: 0.2536 - val_accuracy: 0.9143\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 375us/sample - loss: 0.0984 - accuracy: 0.9620 - val_loss: 0.3336 - val_accuracy: 0.9001\n",
      "3162/3162 - 0s - loss: 0.3336 - accuracy: 0.9001\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223DFAE4558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223DFAE4558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.3_epochs-10_it-4\\assets\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_68 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_34 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4811 - accuracy: 0.0803\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 398us/sample - loss: 0.9616 - accuracy: 0.6605 - val_loss: 0.7188 - val_accuracy: 0.7514\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 357us/sample - loss: 0.5832 - accuracy: 0.7841 - val_loss: 0.6697 - val_accuracy: 0.7460\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 365us/sample - loss: 0.5390 - accuracy: 0.7979 - val_loss: 0.6134 - val_accuracy: 0.7799\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 373us/sample - loss: 0.5067 - accuracy: 0.8110 - val_loss: 0.6450 - val_accuracy: 0.7641\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 359us/sample - loss: 0.4843 - accuracy: 0.8187 - val_loss: 0.6118 - val_accuracy: 0.7796\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 329us/sample - loss: 0.4680 - accuracy: 0.8207 - val_loss: 0.6042 - val_accuracy: 0.7755\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 343us/sample - loss: 0.4554 - accuracy: 0.8250 - val_loss: 0.6836 - val_accuracy: 0.7527\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 343us/sample - loss: 0.4444 - accuracy: 0.8279 - val_loss: 0.5809 - val_accuracy: 0.7938\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 341us/sample - loss: 0.4491 - accuracy: 0.8259 - val_loss: 0.5987 - val_accuracy: 0.7884\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 340us/sample - loss: 0.4351 - accuracy: 0.8307 - val_loss: 0.6005 - val_accuracy: 0.7884\n",
      "3162/3162 - 0s - loss: 0.6005 - accuracy: 0.7884\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223DFC22708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223DFC22708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.3_epochs-10_it-5\\assets\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_70 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_35 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4871 - accuracy: 0.1161\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 391us/sample - loss: 1.0631 - accuracy: 0.6758 - val_loss: 0.8229 - val_accuracy: 0.8106\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 343us/sample - loss: 0.6657 - accuracy: 0.8612 - val_loss: 0.6911 - val_accuracy: 0.8624\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 0.6001 - accuracy: 0.8976 - val_loss: 0.6599 - val_accuracy: 0.8763\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 332us/sample - loss: 0.5828 - accuracy: 0.9097 - val_loss: 0.6816 - val_accuracy: 0.8631\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 331us/sample - loss: 0.5719 - accuracy: 0.9202 - val_loss: 0.6796 - val_accuracy: 0.8507\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 348us/sample - loss: 0.5674 - accuracy: 0.9218 - val_loss: 0.6386 - val_accuracy: 0.8956\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 0.5582 - accuracy: 0.9283 - val_loss: 0.6369 - val_accuracy: 0.9035\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.5620 - accuracy: 0.9257 - val_loss: 0.6683 - val_accuracy: 0.8827\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 353us/sample - loss: 0.5464 - accuracy: 0.9338 - val_loss: 0.6445 - val_accuracy: 0.9086\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 384us/sample - loss: 0.5487 - accuracy: 0.9325 - val_loss: 0.6623 - val_accuracy: 0.9048\n",
      "3162/3162 - 0s - loss: 0.6623 - accuracy: 0.9048\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223DFD018B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223DFD018B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.3_epochs-10_it-6\\assets\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_72 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_72 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_73 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_36 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4751 - accuracy: 0.1758\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 4s 541us/sample - loss: 0.7077 - accuracy: 0.7456 - val_loss: 0.3798 - val_accuracy: 0.8533\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 343us/sample - loss: 0.2724 - accuracy: 0.8976 - val_loss: 0.3502 - val_accuracy: 0.8552\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 342us/sample - loss: 0.2210 - accuracy: 0.9194 - val_loss: 0.3041 - val_accuracy: 0.8858\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 340us/sample - loss: 0.1997 - accuracy: 0.9238 - val_loss: 0.2995 - val_accuracy: 0.8868\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 345us/sample - loss: 0.1839 - accuracy: 0.9296 - val_loss: 0.2482 - val_accuracy: 0.9096\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 331us/sample - loss: 0.1743 - accuracy: 0.9350 - val_loss: 0.3654 - val_accuracy: 0.8700\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.1659 - accuracy: 0.9350 - val_loss: 0.2915 - val_accuracy: 0.8966\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.1621 - accuracy: 0.9367 - val_loss: 0.2816 - val_accuracy: 0.8972\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.1554 - accuracy: 0.9404 - val_loss: 0.3687 - val_accuracy: 0.8855\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.1557 - accuracy: 0.9394 - val_loss: 0.3073 - val_accuracy: 0.8941\n",
      "3162/3162 - 0s - loss: 0.3073 - accuracy: 0.8941\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223998895E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223998895E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.3_epochs-10_it-7\\assets\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_74 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_74 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_75 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_37 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4888 - accuracy: 0.0351\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 390us/sample - loss: 1.0039 - accuracy: 0.6565 - val_loss: 0.7757 - val_accuracy: 0.7037\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.6096 - accuracy: 0.7724 - val_loss: 0.6406 - val_accuracy: 0.7666\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 340us/sample - loss: 0.5578 - accuracy: 0.7836 - val_loss: 0.6351 - val_accuracy: 0.7669\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.5303 - accuracy: 0.7943 - val_loss: 0.5967 - val_accuracy: 0.7764\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 367us/sample - loss: 0.5174 - accuracy: 0.7971 - val_loss: 0.6137 - val_accuracy: 0.7704\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 366us/sample - loss: 0.5203 - accuracy: 0.7963 - val_loss: 0.6163 - val_accuracy: 0.7644\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 369us/sample - loss: 0.5219 - accuracy: 0.7936 - val_loss: 0.6434 - val_accuracy: 0.7650\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 367us/sample - loss: 0.4999 - accuracy: 0.8019 - val_loss: 0.6197 - val_accuracy: 0.7663\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 341us/sample - loss: 0.5010 - accuracy: 0.8013 - val_loss: 0.6742 - val_accuracy: 0.7476\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 346us/sample - loss: 0.4938 - accuracy: 0.8044 - val_loss: 0.6305 - val_accuracy: 0.7663\n",
      "3162/3162 - 0s - loss: 0.6305 - accuracy: 0.7663\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000022389284B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000022389284B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.3_epochs-10_it-8\\assets\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_76 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_76 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_77 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_38 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.5100 - accuracy: 0.0073\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 414us/sample - loss: 1.1838 - accuracy: 0.5731 - val_loss: 0.9885 - val_accuracy: 0.6192\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 339us/sample - loss: 0.9062 - accuracy: 0.6467 - val_loss: 0.9841 - val_accuracy: 0.6360\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 333us/sample - loss: 0.8557 - accuracy: 0.6685 - val_loss: 0.9988 - val_accuracy: 0.6142\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 332us/sample - loss: 0.8305 - accuracy: 0.6752 - val_loss: 0.9122 - val_accuracy: 0.6543\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 0.8211 - accuracy: 0.6801 - val_loss: 0.9184 - val_accuracy: 0.6569\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.8079 - accuracy: 0.6813 - val_loss: 0.9032 - val_accuracy: 0.6518\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 0.7960 - accuracy: 0.6849 - val_loss: 0.9183 - val_accuracy: 0.6591\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 343us/sample - loss: 0.7895 - accuracy: 0.6892 - val_loss: 0.8820 - val_accuracy: 0.6622\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 332us/sample - loss: 0.7854 - accuracy: 0.6900 - val_loss: 0.8893 - val_accuracy: 0.6600\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 342us/sample - loss: 0.7753 - accuracy: 0.6922 - val_loss: 0.9507 - val_accuracy: 0.6556\n",
      "3162/3162 - 0s - loss: 0.9507 - accuracy: 0.6556\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223DF490798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223DF490798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.3_epochs-10_it-9\\assets\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_78 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_78 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_79 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_39 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4661 - accuracy: 0.1645\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 393us/sample - loss: 0.7035 - accuracy: 0.7415 - val_loss: 0.3185 - val_accuracy: 0.8966\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 343us/sample - loss: 0.2426 - accuracy: 0.9123 - val_loss: 0.3039 - val_accuracy: 0.8855\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 348us/sample - loss: 0.1667 - accuracy: 0.9412 - val_loss: 0.2303 - val_accuracy: 0.9156\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.1322 - accuracy: 0.9551 - val_loss: 0.2354 - val_accuracy: 0.9137\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 333us/sample - loss: 0.1235 - accuracy: 0.9557 - val_loss: 0.2988 - val_accuracy: 0.8985\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 340us/sample - loss: 0.1118 - accuracy: 0.9605 - val_loss: 0.3712 - val_accuracy: 0.8915\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 363us/sample - loss: 0.1056 - accuracy: 0.9633 - val_loss: 0.2006 - val_accuracy: 0.9304\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 354us/sample - loss: 0.0852 - accuracy: 0.9726 - val_loss: 0.2119 - val_accuracy: 0.9301\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 386us/sample - loss: 0.0854 - accuracy: 0.9708 - val_loss: 0.1996 - val_accuracy: 0.9380\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 330us/sample - loss: 0.0849 - accuracy: 0.9709 - val_loss: 0.2173 - val_accuracy: 0.9323\n",
      "3162/3162 - 0s - loss: 0.2173 - accuracy: 0.9323\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002238AE86828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002238AE86828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.4_epochs-10_it-0\\assets\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_80 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_80 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_81 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_40 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.5247 - accuracy: 0.0073\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 433us/sample - loss: 1.5096 - accuracy: 0.5391 - val_loss: 1.3185 - val_accuracy: 0.6588\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 419us/sample - loss: 1.1436 - accuracy: 0.7023 - val_loss: 1.1046 - val_accuracy: 0.7037\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 341us/sample - loss: 1.0752 - accuracy: 0.7319 - val_loss: 1.1280 - val_accuracy: 0.7103\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 375us/sample - loss: 1.0381 - accuracy: 0.7536 - val_loss: 1.0610 - val_accuracy: 0.7372\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 348us/sample - loss: 1.0082 - accuracy: 0.7658 - val_loss: 1.0471 - val_accuracy: 0.7410\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 343us/sample - loss: 0.9990 - accuracy: 0.7648 - val_loss: 1.0321 - val_accuracy: 0.7391\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 339us/sample - loss: 0.9931 - accuracy: 0.7680 - val_loss: 1.0613 - val_accuracy: 0.7438\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 354us/sample - loss: 0.9818 - accuracy: 0.7721 - val_loss: 1.0477 - val_accuracy: 0.7647\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 343us/sample - loss: 0.9826 - accuracy: 0.7725 - val_loss: 1.0614 - val_accuracy: 0.7394\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 353us/sample - loss: 0.9694 - accuracy: 0.7776 - val_loss: 1.0992 - val_accuracy: 0.7457\n",
      "3162/3162 - 0s - loss: 1.0992 - accuracy: 0.7457\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223A491A678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223A491A678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.4_epochs-10_it-1\\assets\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_82 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_82 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_83 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_41 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4793 - accuracy: 0.1202\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 431us/sample - loss: 1.4109 - accuracy: 0.5540 - val_loss: 1.0948 - val_accuracy: 0.6496\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 342us/sample - loss: 1.0059 - accuracy: 0.6604 - val_loss: 1.0253 - val_accuracy: 0.6490\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 351us/sample - loss: 0.9486 - accuracy: 0.6649 - val_loss: 0.9971 - val_accuracy: 0.6512\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 356us/sample - loss: 0.9143 - accuracy: 0.6645 - val_loss: 0.9516 - val_accuracy: 0.6553\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 374us/sample - loss: 0.9090 - accuracy: 0.6646 - val_loss: 0.9991 - val_accuracy: 0.6480\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.8924 - accuracy: 0.6665 - val_loss: 0.9895 - val_accuracy: 0.6455\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.8776 - accuracy: 0.6680 - val_loss: 0.9784 - val_accuracy: 0.6556\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 342us/sample - loss: 0.8752 - accuracy: 0.6668 - val_loss: 0.9847 - val_accuracy: 0.6550\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 347us/sample - loss: 0.8726 - accuracy: 0.6677 - val_loss: 1.0347 - val_accuracy: 0.6496\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 339us/sample - loss: 0.8650 - accuracy: 0.6682 - val_loss: 1.0188 - val_accuracy: 0.6546\n",
      "3162/3162 - 0s - loss: 1.0188 - accuracy: 0.6546\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223DF490CA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223DF490CA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.4_epochs-10_it-2\\assets\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_84 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_84 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_85 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_42 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4949 - accuracy: 0.0092\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 423us/sample - loss: 0.7504 - accuracy: 0.7112 - val_loss: 0.3910 - val_accuracy: 0.8643\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.2783 - accuracy: 0.8960 - val_loss: 0.2914 - val_accuracy: 0.9004\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 340us/sample - loss: 0.2119 - accuracy: 0.9215 - val_loss: 0.2569 - val_accuracy: 0.9092\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 353us/sample - loss: 0.1601 - accuracy: 0.9412 - val_loss: 0.5356 - val_accuracy: 0.8286\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 339us/sample - loss: 0.1373 - accuracy: 0.9486 - val_loss: 0.2487 - val_accuracy: 0.9178\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 348us/sample - loss: 0.1276 - accuracy: 0.9502 - val_loss: 0.2004 - val_accuracy: 0.9257\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 340us/sample - loss: 0.1134 - accuracy: 0.9566 - val_loss: 0.1941 - val_accuracy: 0.9298\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 343us/sample - loss: 0.1035 - accuracy: 0.9609 - val_loss: 0.2160 - val_accuracy: 0.9254\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 333us/sample - loss: 0.1096 - accuracy: 0.9593 - val_loss: 0.2346 - val_accuracy: 0.9194\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.0886 - accuracy: 0.9673 - val_loss: 0.2081 - val_accuracy: 0.9257\n",
      "3162/3162 - 0s - loss: 0.2081 - accuracy: 0.9257\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002239FBFFA68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002239FBFFA68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.4_epochs-10_it-3\\assets\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_86 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_86 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_87 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_87 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_43 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.5028 - accuracy: 0.0047\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 413us/sample - loss: 1.7419 - accuracy: 0.4238 - val_loss: 1.5816 - val_accuracy: 0.4567\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 358us/sample - loss: 1.4789 - accuracy: 0.4617 - val_loss: 1.4593 - val_accuracy: 0.4643\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 350us/sample - loss: 1.4249 - accuracy: 0.4661 - val_loss: 1.4455 - val_accuracy: 0.4617\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 350us/sample - loss: 1.4095 - accuracy: 0.4643 - val_loss: 1.5004 - val_accuracy: 0.4466\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 387us/sample - loss: 1.3914 - accuracy: 0.4666 - val_loss: 1.4889 - val_accuracy: 0.4614\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 351us/sample - loss: 1.3890 - accuracy: 0.4675 - val_loss: 1.4507 - val_accuracy: 0.4570\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 343us/sample - loss: 1.3745 - accuracy: 0.4676 - val_loss: 1.4832 - val_accuracy: 0.4598\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 359us/sample - loss: 1.3707 - accuracy: 0.4692 - val_loss: 1.4669 - val_accuracy: 0.4548\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 366us/sample - loss: 1.3645 - accuracy: 0.4680 - val_loss: 1.4831 - val_accuracy: 0.4564\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 343us/sample - loss: 1.3654 - accuracy: 0.4693 - val_loss: 1.4706 - val_accuracy: 0.4564\n",
      "3162/3162 - 0s - loss: 1.4706 - accuracy: 0.4564\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223A4EC9948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223A4EC9948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.4_epochs-10_it-4\\assets\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_88 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_88 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_89 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_44 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4736 - accuracy: 0.1322\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 411us/sample - loss: 0.6462 - accuracy: 0.7621 - val_loss: 0.3338 - val_accuracy: 0.8798oss: 0.745\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 353us/sample - loss: 0.2665 - accuracy: 0.9029 - val_loss: 0.2386 - val_accuracy: 0.9197\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 342us/sample - loss: 0.1957 - accuracy: 0.9274 - val_loss: 0.2728 - val_accuracy: 0.9045\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 360us/sample - loss: 0.1603 - accuracy: 0.9458 - val_loss: 0.2844 - val_accuracy: 0.8985\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 362us/sample - loss: 0.1485 - accuracy: 0.9471 - val_loss: 0.2400 - val_accuracy: 0.9168\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 344us/sample - loss: 0.1357 - accuracy: 0.9515 - val_loss: 0.2891 - val_accuracy: 0.9001\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.1248 - accuracy: 0.9561 - val_loss: 0.2286 - val_accuracy: 0.9235\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 339us/sample - loss: 0.1182 - accuracy: 0.9573 - val_loss: 0.2649 - val_accuracy: 0.9168\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 341us/sample - loss: 0.1117 - accuracy: 0.9578 - val_loss: 0.2449 - val_accuracy: 0.9231\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 347us/sample - loss: 0.1066 - accuracy: 0.9619 - val_loss: 0.2385 - val_accuracy: 0.9266\n",
      "3162/3162 - 0s - loss: 0.2385 - accuracy: 0.9266\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223935BB168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223935BB168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.4_epochs-10_it-5\\assets\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_90 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_90 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_91 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_91 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_45 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_135 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4869 - accuracy: 0.0351\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 420us/sample - loss: 0.7117 - accuracy: 0.7388 - val_loss: 0.3870 - val_accuracy: 0.8469\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 350us/sample - loss: 0.2762 - accuracy: 0.8984 - val_loss: 0.3036 - val_accuracy: 0.8937\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 333us/sample - loss: 0.2405 - accuracy: 0.9154 - val_loss: 0.2958 - val_accuracy: 0.8906\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 364us/sample - loss: 0.1965 - accuracy: 0.9307 - val_loss: 0.2773 - val_accuracy: 0.9039\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 345us/sample - loss: 0.1739 - accuracy: 0.9424 - val_loss: 0.3000 - val_accuracy: 0.9001\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 333us/sample - loss: 0.1543 - accuracy: 0.9503 - val_loss: 0.2969 - val_accuracy: 0.8988\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 359us/sample - loss: 0.1540 - accuracy: 0.9464 - val_loss: 0.3172 - val_accuracy: 0.8925\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.1476 - accuracy: 0.9497 - val_loss: 0.2793 - val_accuracy: 0.9092\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 342us/sample - loss: 0.1302 - accuracy: 0.9552 - val_loss: 0.3219 - val_accuracy: 0.8994\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 358us/sample - loss: 0.1260 - accuracy: 0.9558 - val_loss: 0.3477 - val_accuracy: 0.8931\n",
      "3162/3162 - 0s - loss: 0.3477 - accuracy: 0.8931\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223935A7E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223935A7E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.4_epochs-10_it-6\\assets\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_92 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_92 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_93 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_93 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_46 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_139 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_140 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4743 - accuracy: 0.1989\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 398us/sample - loss: 0.6373 - accuracy: 0.7619 - val_loss: 0.3659 - val_accuracy: 0.8640\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.2650 - accuracy: 0.9097 - val_loss: 0.3030 - val_accuracy: 0.8915\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.2076 - accuracy: 0.9279 - val_loss: 0.2617 - val_accuracy: 0.9092\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 333us/sample - loss: 0.1671 - accuracy: 0.9448 - val_loss: 0.2711 - val_accuracy: 0.9127\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 331us/sample - loss: 0.1581 - accuracy: 0.9468 - val_loss: 0.2443 - val_accuracy: 0.9187\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 381us/sample - loss: 0.1496 - accuracy: 0.9481 - val_loss: 0.2533 - val_accuracy: 0.9162\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 357us/sample - loss: 0.1391 - accuracy: 0.9525 - val_loss: 0.2973 - val_accuracy: 0.9045\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 339us/sample - loss: 0.1382 - accuracy: 0.9502 - val_loss: 0.2285 - val_accuracy: 0.9269\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 350us/sample - loss: 0.1361 - accuracy: 0.9526 - val_loss: 0.2791 - val_accuracy: 0.9159\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 329us/sample - loss: 0.1238 - accuracy: 0.9544 - val_loss: 0.3070 - val_accuracy: 0.9077\n",
      "3162/3162 - 0s - loss: 0.3070 - accuracy: 0.9077\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000022399173318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000022399173318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.4_epochs-10_it-7\\assets\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_94 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_94 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_95 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_95 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_47 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_141 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_142 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_143 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4733 - accuracy: 0.0689\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 393us/sample - loss: 0.6830 - accuracy: 0.7522 - val_loss: 0.4151 - val_accuracy: 0.8302\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 332us/sample - loss: 0.2579 - accuracy: 0.9036 - val_loss: 0.3342 - val_accuracy: 0.8824\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 331us/sample - loss: 0.1854 - accuracy: 0.9336 - val_loss: 0.2488 - val_accuracy: 0.9175\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 330us/sample - loss: 0.1582 - accuracy: 0.9444 - val_loss: 0.2043 - val_accuracy: 0.9292\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 352us/sample - loss: 0.1409 - accuracy: 0.9503 - val_loss: 0.2313 - val_accuracy: 0.9190\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 340us/sample - loss: 0.1288 - accuracy: 0.9540 - val_loss: 0.2738 - val_accuracy: 0.9070\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.1168 - accuracy: 0.9597 - val_loss: 0.2212 - val_accuracy: 0.9241\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 331us/sample - loss: 0.1058 - accuracy: 0.9621 - val_loss: 0.2413 - val_accuracy: 0.9203\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 361us/sample - loss: 0.1014 - accuracy: 0.9619 - val_loss: 0.2153 - val_accuracy: 0.9304\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 397us/sample - loss: 0.1030 - accuracy: 0.9620 - val_loss: 0.2332 - val_accuracy: 0.9238\n",
      "3162/3162 - 0s - loss: 0.2332 - accuracy: 0.9238\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223A512A708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223A512A708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.4_epochs-10_it-8\\assets\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_96 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_96 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_97 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_48 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_145 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4856 - accuracy: 0.0066\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 440us/sample - loss: 0.6139 - accuracy: 0.7805 - val_loss: 0.3053 - val_accuracy: 0.8953\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 333us/sample - loss: 0.2378 - accuracy: 0.9190 - val_loss: 0.2263 - val_accuracy: 0.9219\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 353us/sample - loss: 0.1818 - accuracy: 0.9386 - val_loss: 0.3370 - val_accuracy: 0.8760\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 357us/sample - loss: 0.1562 - accuracy: 0.9452 - val_loss: 0.2487 - val_accuracy: 0.9130\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 339us/sample - loss: 0.1356 - accuracy: 0.9527 - val_loss: 0.2008 - val_accuracy: 0.9320\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 365us/sample - loss: 0.1237 - accuracy: 0.9571 - val_loss: 0.2366 - val_accuracy: 0.9190\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 346us/sample - loss: 0.1117 - accuracy: 0.9611 - val_loss: 0.2954 - val_accuracy: 0.9016\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 342us/sample - loss: 0.0983 - accuracy: 0.9629 - val_loss: 0.2139 - val_accuracy: 0.9314\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 340us/sample - loss: 0.0998 - accuracy: 0.9634 - val_loss: 0.2492 - val_accuracy: 0.9175\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 331us/sample - loss: 0.1008 - accuracy: 0.9629 - val_loss: 0.2068 - val_accuracy: 0.9304\n",
      "3162/3162 - 0s - loss: 0.2068 - accuracy: 0.9304\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223DF0DB168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223DF0DB168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.4_epochs-10_it-9\\assets\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-0\n",
      "3162/3162 - 1s - loss: 0.6135 - accuracy: 0.9247\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-1\n",
      "3162/3162 - 1s - loss: 0.5921 - accuracy: 0.7875\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-2\n",
      "3162/3162 - 1s - loss: 0.2480 - accuracy: 0.9187\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-3\n",
      "3162/3162 - 1s - loss: 0.9100 - accuracy: 0.6610\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-4\n",
      "3162/3162 - 1s - loss: 0.6608 - accuracy: 0.8877\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-5\n",
      "3162/3162 - 1s - loss: 0.7964 - accuracy: 0.7239\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-6\n",
      "3162/3162 - 1s - loss: 0.6462 - accuracy: 0.7612\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-7\n",
      "3162/3162 - 1s - loss: 1.0570 - accuracy: 0.7375\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-8\n",
      "3162/3162 - 1s - loss: 1.0262 - accuracy: 0.6195\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-9\n",
      "3162/3162 - 1s - loss: 0.2868 - accuracy: 0.9130\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_98 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_98 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_99 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_99 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_49 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_147 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_148 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_149 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4776 - accuracy: 0.1366\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "7767/7767 [==============================] - 4s 508us/sample - loss: 1.4445 - accuracy: 0.5723 - val_loss: 1.1660 - val_accuracy: 0.7075\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 4s 501us/sample - loss: 1.1148 - accuracy: 0.7191 - val_loss: 1.1089 - val_accuracy: 0.6847\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 4s 478us/sample - loss: 1.0511 - accuracy: 0.7440 - val_loss: 1.0515 - val_accuracy: 0.7559\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 4s 474us/sample - loss: 1.0347 - accuracy: 0.7567 - val_loss: 1.0531 - val_accuracy: 0.7622\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 4s 465us/sample - loss: 1.0122 - accuracy: 0.7627 - val_loss: 1.0920 - val_accuracy: 0.7416\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 4s 459us/sample - loss: 1.0112 - accuracy: 0.7646 - val_loss: 1.1027 - val_accuracy: 0.7309\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 451us/sample - loss: 0.9912 - accuracy: 0.7726 - val_loss: 1.0553 - val_accuracy: 0.7388\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 4s 477us/sample - loss: 0.9937 - accuracy: 0.7686 - val_loss: 1.1537 - val_accuracy: 0.7337\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 4s 488us/sample - loss: 0.9796 - accuracy: 0.7743 - val_loss: 1.0317 - val_accuracy: 0.7644\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 4s 460us/sample - loss: 0.9744 - accuracy: 0.7758 - val_loss: 1.0578 - val_accuracy: 0.7609\n",
      "3162/3162 - 1s - loss: 1.0578 - accuracy: 0.7609\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000022399ACB5E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000022399ACB5E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.6_epochs-10_it-0\\assets\n",
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_100 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_100 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_101 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_50 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_150 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_151 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_152 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4866 - accuracy: 0.0259\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 4s 578us/sample - loss: 1.2466 - accuracy: 0.6172 - val_loss: 1.0900 - val_accuracy: 0.6869\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 382us/sample - loss: 0.9967 - accuracy: 0.7519 - val_loss: 1.0213 - val_accuracy: 0.7479\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 384us/sample - loss: 0.9528 - accuracy: 0.7766 - val_loss: 1.0197 - val_accuracy: 0.7505\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 382us/sample - loss: 0.9405 - accuracy: 0.7804 - val_loss: 1.0730 - val_accuracy: 0.7223\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 382us/sample - loss: 0.9197 - accuracy: 0.7900 - val_loss: 1.0559 - val_accuracy: 0.7460\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 429us/sample - loss: 0.9151 - accuracy: 0.7925 - val_loss: 0.9985 - val_accuracy: 0.7606\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 432us/sample - loss: 0.9109 - accuracy: 0.7930 - val_loss: 0.9798 - val_accuracy: 0.7679\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 4s 459us/sample - loss: 0.9002 - accuracy: 0.7955 - val_loss: 1.0374 - val_accuracy: 0.7543\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 437us/sample - loss: 0.8974 - accuracy: 0.8010 - val_loss: 0.9942 - val_accuracy: 0.7682\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 389us/sample - loss: 0.8933 - accuracy: 0.8001 - val_loss: 0.9937 - val_accuracy: 0.7682\n",
      "3162/3162 - 0s - loss: 0.9937 - accuracy: 0.7682\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223DED941F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223DED941F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.6_epochs-10_it-1\\assets\n",
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_102 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_102 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_103 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_103 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_51 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_153 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_154 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_155 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4667 - accuracy: 0.1063\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 5s 588us/sample - loss: 1.3565 - accuracy: 0.6226 - val_loss: 1.1070 - val_accuracy: 0.7157\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 4s 465us/sample - loss: 1.0755 - accuracy: 0.7381 - val_loss: 1.1059 - val_accuracy: 0.7596\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 4s 458us/sample - loss: 1.0264 - accuracy: 0.7628 - val_loss: 1.0834 - val_accuracy: 0.7625\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 4s 578us/sample - loss: 1.0066 - accuracy: 0.7694 - val_loss: 1.1317 - val_accuracy: 0.7283\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 447us/sample - loss: 0.9923 - accuracy: 0.7737 - val_loss: 1.0426 - val_accuracy: 0.7676\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 4s 461us/sample - loss: 0.9846 - accuracy: 0.7783 - val_loss: 1.0409 - val_accuracy: 0.7672\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 4s 460us/sample - loss: 0.9717 - accuracy: 0.7828 - val_loss: 1.0321 - val_accuracy: 0.7672\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 4s 465us/sample - loss: 0.9650 - accuracy: 0.7825 - val_loss: 1.0852 - val_accuracy: 0.7622\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 4s 496us/sample - loss: 0.9668 - accuracy: 0.7852 - val_loss: 1.0383 - val_accuracy: 0.7587\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 4s 528us/sample - loss: 0.9632 - accuracy: 0.7829 - val_loss: 1.0463 - val_accuracy: 0.7615\n",
      "3162/3162 - 1s - loss: 1.0463 - accuracy: 0.7615\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223A02FDC18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223A02FDC18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.6_epochs-10_it-2\\assets\n",
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_104 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_104 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_105 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_105 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_52 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_156 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4679 - accuracy: 0.1730\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 4s 510us/sample - loss: 1.3216 - accuracy: 0.5919 - val_loss: 1.0838 - val_accuracy: 0.6252\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 424us/sample - loss: 1.0198 - accuracy: 0.6534 - val_loss: 1.0643 - val_accuracy: 0.6316\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 4s 487us/sample - loss: 0.9731 - accuracy: 0.6559 - val_loss: 1.0001 - val_accuracy: 0.6414\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 447us/sample - loss: 0.9500 - accuracy: 0.6570 - val_loss: 1.0488 - val_accuracy: 0.6445\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 410us/sample - loss: 0.9336 - accuracy: 0.6601 - val_loss: 1.0070 - val_accuracy: 0.6363\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 351us/sample - loss: 0.9222 - accuracy: 0.6607 - val_loss: 0.9756 - val_accuracy: 0.6455\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 329us/sample - loss: 0.9105 - accuracy: 0.6613 - val_loss: 1.0032 - val_accuracy: 0.6417\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.9106 - accuracy: 0.6602 - val_loss: 0.9991 - val_accuracy: 0.6452\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 350us/sample - loss: 0.9041 - accuracy: 0.6606 - val_loss: 1.0123 - val_accuracy: 0.6385\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 333us/sample - loss: 0.9070 - accuracy: 0.6618 - val_loss: 0.9817 - val_accuracy: 0.6445\n",
      "3162/3162 - 0s - loss: 0.9817 - accuracy: 0.6445\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000022397A511F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000022397A511F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.6_epochs-10_it-3\\assets\n",
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_106 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_106 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_107 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_53 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_159 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_160 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_161 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4751 - accuracy: 0.1325\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 406us/sample - loss: 0.9531 - accuracy: 0.6643 - val_loss: 0.7561 - val_accuracy: 0.7252\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 341us/sample - loss: 0.6387 - accuracy: 0.7572 - val_loss: 0.6521 - val_accuracy: 0.7666\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 0.5807 - accuracy: 0.7762 - val_loss: 0.6501 - val_accuracy: 0.7615\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 330us/sample - loss: 0.5665 - accuracy: 0.7824 - val_loss: 0.6568 - val_accuracy: 0.7460\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.5524 - accuracy: 0.7855 - val_loss: 0.6291 - val_accuracy: 0.7647\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 330us/sample - loss: 0.5345 - accuracy: 0.7905 - val_loss: 0.6348 - val_accuracy: 0.7647\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.5279 - accuracy: 0.7936 - val_loss: 0.6807 - val_accuracy: 0.7555\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 0.5258 - accuracy: 0.7926 - val_loss: 0.6730 - val_accuracy: 0.7527\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.5160 - accuracy: 0.7975 - val_loss: 0.6674 - val_accuracy: 0.7460\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.5185 - accuracy: 0.7958 - val_loss: 0.6125 - val_accuracy: 0.7701\n",
      "3162/3162 - 0s - loss: 0.6125 - accuracy: 0.7701\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223978443A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223978443A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.6_epochs-10_it-4\\assets\n",
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_108 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_108 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_109 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_109 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_54 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_162 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_163 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_164 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4669 - accuracy: 0.2018\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 401us/sample - loss: 0.6730 - accuracy: 0.7489 - val_loss: 0.4603 - val_accuracy: 0.7960\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 330us/sample - loss: 0.3091 - accuracy: 0.8859 - val_loss: 0.2841 - val_accuracy: 0.8975\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 0.2551 - accuracy: 0.9025 - val_loss: 0.3033 - val_accuracy: 0.8814\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.2312 - accuracy: 0.9132 - val_loss: 0.3624 - val_accuracy: 0.8669\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 0.2101 - accuracy: 0.9203 - val_loss: 0.3180 - val_accuracy: 0.8833\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 332us/sample - loss: 0.1987 - accuracy: 0.9247 - val_loss: 0.2849 - val_accuracy: 0.8915\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 344us/sample - loss: 0.1941 - accuracy: 0.9240 - val_loss: 0.2609 - val_accuracy: 0.9016\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 329us/sample - loss: 0.1774 - accuracy: 0.9301 - val_loss: 0.2822 - val_accuracy: 0.8991\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.1754 - accuracy: 0.9325 - val_loss: 0.2736 - val_accuracy: 0.8991\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 329us/sample - loss: 0.1784 - accuracy: 0.9315 - val_loss: 0.3233 - val_accuracy: 0.8884\n",
      "3162/3162 - 0s - loss: 0.3233 - accuracy: 0.8884\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002239FE40558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002239FE40558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.6_epochs-10_it-5\\assets\n",
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_110 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_110 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_111 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_111 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_55 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_165 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_166 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_167 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.5036 - accuracy: 0.0092\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 399us/sample - loss: 1.5296 - accuracy: 0.4999 - val_loss: 1.2632 - val_accuracy: 0.5468\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 330us/sample - loss: 1.1956 - accuracy: 0.5758 - val_loss: 1.1688 - val_accuracy: 0.5787\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 1.1325 - accuracy: 0.5848 - val_loss: 1.1346 - val_accuracy: 0.5848\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 330us/sample - loss: 1.1149 - accuracy: 0.5853 - val_loss: 1.1756 - val_accuracy: 0.5658\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 1.0917 - accuracy: 0.5898 - val_loss: 1.0897 - val_accuracy: 0.5886\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 1.0866 - accuracy: 0.5913 - val_loss: 1.1352 - val_accuracy: 0.5718\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 1.0712 - accuracy: 0.5924 - val_loss: 1.0844 - val_accuracy: 0.5876\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 330us/sample - loss: 1.0756 - accuracy: 0.5926 - val_loss: 1.0992 - val_accuracy: 0.5860\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 333us/sample - loss: 1.0688 - accuracy: 0.5924 - val_loss: 1.0908 - val_accuracy: 0.5889\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 1.0538 - accuracy: 0.5941 - val_loss: 1.1293 - val_accuracy: 0.5753\n",
      "3162/3162 - 0s - loss: 1.1293 - accuracy: 0.5753\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223E71DC708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223E71DC708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.6_epochs-10_it-6\\assets\n",
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_112 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_112 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_113 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_113 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_56 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_168 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_169 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_170 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4672 - accuracy: 0.2954\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 418us/sample - loss: 1.0463 - accuracy: 0.6265 - val_loss: 0.5182 - val_accuracy: 0.7903\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 0.3135 - accuracy: 0.8850 - val_loss: 0.3239 - val_accuracy: 0.8716\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 346us/sample - loss: 0.2562 - accuracy: 0.9063 - val_loss: 0.2740 - val_accuracy: 0.8972\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.2233 - accuracy: 0.9173 - val_loss: 0.2560 - val_accuracy: 0.9089\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 329us/sample - loss: 0.2129 - accuracy: 0.9204 - val_loss: 0.2915 - val_accuracy: 0.8994\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 330us/sample - loss: 0.1925 - accuracy: 0.9285 - val_loss: 0.2783 - val_accuracy: 0.8953\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.1908 - accuracy: 0.9303 - val_loss: 0.2987 - val_accuracy: 0.8960\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.1789 - accuracy: 0.9341 - val_loss: 0.2623 - val_accuracy: 0.9010\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 330us/sample - loss: 0.1682 - accuracy: 0.9370 - val_loss: 0.2319 - val_accuracy: 0.9156\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.1649 - accuracy: 0.9385 - val_loss: 0.2277 - val_accuracy: 0.9213\n",
      "3162/3162 - 0s - loss: 0.2277 - accuracy: 0.9213\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223B30F58B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223B30F58B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.6_epochs-10_it-7\\assets\n",
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_114 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_114 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_115 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_57 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_171 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_172 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_173 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.5003 - accuracy: 0.0082\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 400us/sample - loss: 1.8585 - accuracy: 0.3380 - val_loss: 1.4994 - val_accuracy: 0.4364\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 330us/sample - loss: 1.3828 - accuracy: 0.4697 - val_loss: 1.3671 - val_accuracy: 0.4801\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 1.3462 - accuracy: 0.4770 - val_loss: 1.3454 - val_accuracy: 0.4807\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 1.3338 - accuracy: 0.4795 - val_loss: 1.4196 - val_accuracy: 0.4734\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 1.3251 - accuracy: 0.4804 - val_loss: 1.3480 - val_accuracy: 0.4820\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 1.3201 - accuracy: 0.4800 - val_loss: 1.3625 - val_accuracy: 0.4826\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 1.3163 - accuracy: 0.4819 - val_loss: 1.3434 - val_accuracy: 0.4826\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 1.3134 - accuracy: 0.4827 - val_loss: 1.4032 - val_accuracy: 0.4756\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 1.3058 - accuracy: 0.4826 - val_loss: 1.3451 - val_accuracy: 0.4798\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 1.3060 - accuracy: 0.4833 - val_loss: 1.3516 - val_accuracy: 0.4813\n",
      "3162/3162 - 0s - loss: 1.3516 - accuracy: 0.4813\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223B3168A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223B3168A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.6_epochs-10_it-8\\assets\n",
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_116 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_116 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_117 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_117 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_58 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_174 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_175 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_176 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4948 - accuracy: 0.0133\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 400us/sample - loss: 0.7543 - accuracy: 0.7160 - val_loss: 0.3659 - val_accuracy: 0.8659\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 331us/sample - loss: 0.3066 - accuracy: 0.8867 - val_loss: 0.3132 - val_accuracy: 0.8691\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.2234 - accuracy: 0.9206 - val_loss: 0.2790 - val_accuracy: 0.9039\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.1940 - accuracy: 0.9318 - val_loss: 0.2535 - val_accuracy: 0.9080\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.1689 - accuracy: 0.9410 - val_loss: 0.3518 - val_accuracy: 0.8843\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 0.1557 - accuracy: 0.9448 - val_loss: 0.2125 - val_accuracy: 0.9231\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 329us/sample - loss: 0.1405 - accuracy: 0.9511 - val_loss: 0.2060 - val_accuracy: 0.9269\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.1241 - accuracy: 0.9555 - val_loss: 0.2527 - val_accuracy: 0.9143\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 329us/sample - loss: 0.1257 - accuracy: 0.9542 - val_loss: 0.2400 - val_accuracy: 0.9228\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.1142 - accuracy: 0.9588 - val_loss: 0.2010 - val_accuracy: 0.9326\n",
      "3162/3162 - 0s - loss: 0.2010 - accuracy: 0.9326\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223B3397C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223B3397C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.6_epochs-10_it-9\\assets\n",
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_118 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_118 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_119 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_59 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_177 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_178 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4675 - accuracy: 0.1622\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 397us/sample - loss: 0.7149 - accuracy: 0.7260 - val_loss: 0.3935 - val_accuracy: 0.8624\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 331us/sample - loss: 0.3418 - accuracy: 0.8808 - val_loss: 0.2862 - val_accuracy: 0.8950\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.2668 - accuracy: 0.9037 - val_loss: 0.2266 - val_accuracy: 0.9273\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.2309 - accuracy: 0.9159 - val_loss: 0.2458 - val_accuracy: 0.9184\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 339us/sample - loss: 0.1973 - accuracy: 0.9309 - val_loss: 0.2315 - val_accuracy: 0.9181\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 0.1812 - accuracy: 0.9347 - val_loss: 0.2514 - val_accuracy: 0.9108\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.1785 - accuracy: 0.9374 - val_loss: 0.2107 - val_accuracy: 0.9276\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 0.1557 - accuracy: 0.9466 - val_loss: 0.2345 - val_accuracy: 0.9165\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.1442 - accuracy: 0.9486 - val_loss: 0.1880 - val_accuracy: 0.9371\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 329us/sample - loss: 0.1361 - accuracy: 0.9489 - val_loss: 0.3056 - val_accuracy: 0.9035\n",
      "3162/3162 - 0s - loss: 0.3056 - accuracy: 0.9035\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223B3598DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223B3598DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.7_epochs-10_it-0\\assets\n",
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_120 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_120 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_121 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_60 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_180 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_181 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_182 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4828 - accuracy: 0.1037\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 400us/sample - loss: 1.2548 - accuracy: 0.5362 - val_loss: 1.0114 - val_accuracy: 0.6173\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.9631 - accuracy: 0.6273 - val_loss: 0.9715 - val_accuracy: 0.6354\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 342us/sample - loss: 0.9117 - accuracy: 0.6463 - val_loss: 0.9402 - val_accuracy: 0.6401\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 333us/sample - loss: 0.7894 - accuracy: 0.7108 - val_loss: 0.6928 - val_accuracy: 0.7748\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 331us/sample - loss: 0.5823 - accuracy: 0.7887 - val_loss: 0.6723 - val_accuracy: 0.7834\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.5519 - accuracy: 0.7967 - val_loss: 0.6162 - val_accuracy: 0.7796\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 325us/sample - loss: 0.5384 - accuracy: 0.7984 - val_loss: 0.6171 - val_accuracy: 0.7929\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 340us/sample - loss: 0.5163 - accuracy: 0.8047 - val_loss: 0.6250 - val_accuracy: 0.7824\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 330us/sample - loss: 0.5143 - accuracy: 0.8065 - val_loss: 0.6118 - val_accuracy: 0.7840\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.5099 - accuracy: 0.8071 - val_loss: 0.5966 - val_accuracy: 0.7859\n",
      "3162/3162 - 0s - loss: 0.5966 - accuracy: 0.7859\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223B366AF78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223B366AF78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.7_epochs-10_it-1\\assets\n",
      "Model: \"sequential_61\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_122 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_122 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_123 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_61 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_183 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_184 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_185 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4843 - accuracy: 0.0443\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 397us/sample - loss: 1.1358 - accuracy: 0.6493 - val_loss: 0.8032 - val_accuracy: 0.7454\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 330us/sample - loss: 0.7874 - accuracy: 0.7456 - val_loss: 0.9483 - val_accuracy: 0.6626\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.7301 - accuracy: 0.7574 - val_loss: 0.7693 - val_accuracy: 0.7404\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 339us/sample - loss: 0.6830 - accuracy: 0.7627 - val_loss: 0.7423 - val_accuracy: 0.7337\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 343us/sample - loss: 0.6702 - accuracy: 0.7626 - val_loss: 0.6914 - val_accuracy: 0.7571\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 0.6615 - accuracy: 0.7688 - val_loss: 0.7840 - val_accuracy: 0.7321\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 0.6536 - accuracy: 0.7690 - val_loss: 0.6933 - val_accuracy: 0.7533\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.6399 - accuracy: 0.7715 - val_loss: 0.6763 - val_accuracy: 0.7549\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.6409 - accuracy: 0.7711 - val_loss: 0.6974 - val_accuracy: 0.7486\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 325us/sample - loss: 0.6332 - accuracy: 0.7716 - val_loss: 0.7667 - val_accuracy: 0.7362\n",
      "3162/3162 - 0s - loss: 0.7667 - accuracy: 0.7362\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223B3BAA168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223B3BAA168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.7_epochs-10_it-2\\assets\n",
      "Model: \"sequential_62\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_124 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_124 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_125 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_62 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_186 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_187 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_188 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4998 - accuracy: 0.0108\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 399us/sample - loss: 1.3748 - accuracy: 0.5810 - val_loss: 1.1031 - val_accuracy: 0.6256\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 330us/sample - loss: 1.0859 - accuracy: 0.6408 - val_loss: 1.0831 - val_accuracy: 0.6221\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 333us/sample - loss: 1.0364 - accuracy: 0.6425 - val_loss: 1.0719 - val_accuracy: 0.6139\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 1.0009 - accuracy: 0.6432 - val_loss: 1.0226 - val_accuracy: 0.6243\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.9864 - accuracy: 0.6439 - val_loss: 1.0294 - val_accuracy: 0.6246\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.9650 - accuracy: 0.6450 - val_loss: 1.0133 - val_accuracy: 0.6227\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.9746 - accuracy: 0.6447 - val_loss: 1.0067 - val_accuracy: 0.6259\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.9562 - accuracy: 0.6449 - val_loss: 1.1128 - val_accuracy: 0.6015\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.9558 - accuracy: 0.6443 - val_loss: 0.9905 - val_accuracy: 0.6268\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.9487 - accuracy: 0.6450 - val_loss: 0.9826 - val_accuracy: 0.6306\n",
      "3162/3162 - 0s - loss: 0.9826 - accuracy: 0.6306\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223B3BCA318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223B3BCA318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.7_epochs-10_it-3\\assets\n",
      "Model: \"sequential_63\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_126 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_126 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_127 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_127 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_63 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_189 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_190 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_191 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4917 - accuracy: 0.0032\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 399us/sample - loss: 1.4993 - accuracy: 0.5032 - val_loss: 1.2411 - val_accuracy: 0.6161\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 329us/sample - loss: 1.1553 - accuracy: 0.6669 - val_loss: 1.1270 - val_accuracy: 0.7170\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 1.0904 - accuracy: 0.7053 - val_loss: 1.1073 - val_accuracy: 0.7163\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 1.0604 - accuracy: 0.7229 - val_loss: 1.0889 - val_accuracy: 0.7065\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 1.0561 - accuracy: 0.7243 - val_loss: 1.0808 - val_accuracy: 0.7283\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 1.0392 - accuracy: 0.7304 - val_loss: 1.1156 - val_accuracy: 0.6670\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 1.0396 - accuracy: 0.7322 - val_loss: 1.0631 - val_accuracy: 0.7337\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 1.0196 - accuracy: 0.7425 - val_loss: 1.0581 - val_accuracy: 0.7404\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 1.0157 - accuracy: 0.7443 - val_loss: 1.0432 - val_accuracy: 0.7309\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 1.0167 - accuracy: 0.7446 - val_loss: 1.0540 - val_accuracy: 0.7287\n",
      "3162/3162 - 0s - loss: 1.0540 - accuracy: 0.7287\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223B3CA14C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223B3CA14C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.7_epochs-10_it-4\\assets\n",
      "Model: \"sequential_64\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_128 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_128 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_129 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_129 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_64 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_192 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_193 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_194 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4844 - accuracy: 0.1480\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 397us/sample - loss: 1.3538 - accuracy: 0.5944 - val_loss: 1.1624 - val_accuracy: 0.6044\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 330us/sample - loss: 1.0475 - accuracy: 0.6533 - val_loss: 1.0521 - val_accuracy: 0.6357\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.9938 - accuracy: 0.6582 - val_loss: 1.0372 - val_accuracy: 0.6357\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.9493 - accuracy: 0.6645 - val_loss: 1.0049 - val_accuracy: 0.6471\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 332us/sample - loss: 0.9367 - accuracy: 0.6659 - val_loss: 0.9751 - val_accuracy: 0.6509\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 342us/sample - loss: 0.9145 - accuracy: 0.6685 - val_loss: 1.0152 - val_accuracy: 0.6382\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.9112 - accuracy: 0.6685 - val_loss: 0.9596 - val_accuracy: 0.6569\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 325us/sample - loss: 0.8988 - accuracy: 0.6698 - val_loss: 0.9863 - val_accuracy: 0.6448\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 0.7814 - accuracy: 0.7147 - val_loss: 0.5557 - val_accuracy: 0.7938\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 0.4929 - accuracy: 0.8119 - val_loss: 0.6083 - val_accuracy: 0.7802\n",
      "3162/3162 - 0s - loss: 0.6083 - accuracy: 0.7802\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223D46E8678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223D46E8678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.7_epochs-10_it-5\\assets\n",
      "Model: \"sequential_65\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_130 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_130 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_131 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_131 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_65 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_195 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_196 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_197 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4919 - accuracy: 0.0345\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 395us/sample - loss: 1.0884 - accuracy: 0.6073 - val_loss: 0.7467 - val_accuracy: 0.7340\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 329us/sample - loss: 0.6741 - accuracy: 0.7527 - val_loss: 0.6648 - val_accuracy: 0.7612\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 332us/sample - loss: 0.6094 - accuracy: 0.7710 - val_loss: 0.6798 - val_accuracy: 0.7464\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.5864 - accuracy: 0.7811 - val_loss: 0.6485 - val_accuracy: 0.7647\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 325us/sample - loss: 0.5701 - accuracy: 0.7867 - val_loss: 0.6636 - val_accuracy: 0.7479\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 329us/sample - loss: 0.5587 - accuracy: 0.7908 - val_loss: 0.6866 - val_accuracy: 0.7460\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.5490 - accuracy: 0.7907 - val_loss: 0.6165 - val_accuracy: 0.7679\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.5390 - accuracy: 0.7930 - val_loss: 0.6277 - val_accuracy: 0.7615\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.5385 - accuracy: 0.7955 - val_loss: 0.6328 - val_accuracy: 0.7657\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.5312 - accuracy: 0.7979 - val_loss: 0.6918 - val_accuracy: 0.7527\n",
      "3162/3162 - 0s - loss: 0.6918 - accuracy: 0.7527\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223D48D9828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223D48D9828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.7_epochs-10_it-6\\assets\n",
      "Model: \"sequential_66\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_132 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_132 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_133 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_133 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_66 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_198 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_199 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_200 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4895 - accuracy: 0.0468\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 398us/sample - loss: 0.7752 - accuracy: 0.7058 - val_loss: 0.4134 - val_accuracy: 0.8409\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 330us/sample - loss: 0.3523 - accuracy: 0.8702 - val_loss: 0.3553 - val_accuracy: 0.8694\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 332us/sample - loss: 0.2778 - accuracy: 0.8978 - val_loss: 0.3602 - val_accuracy: 0.8637\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 0.2492 - accuracy: 0.9090 - val_loss: 0.2918 - val_accuracy: 0.8963\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.2286 - accuracy: 0.9186 - val_loss: 0.3029 - val_accuracy: 0.8896\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.2212 - accuracy: 0.9208 - val_loss: 0.2687 - val_accuracy: 0.8988\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.2045 - accuracy: 0.9258 - val_loss: 0.2564 - val_accuracy: 0.9035\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 325us/sample - loss: 0.2008 - accuracy: 0.9257 - val_loss: 0.2605 - val_accuracy: 0.9029\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.1996 - accuracy: 0.9264 - val_loss: 0.2507 - val_accuracy: 0.9156\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.1927 - accuracy: 0.9291 - val_loss: 0.2635 - val_accuracy: 0.9045\n",
      "3162/3162 - 0s - loss: 0.2635 - accuracy: 0.9045\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223D4CFD9D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223D4CFD9D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.7_epochs-10_it-7\\assets\n",
      "Model: \"sequential_67\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_134 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_134 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_135 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_135 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_67 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_201 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_202 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_203 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4790 - accuracy: 0.0104\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 399us/sample - loss: 1.1687 - accuracy: 0.5888 - val_loss: 0.7998 - val_accuracy: 0.7043\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 342us/sample - loss: 0.7838 - accuracy: 0.7000 - val_loss: 0.7232 - val_accuracy: 0.7249\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 351us/sample - loss: 0.3684 - accuracy: 0.8662 - val_loss: 0.2819 - val_accuracy: 0.8928\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.2565 - accuracy: 0.9074 - val_loss: 0.2602 - val_accuracy: 0.9035\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.2295 - accuracy: 0.9191 - val_loss: 0.3091 - val_accuracy: 0.8890\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.2212 - accuracy: 0.9171 - val_loss: 0.2909 - val_accuracy: 0.8960\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.2149 - accuracy: 0.9212 - val_loss: 0.3403 - val_accuracy: 0.8874\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 0.1997 - accuracy: 0.9274 - val_loss: 0.2532 - val_accuracy: 0.9118\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.1981 - accuracy: 0.9258 - val_loss: 0.2992 - val_accuracy: 0.8931\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.1987 - accuracy: 0.9256 - val_loss: 0.2629 - val_accuracy: 0.9045\n",
      "3162/3162 - 0s - loss: 0.2629 - accuracy: 0.9045\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223D4ED4B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223D4ED4B88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.7_epochs-10_it-8\\assets\n",
      "Model: \"sequential_68\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_136 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_136 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_137 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_137 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_68 (Flatten)         (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_204 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_205 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_206 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4838 - accuracy: 0.0357\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 400us/sample - loss: 1.1253 - accuracy: 0.6445 - val_loss: 0.9104 - val_accuracy: 0.7135\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 330us/sample - loss: 0.7650 - accuracy: 0.7495 - val_loss: 0.7516 - val_accuracy: 0.7479\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.6989 - accuracy: 0.7649 - val_loss: 0.7578 - val_accuracy: 0.7413\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 0.6740 - accuracy: 0.7695 - val_loss: 0.6895 - val_accuracy: 0.7596\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.6702 - accuracy: 0.7675 - val_loss: 0.6807 - val_accuracy: 0.7625\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.6460 - accuracy: 0.7739 - val_loss: 0.6836 - val_accuracy: 0.7612\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.6415 - accuracy: 0.7762 - val_loss: 0.7037 - val_accuracy: 0.7536\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 332us/sample - loss: 0.6278 - accuracy: 0.7769 - val_loss: 0.7178 - val_accuracy: 0.7502\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 341us/sample - loss: 0.6223 - accuracy: 0.7769 - val_loss: 0.7227 - val_accuracy: 0.7460\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.6210 - accuracy: 0.7757 - val_loss: 0.7488 - val_accuracy: 0.7410\n",
      "3162/3162 - 0s - loss: 0.7488 - accuracy: 0.7410\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223D4AB0318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223D4AB0318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.7_epochs-10_it-9\\assets\n"
     ]
    }
   ],
   "source": [
    "dropout_data = runner.test_param(dropout = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#runner.print_results(dropout_data, 'dropout')\n",
    "runner.plot_results(dropout_data, 'dropout')\n",
    "plt.savefig(\"plots/dropout-0-to-0.7.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_69\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_138 (Conv1D)          (None, 560, 64)           192       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_138 (MaxPoolin (None, 280, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_139 (Conv1D)          (None, 279, 64)           8256      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_139 (MaxPoolin (None, 139, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 139, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_69 (Flatten)         (None, 8896)              0         \n",
      "_________________________________________________________________\n",
      "dense_207 (Dense)            (None, 64)                569408    \n",
      "_________________________________________________________________\n",
      "dense_208 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_209 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,332\n",
      "Trainable params: 580,332\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4847 - accuracy: 0.0367\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 399us/sample - loss: 1.8741 - accuracy: 0.3965 - val_loss: 1.4960 - val_accuracy: 0.6309\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 323us/sample - loss: 1.0660 - accuracy: 0.7245 - val_loss: 1.0389 - val_accuracy: 0.7236\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 325us/sample - loss: 0.9435 - accuracy: 0.7828 - val_loss: 1.0064 - val_accuracy: 0.7296\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 2s 321us/sample - loss: 0.9167 - accuracy: 0.7909 - val_loss: 0.9997 - val_accuracy: 0.7688\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 2s 319us/sample - loss: 0.9043 - accuracy: 0.7981 - val_loss: 0.9879 - val_accuracy: 0.7726\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 2s 318us/sample - loss: 0.8904 - accuracy: 0.8075 - val_loss: 0.9872 - val_accuracy: 0.7717\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 2s 318us/sample - loss: 0.8869 - accuracy: 0.8042 - val_loss: 1.0057 - val_accuracy: 0.7713\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 2s 321us/sample - loss: 0.8757 - accuracy: 0.8080 - val_loss: 0.9869 - val_accuracy: 0.7751\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 2s 319us/sample - loss: 0.8723 - accuracy: 0.8137 - val_loss: 1.0296 - val_accuracy: 0.7657\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 2s 319us/sample - loss: 0.8735 - accuracy: 0.8116 - val_loss: 1.0493 - val_accuracy: 0.7543\n",
      "3162/3162 - 0s - loss: 1.0493 - accuracy: 0.7543\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223A0771DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223A0771DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-2_dropout-0.5_epochs-10_it-0\\assets\n",
      "Model: \"sequential_70\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_140 (Conv1D)          (None, 560, 64)           192       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_140 (MaxPoolin (None, 280, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_141 (Conv1D)          (None, 279, 64)           8256      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_141 (MaxPoolin (None, 139, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 139, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_70 (Flatten)         (None, 8896)              0         \n",
      "_________________________________________________________________\n",
      "dense_210 (Dense)            (None, 64)                569408    \n",
      "_________________________________________________________________\n",
      "dense_211 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_212 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,332\n",
      "Trainable params: 580,332\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4793 - accuracy: 0.1730\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 386us/sample - loss: 1.4293 - accuracy: 0.5544 - val_loss: 1.1366 - val_accuracy: 0.6142\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 341us/sample - loss: 1.0610 - accuracy: 0.6416 - val_loss: 0.8523 - val_accuracy: 0.7157\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 342us/sample - loss: 0.6964 - accuracy: 0.7619 - val_loss: 0.7403 - val_accuracy: 0.7416\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 0.6605 - accuracy: 0.7686 - val_loss: 0.6899 - val_accuracy: 0.7511\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 339us/sample - loss: 0.6394 - accuracy: 0.7712 - val_loss: 0.7287 - val_accuracy: 0.7441\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 332us/sample - loss: 0.6341 - accuracy: 0.7711 - val_loss: 0.7285 - val_accuracy: 0.7410\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 322us/sample - loss: 0.6250 - accuracy: 0.7706 - val_loss: 0.7278 - val_accuracy: 0.7479\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 2s 319us/sample - loss: 0.6134 - accuracy: 0.7726 - val_loss: 0.7280 - val_accuracy: 0.7419\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 2s 321us/sample - loss: 0.6083 - accuracy: 0.7743 - val_loss: 0.6911 - val_accuracy: 0.7483\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 2s 318us/sample - loss: 0.6088 - accuracy: 0.7715 - val_loss: 0.7248 - val_accuracy: 0.7476\n",
      "3162/3162 - 0s - loss: 0.7248 - accuracy: 0.7476\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002239FFE7048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002239FFE7048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-2_dropout-0.5_epochs-10_it-1\\assets\n",
      "Model: \"sequential_71\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_142 (Conv1D)          (None, 560, 64)           192       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_142 (MaxPoolin (None, 280, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_143 (Conv1D)          (None, 279, 64)           8256      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_143 (MaxPoolin (None, 139, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 139, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_71 (Flatten)         (None, 8896)              0         \n",
      "_________________________________________________________________\n",
      "dense_213 (Dense)            (None, 64)                569408    \n",
      "_________________________________________________________________\n",
      "dense_214 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_215 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,332\n",
      "Trainable params: 580,332\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4928 - accuracy: 0.0032\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 385us/sample - loss: 0.8414 - accuracy: 0.7050 - val_loss: 0.4051 - val_accuracy: 0.8428\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 2s 321us/sample - loss: 0.3138 - accuracy: 0.8867 - val_loss: 0.3036 - val_accuracy: 0.8808\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 0.2554 - accuracy: 0.9015 - val_loss: 0.3219 - val_accuracy: 0.8763\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 2s 321us/sample - loss: 0.2213 - accuracy: 0.9139 - val_loss: 0.3127 - val_accuracy: 0.8827\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 2s 320us/sample - loss: 0.2181 - accuracy: 0.9171 - val_loss: 0.2666 - val_accuracy: 0.9007\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 2s 322us/sample - loss: 0.1957 - accuracy: 0.9246 - val_loss: 0.2986 - val_accuracy: 0.8925\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 2s 320us/sample - loss: 0.1981 - accuracy: 0.9246 - val_loss: 0.3147 - val_accuracy: 0.8805\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 2s 320us/sample - loss: 0.1856 - accuracy: 0.9288 - val_loss: 0.3176 - val_accuracy: 0.8893\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 322us/sample - loss: 0.1788 - accuracy: 0.9310 - val_loss: 0.3400 - val_accuracy: 0.8741\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 2s 320us/sample - loss: 0.1713 - accuracy: 0.9325 - val_loss: 0.3101 - val_accuracy: 0.8912\n",
      "3162/3162 - 0s - loss: 0.3101 - accuracy: 0.8912\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223DF1471F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223DF1471F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-2_dropout-0.5_epochs-10_it-2\\assets\n",
      "Model: \"sequential_72\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_144 (Conv1D)          (None, 560, 64)           192       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_144 (MaxPoolin (None, 280, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_145 (Conv1D)          (None, 279, 64)           8256      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_145 (MaxPoolin (None, 139, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 139, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_72 (Flatten)         (None, 8896)              0         \n",
      "_________________________________________________________________\n",
      "dense_216 (Dense)            (None, 64)                569408    \n",
      "_________________________________________________________________\n",
      "dense_217 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_218 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,332\n",
      "Trainable params: 580,332\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4775 - accuracy: 0.1493\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 387us/sample - loss: 1.0062 - accuracy: 0.6495 - val_loss: 0.7235 - val_accuracy: 0.7385\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 2s 321us/sample - loss: 0.6172 - accuracy: 0.7740 - val_loss: 0.6892 - val_accuracy: 0.7524\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 324us/sample - loss: 0.5493 - accuracy: 0.7973 - val_loss: 0.5988 - val_accuracy: 0.7932\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 2s 321us/sample - loss: 0.2969 - accuracy: 0.8975 - val_loss: 0.2874 - val_accuracy: 0.9064\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 2s 321us/sample - loss: 0.1580 - accuracy: 0.9440 - val_loss: 0.2654 - val_accuracy: 0.9146\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 2s 318us/sample - loss: 0.1370 - accuracy: 0.9497 - val_loss: 0.2405 - val_accuracy: 0.9203\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 2s 318us/sample - loss: 0.1212 - accuracy: 0.9588 - val_loss: 0.2496 - val_accuracy: 0.9260\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 2s 320us/sample - loss: 0.1102 - accuracy: 0.9629 - val_loss: 0.2616 - val_accuracy: 0.9178\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 2s 320us/sample - loss: 0.1071 - accuracy: 0.9632 - val_loss: 0.2479 - val_accuracy: 0.9254\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 2s 319us/sample - loss: 0.0992 - accuracy: 0.9679 - val_loss: 0.3771 - val_accuracy: 0.8906\n",
      "3162/3162 - 0s - loss: 0.3771 - accuracy: 0.8906\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002238B6813A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002238B6813A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-2_dropout-0.5_epochs-10_it-3\\assets\n",
      "Model: \"sequential_73\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_146 (Conv1D)          (None, 560, 64)           192       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_146 (MaxPoolin (None, 280, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_147 (Conv1D)          (None, 279, 64)           8256      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_147 (MaxPoolin (None, 139, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 139, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_73 (Flatten)         (None, 8896)              0         \n",
      "_________________________________________________________________\n",
      "dense_219 (Dense)            (None, 64)                569408    \n",
      "_________________________________________________________________\n",
      "dense_220 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_221 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,332\n",
      "Trainable params: 580,332\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4714 - accuracy: 0.0478\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 388us/sample - loss: 1.0774 - accuracy: 0.6058 - val_loss: 0.7858 - val_accuracy: 0.6882\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 2s 320us/sample - loss: 0.7352 - accuracy: 0.7072 - val_loss: 0.7628 - val_accuracy: 0.6996\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 324us/sample - loss: 0.6871 - accuracy: 0.7294 - val_loss: 0.6981 - val_accuracy: 0.7242\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 323us/sample - loss: 0.6610 - accuracy: 0.7364 - val_loss: 0.7808 - val_accuracy: 0.6983\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 323us/sample - loss: 0.6533 - accuracy: 0.7402 - val_loss: 0.7161 - val_accuracy: 0.7207\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 2s 319us/sample - loss: 0.6411 - accuracy: 0.7449 - val_loss: 0.7096 - val_accuracy: 0.7192\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 2s 320us/sample - loss: 0.6419 - accuracy: 0.7447 - val_loss: 0.7026 - val_accuracy: 0.7239\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 2s 321us/sample - loss: 0.6368 - accuracy: 0.7451 - val_loss: 0.7689 - val_accuracy: 0.7034\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 2s 320us/sample - loss: 0.6301 - accuracy: 0.7483 - val_loss: 0.7395 - val_accuracy: 0.7113\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 2s 319us/sample - loss: 0.6247 - accuracy: 0.7501 - val_loss: 0.7232 - val_accuracy: 0.7239\n",
      "3162/3162 - 0s - loss: 0.7232 - accuracy: 0.7239\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002239FB00558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002239FB00558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-2_dropout-0.5_epochs-10_it-4\\assets\n",
      "Model: \"sequential_74\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_148 (Conv1D)          (None, 560, 64)           192       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_148 (MaxPoolin (None, 280, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_149 (Conv1D)          (None, 279, 64)           8256      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_149 (MaxPoolin (None, 139, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 139, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_74 (Flatten)         (None, 8896)              0         \n",
      "_________________________________________________________________\n",
      "dense_222 (Dense)            (None, 64)                569408    \n",
      "_________________________________________________________________\n",
      "dense_223 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_224 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,332\n",
      "Trainable params: 580,332\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4741 - accuracy: 0.1467\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 386us/sample - loss: 1.0522 - accuracy: 0.6874 - val_loss: 0.7333 - val_accuracy: 0.7603\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 2s 321us/sample - loss: 0.6950 - accuracy: 0.7728 - val_loss: 0.7650 - val_accuracy: 0.7391\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 325us/sample - loss: 0.6471 - accuracy: 0.7809 - val_loss: 0.6945 - val_accuracy: 0.7590\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 322us/sample - loss: 0.6173 - accuracy: 0.7841 - val_loss: 0.6789 - val_accuracy: 0.7584\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 2s 320us/sample - loss: 0.5987 - accuracy: 0.7869 - val_loss: 0.7149 - val_accuracy: 0.7634\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 2s 320us/sample - loss: 0.5888 - accuracy: 0.7869 - val_loss: 0.7227 - val_accuracy: 0.7565\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 2s 320us/sample - loss: 0.5824 - accuracy: 0.7895 - val_loss: 0.7572 - val_accuracy: 0.7552\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 2s 321us/sample - loss: 0.4341 - accuracy: 0.8422 - val_loss: 0.2895 - val_accuracy: 0.9032\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 2s 320us/sample - loss: 0.1835 - accuracy: 0.9321 - val_loss: 0.2839 - val_accuracy: 0.9035\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 2s 321us/sample - loss: 0.1616 - accuracy: 0.9394 - val_loss: 0.3203 - val_accuracy: 0.8925\n",
      "3162/3162 - 0s - loss: 0.3203 - accuracy: 0.8925\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223B3383708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223B3383708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-2_dropout-0.5_epochs-10_it-5\\assets\n",
      "Model: \"sequential_75\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_150 (Conv1D)          (None, 560, 64)           192       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_150 (MaxPoolin (None, 280, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_151 (Conv1D)          (None, 279, 64)           8256      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_151 (MaxPoolin (None, 139, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 139, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_75 (Flatten)         (None, 8896)              0         \n",
      "_________________________________________________________________\n",
      "dense_225 (Dense)            (None, 64)                569408    \n",
      "_________________________________________________________________\n",
      "dense_226 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_227 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,332\n",
      "Trainable params: 580,332\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4888 - accuracy: 0.0085\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 388us/sample - loss: 0.9777 - accuracy: 0.6555 - val_loss: 0.7009 - val_accuracy: 0.7492\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 322us/sample - loss: 0.3956 - accuracy: 0.8651 - val_loss: 0.3146 - val_accuracy: 0.8877\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.2373 - accuracy: 0.9185 - val_loss: 0.2842 - val_accuracy: 0.9029\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 2s 320us/sample - loss: 0.1990 - accuracy: 0.9301 - val_loss: 0.3030 - val_accuracy: 0.8975\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 2s 319us/sample - loss: 0.1787 - accuracy: 0.9377 - val_loss: 0.2611 - val_accuracy: 0.9130\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 2s 319us/sample - loss: 0.1701 - accuracy: 0.9413 - val_loss: 0.3130 - val_accuracy: 0.9058\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 323us/sample - loss: 0.1562 - accuracy: 0.9446 - val_loss: 0.3046 - val_accuracy: 0.9105\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 2s 322us/sample - loss: 0.1454 - accuracy: 0.9488 - val_loss: 0.3208 - val_accuracy: 0.8982\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 2s 321us/sample - loss: 0.1496 - accuracy: 0.9466 - val_loss: 0.2972 - val_accuracy: 0.9080\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 2s 319us/sample - loss: 0.1293 - accuracy: 0.9571 - val_loss: 0.2828 - val_accuracy: 0.9146\n",
      "3162/3162 - 0s - loss: 0.2828 - accuracy: 0.9146\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223D4EA78B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223D4EA78B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-2_dropout-0.5_epochs-10_it-6\\assets\n",
      "Model: \"sequential_76\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_152 (Conv1D)          (None, 560, 64)           192       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_152 (MaxPoolin (None, 280, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_153 (Conv1D)          (None, 279, 64)           8256      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_153 (MaxPoolin (None, 139, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 139, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_76 (Flatten)         (None, 8896)              0         \n",
      "_________________________________________________________________\n",
      "dense_228 (Dense)            (None, 64)                569408    \n",
      "_________________________________________________________________\n",
      "dense_229 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_230 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,332\n",
      "Trainable params: 580,332\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4871 - accuracy: 0.1436\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 384us/sample - loss: 0.7605 - accuracy: 0.7630 - val_loss: 0.3443 - val_accuracy: 0.8760\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 2s 320us/sample - loss: 0.2708 - accuracy: 0.9028 - val_loss: 0.3330 - val_accuracy: 0.8719\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 330us/sample - loss: 0.2323 - accuracy: 0.9193 - val_loss: 0.2800 - val_accuracy: 0.8928\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 2s 320us/sample - loss: 0.2006 - accuracy: 0.9280 - val_loss: 0.3313 - val_accuracy: 0.8776\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 2s 317us/sample - loss: 0.1939 - accuracy: 0.9292 - val_loss: 0.2876 - val_accuracy: 0.9013\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 2s 319us/sample - loss: 0.1811 - accuracy: 0.9331 - val_loss: 0.3139 - val_accuracy: 0.8941\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 2s 318us/sample - loss: 0.1737 - accuracy: 0.9345 - val_loss: 0.3665 - val_accuracy: 0.8925\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 2s 317us/sample - loss: 0.1675 - accuracy: 0.9379 - val_loss: 0.3063 - val_accuracy: 0.9001\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 2s 321us/sample - loss: 0.1638 - accuracy: 0.9378 - val_loss: 0.3339 - val_accuracy: 0.8871\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 2s 319us/sample - loss: 0.1596 - accuracy: 0.9363 - val_loss: 0.2853 - val_accuracy: 0.9058\n",
      "3162/3162 - 0s - loss: 0.2853 - accuracy: 0.9058\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223B3402A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223B3402A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-2_dropout-0.5_epochs-10_it-7\\assets\n",
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_154 (Conv1D)          (None, 560, 64)           192       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_154 (MaxPoolin (None, 280, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_155 (Conv1D)          (None, 279, 64)           8256      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_155 (MaxPoolin (None, 139, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 139, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_77 (Flatten)         (None, 8896)              0         \n",
      "_________________________________________________________________\n",
      "dense_231 (Dense)            (None, 64)                569408    \n",
      "_________________________________________________________________\n",
      "dense_232 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_233 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,332\n",
      "Trainable params: 580,332\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4877 - accuracy: 0.0073\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 387us/sample - loss: 1.3489 - accuracy: 0.5822 - val_loss: 1.1040 - val_accuracy: 0.6237\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 2s 321us/sample - loss: 1.0415 - accuracy: 0.6432 - val_loss: 1.0862 - val_accuracy: 0.6145\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 325us/sample - loss: 0.9904 - accuracy: 0.6444 - val_loss: 1.0264 - val_accuracy: 0.6259\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 2s 320us/sample - loss: 0.9668 - accuracy: 0.6463 - val_loss: 1.0685 - val_accuracy: 0.6148\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 331us/sample - loss: 0.9582 - accuracy: 0.6467 - val_loss: 1.0181 - val_accuracy: 0.6293\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 322us/sample - loss: 0.9485 - accuracy: 0.6452 - val_loss: 1.0086 - val_accuracy: 0.6268\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 2s 316us/sample - loss: 0.9437 - accuracy: 0.6462 - val_loss: 1.0834 - val_accuracy: 0.6148\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 2s 319us/sample - loss: 0.9337 - accuracy: 0.6474 - val_loss: 1.0659 - val_accuracy: 0.6183\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 2s 318us/sample - loss: 0.9285 - accuracy: 0.6468 - val_loss: 1.0442 - val_accuracy: 0.6240\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 2s 320us/sample - loss: 0.9276 - accuracy: 0.6476 - val_loss: 1.0132 - val_accuracy: 0.6252\n",
      "3162/3162 - 0s - loss: 1.0132 - accuracy: 0.6252\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223B3812C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223B3812C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-2_dropout-0.5_epochs-10_it-8\\assets\n",
      "Model: \"sequential_78\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_156 (Conv1D)          (None, 560, 64)           192       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_156 (MaxPoolin (None, 280, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_157 (Conv1D)          (None, 279, 64)           8256      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_157 (MaxPoolin (None, 139, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 139, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_78 (Flatten)         (None, 8896)              0         \n",
      "_________________________________________________________________\n",
      "dense_234 (Dense)            (None, 64)                569408    \n",
      "_________________________________________________________________\n",
      "dense_235 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_236 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,332\n",
      "Trainable params: 580,332\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4945 - accuracy: 0.0082\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 389us/sample - loss: 0.8265 - accuracy: 0.7168 - val_loss: 0.3998 - val_accuracy: 0.8669\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 0.3132 - accuracy: 0.8899 - val_loss: 0.3329 - val_accuracy: 0.8915\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 354us/sample - loss: 0.2441 - accuracy: 0.9113 - val_loss: 0.3039 - val_accuracy: 0.8912\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.2037 - accuracy: 0.9276 - val_loss: 0.2919 - val_accuracy: 0.8985\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 329us/sample - loss: 0.1935 - accuracy: 0.9293 - val_loss: 0.2991 - val_accuracy: 0.8950\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 339us/sample - loss: 0.1907 - accuracy: 0.9301 - val_loss: 0.3076 - val_accuracy: 0.8903\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 340us/sample - loss: 0.1769 - accuracy: 0.9370 - val_loss: 0.2835 - val_accuracy: 0.9083\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 325us/sample - loss: 0.1640 - accuracy: 0.9404 - val_loss: 0.3248 - val_accuracy: 0.8975\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 329us/sample - loss: 0.1630 - accuracy: 0.9410 - val_loss: 0.3171 - val_accuracy: 0.8922\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 330us/sample - loss: 0.1578 - accuracy: 0.9419 - val_loss: 0.2578 - val_accuracy: 0.9121\n",
      "3162/3162 - 0s - loss: 0.2578 - accuracy: 0.9121\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223B3D4ADC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223B3D4ADC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-2_dropout-0.5_epochs-10_it-9\\assets\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-0\n",
      "3162/3162 - 1s - loss: 0.6135 - accuracy: 0.9247\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-1\n",
      "3162/3162 - 1s - loss: 0.5921 - accuracy: 0.7875\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-2\n",
      "3162/3162 - 1s - loss: 0.2480 - accuracy: 0.9187\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-3\n",
      "3162/3162 - 1s - loss: 0.9100 - accuracy: 0.6610\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-4\n",
      "3162/3162 - 1s - loss: 0.6608 - accuracy: 0.8877\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-5\n",
      "3162/3162 - 1s - loss: 0.7964 - accuracy: 0.7239\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-6\n",
      "3162/3162 - 1s - loss: 0.6462 - accuracy: 0.7612\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-7\n",
      "3162/3162 - 1s - loss: 1.0570 - accuracy: 0.7375\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-8\n",
      "3162/3162 - 1s - loss: 1.0262 - accuracy: 0.6195\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-9\n",
      "3162/3162 - 1s - loss: 0.2868 - accuracy: 0.9130\n",
      "Model: \"sequential_79\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_158 (Conv1D)          (None, 557, 64)           384       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_158 (MaxPoolin (None, 278, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_159 (Conv1D)          (None, 274, 64)           20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_159 (MaxPoolin (None, 137, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, 137, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_79 (Flatten)         (None, 8768)              0         \n",
      "_________________________________________________________________\n",
      "dense_237 (Dense)            (None, 64)                561216    \n",
      "_________________________________________________________________\n",
      "dense_238 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_239 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 584,620\n",
      "Trainable params: 584,620\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4966 - accuracy: 0.0089\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 424us/sample - loss: 1.4127 - accuracy: 0.5496 - val_loss: 0.8455 - val_accuracy: 0.7385\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 365us/sample - loss: 0.7096 - accuracy: 0.7726 - val_loss: 0.7890 - val_accuracy: 0.7318\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 371us/sample - loss: 0.6466 - accuracy: 0.7752 - val_loss: 0.6899 - val_accuracy: 0.7546\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 364us/sample - loss: 0.6270 - accuracy: 0.7797 - val_loss: 0.6891 - val_accuracy: 0.7593\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 353us/sample - loss: 0.6085 - accuracy: 0.7795 - val_loss: 0.6562 - val_accuracy: 0.7638\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 362us/sample - loss: 0.5958 - accuracy: 0.7809 - val_loss: 0.6862 - val_accuracy: 0.7502\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 407us/sample - loss: 0.5922 - accuracy: 0.7831 - val_loss: 0.6550 - val_accuracy: 0.7650\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 375us/sample - loss: 0.5701 - accuracy: 0.7936 - val_loss: 0.6407 - val_accuracy: 0.7774\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 374us/sample - loss: 0.5687 - accuracy: 0.7934 - val_loss: 0.6516 - val_accuracy: 0.7704\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 378us/sample - loss: 0.5609 - accuracy: 0.7988 - val_loss: 0.6384 - val_accuracy: 0.7717\n",
      "3162/3162 - 0s - loss: 0.6384 - accuracy: 0.7717\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223E7994C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223E7994C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-5_dropout-0.5_epochs-10_it-0\\assets\n",
      "Model: \"sequential_80\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_160 (Conv1D)          (None, 557, 64)           384       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_160 (MaxPoolin (None, 278, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_161 (Conv1D)          (None, 274, 64)           20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_161 (MaxPoolin (None, 137, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_80 (Dropout)         (None, 137, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_80 (Flatten)         (None, 8768)              0         \n",
      "_________________________________________________________________\n",
      "dense_240 (Dense)            (None, 64)                561216    \n",
      "_________________________________________________________________\n",
      "dense_241 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_242 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 584,620\n",
      "Trainable params: 584,620\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4890 - accuracy: 0.0281\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 407us/sample - loss: 0.6579 - accuracy: 0.7661 - val_loss: 0.3890 - val_accuracy: 0.8665\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 343us/sample - loss: 0.2804 - accuracy: 0.9025 - val_loss: 0.3388 - val_accuracy: 0.8811\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 347us/sample - loss: 0.2161 - accuracy: 0.9244 - val_loss: 0.2382 - val_accuracy: 0.9146\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 355us/sample - loss: 0.1810 - accuracy: 0.9360 - val_loss: 0.3652 - val_accuracy: 0.8703\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 398us/sample - loss: 0.1721 - accuracy: 0.9397 - val_loss: 0.2419 - val_accuracy: 0.9159\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 398us/sample - loss: 0.1644 - accuracy: 0.9418 - val_loss: 0.3327 - val_accuracy: 0.8877\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 409us/sample - loss: 0.1454 - accuracy: 0.9466 - val_loss: 0.2458 - val_accuracy: 0.9152\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 354us/sample - loss: 0.1438 - accuracy: 0.9485 - val_loss: 0.2335 - val_accuracy: 0.9213\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 352us/sample - loss: 0.1414 - accuracy: 0.9490 - val_loss: 0.2400 - val_accuracy: 0.9194\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 382us/sample - loss: 0.1282 - accuracy: 0.9544 - val_loss: 0.2363 - val_accuracy: 0.9206\n",
      "3162/3162 - 0s - loss: 0.2363 - accuracy: 0.9206\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223EB8E5AF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223EB8E5AF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-5_dropout-0.5_epochs-10_it-1\\assets\n",
      "Model: \"sequential_81\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_162 (Conv1D)          (None, 557, 64)           384       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_162 (MaxPoolin (None, 278, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_163 (Conv1D)          (None, 274, 64)           20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_163 (MaxPoolin (None, 137, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_81 (Dropout)         (None, 137, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_81 (Flatten)         (None, 8768)              0         \n",
      "_________________________________________________________________\n",
      "dense_243 (Dense)            (None, 64)                561216    \n",
      "_________________________________________________________________\n",
      "dense_244 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_245 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 584,620\n",
      "Trainable params: 584,620\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4827 - accuracy: 0.0104\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 4s 454us/sample - loss: 0.7761 - accuracy: 0.7169 - val_loss: 0.3737 - val_accuracy: 0.8665\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 398us/sample - loss: 0.3058 - accuracy: 0.8872 - val_loss: 0.3047 - val_accuracy: 0.8922\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 411us/sample - loss: 0.2421 - accuracy: 0.9128 - val_loss: 0.2756 - val_accuracy: 0.8874\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 4s 459us/sample - loss: 0.2120 - accuracy: 0.9239 - val_loss: 0.3340 - val_accuracy: 0.8738\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 373us/sample - loss: 0.1898 - accuracy: 0.9320 - val_loss: 0.2547 - val_accuracy: 0.9064\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 366us/sample - loss: 0.1862 - accuracy: 0.9345 - val_loss: 0.2438 - val_accuracy: 0.9096\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 400us/sample - loss: 0.1652 - accuracy: 0.9396 - val_loss: 0.2564 - val_accuracy: 0.9099\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 369us/sample - loss: 0.1750 - accuracy: 0.9352 - val_loss: 0.2349 - val_accuracy: 0.9140\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 362us/sample - loss: 0.1592 - accuracy: 0.9417 - val_loss: 0.2524 - val_accuracy: 0.9118\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 396us/sample - loss: 0.1483 - accuracy: 0.9445 - val_loss: 0.2554 - val_accuracy: 0.9114\n",
      "3162/3162 - 1s - loss: 0.2554 - accuracy: 0.9114\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223A046E828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223A046E828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-5_dropout-0.5_epochs-10_it-2\\assets\n",
      "Model: \"sequential_82\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_164 (Conv1D)          (None, 557, 64)           384       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_164 (MaxPoolin (None, 278, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_165 (Conv1D)          (None, 274, 64)           20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_165 (MaxPoolin (None, 137, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_82 (Dropout)         (None, 137, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_82 (Flatten)         (None, 8768)              0         \n",
      "_________________________________________________________________\n",
      "dense_246 (Dense)            (None, 64)                561216    \n",
      "_________________________________________________________________\n",
      "dense_247 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_248 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 584,620\n",
      "Trainable params: 584,620\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4906 - accuracy: 0.1268\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 4s 511us/sample - loss: 1.3675 - accuracy: 0.5165 - val_loss: 1.1812 - val_accuracy: 0.5316\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 412us/sample - loss: 1.0666 - accuracy: 0.5816 - val_loss: 1.1021 - val_accuracy: 0.5879\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 429us/sample - loss: 1.0089 - accuracy: 0.6033 - val_loss: 1.0739 - val_accuracy: 0.5882\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 411us/sample - loss: 0.9902 - accuracy: 0.6087 - val_loss: 1.0465 - val_accuracy: 0.5958\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 414us/sample - loss: 0.9870 - accuracy: 0.6073 - val_loss: 1.0446 - val_accuracy: 0.5946\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 386us/sample - loss: 0.9688 - accuracy: 0.6153 - val_loss: 1.0630 - val_accuracy: 0.5977\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 388us/sample - loss: 0.9624 - accuracy: 0.6168 - val_loss: 1.0437 - val_accuracy: 0.5961\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 398us/sample - loss: 0.9625 - accuracy: 0.6171 - val_loss: 1.0994 - val_accuracy: 0.5863\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 382us/sample - loss: 0.9592 - accuracy: 0.6190 - val_loss: 1.0711 - val_accuracy: 0.5980\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 377us/sample - loss: 0.9493 - accuracy: 0.6225 - val_loss: 1.0445 - val_accuracy: 0.5955\n",
      "3162/3162 - 0s - loss: 1.0445 - accuracy: 0.5955\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002239FC464C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002239FC464C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-5_dropout-0.5_epochs-10_it-3\\assets\n",
      "Model: \"sequential_83\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_166 (Conv1D)          (None, 557, 64)           384       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_166 (MaxPoolin (None, 278, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_167 (Conv1D)          (None, 274, 64)           20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_167 (MaxPoolin (None, 137, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_83 (Dropout)         (None, 137, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_83 (Flatten)         (None, 8768)              0         \n",
      "_________________________________________________________________\n",
      "dense_249 (Dense)            (None, 64)                561216    \n",
      "_________________________________________________________________\n",
      "dense_250 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_251 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 584,620\n",
      "Trainable params: 584,620\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4774 - accuracy: 0.1382\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 4s 505us/sample - loss: 1.4766 - accuracy: 0.5271 - val_loss: 1.1157 - val_accuracy: 0.6426\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 378us/sample - loss: 1.0159 - accuracy: 0.6546 - val_loss: 1.0061 - val_accuracy: 0.6423\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 349us/sample - loss: 0.9657 - accuracy: 0.6547 - val_loss: 1.0139 - val_accuracy: 0.6366\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 365us/sample - loss: 0.9368 - accuracy: 0.6552 - val_loss: 0.9853 - val_accuracy: 0.6357\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 360us/sample - loss: 0.9212 - accuracy: 0.6564 - val_loss: 1.0061 - val_accuracy: 0.6306\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 368us/sample - loss: 0.9125 - accuracy: 0.6562 - val_loss: 1.0077 - val_accuracy: 0.6429\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 359us/sample - loss: 0.8996 - accuracy: 0.6588 - val_loss: 0.9626 - val_accuracy: 0.6461\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 363us/sample - loss: 0.8941 - accuracy: 0.6582 - val_loss: 1.0092 - val_accuracy: 0.6458\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 354us/sample - loss: 0.8978 - accuracy: 0.6565 - val_loss: 0.9668 - val_accuracy: 0.6420\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 351us/sample - loss: 0.8933 - accuracy: 0.6562 - val_loss: 0.9680 - val_accuracy: 0.6404\n",
      "3162/3162 - 0s - loss: 0.9680 - accuracy: 0.6404\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002239FF96948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002239FF96948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-5_dropout-0.5_epochs-10_it-4\\assets\n",
      "Model: \"sequential_84\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_168 (Conv1D)          (None, 557, 64)           384       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_168 (MaxPoolin (None, 278, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_169 (Conv1D)          (None, 274, 64)           20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_169 (MaxPoolin (None, 137, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_84 (Dropout)         (None, 137, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_84 (Flatten)         (None, 8768)              0         \n",
      "_________________________________________________________________\n",
      "dense_252 (Dense)            (None, 64)                561216    \n",
      "_________________________________________________________________\n",
      "dense_253 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_254 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 584,620\n",
      "Trainable params: 584,620\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4922 - accuracy: 0.0367\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 438us/sample - loss: 1.6127 - accuracy: 0.4693 - val_loss: 1.4689 - val_accuracy: 0.4880\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 378us/sample - loss: 1.3692 - accuracy: 0.5039 - val_loss: 1.3816 - val_accuracy: 0.4930\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 364us/sample - loss: 1.3247 - accuracy: 0.5066 - val_loss: 1.3531 - val_accuracy: 0.4924\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 399us/sample - loss: 1.2949 - accuracy: 0.5079 - val_loss: 1.3513 - val_accuracy: 0.4937\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 384us/sample - loss: 1.2921 - accuracy: 0.5079 - val_loss: 1.3901 - val_accuracy: 0.4842\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 375us/sample - loss: 1.2832 - accuracy: 0.5070 - val_loss: 1.3804 - val_accuracy: 0.4804\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 357us/sample - loss: 1.2733 - accuracy: 0.5100 - val_loss: 1.3695 - val_accuracy: 0.4839\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 371us/sample - loss: 1.2650 - accuracy: 0.5093 - val_loss: 1.3317 - val_accuracy: 0.4892\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 355us/sample - loss: 1.2582 - accuracy: 0.5104 - val_loss: 1.3355 - val_accuracy: 0.4930\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 356us/sample - loss: 1.2630 - accuracy: 0.5100 - val_loss: 1.3449 - val_accuracy: 0.4883\n",
      "3162/3162 - 0s - loss: 1.3449 - accuracy: 0.4883\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223A0034948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223A0034948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-5_dropout-0.5_epochs-10_it-5\\assets\n",
      "Model: \"sequential_85\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_170 (Conv1D)          (None, 557, 64)           384       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_170 (MaxPoolin (None, 278, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_171 (Conv1D)          (None, 274, 64)           20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_171 (MaxPoolin (None, 137, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_85 (Dropout)         (None, 137, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_85 (Flatten)         (None, 8768)              0         \n",
      "_________________________________________________________________\n",
      "dense_255 (Dense)            (None, 64)                561216    \n",
      "_________________________________________________________________\n",
      "dense_256 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_257 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 584,620\n",
      "Trainable params: 584,620\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4869 - accuracy: 0.0455\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 4s 478us/sample - loss: 1.0299 - accuracy: 0.6690 - val_loss: 0.7703 - val_accuracy: 0.7457\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 373us/sample - loss: 0.7369 - accuracy: 0.7515 - val_loss: 0.7944 - val_accuracy: 0.7059\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 375us/sample - loss: 0.6807 - accuracy: 0.7590 - val_loss: 0.7358 - val_accuracy: 0.7334\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 372us/sample - loss: 0.6564 - accuracy: 0.7618 - val_loss: 0.6543 - val_accuracy: 0.7568\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 360us/sample - loss: 0.6437 - accuracy: 0.7637 - val_loss: 0.6966 - val_accuracy: 0.7426\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 359us/sample - loss: 0.6356 - accuracy: 0.7636 - val_loss: 0.6619 - val_accuracy: 0.7524\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 359us/sample - loss: 0.6408 - accuracy: 0.7622 - val_loss: 0.7040 - val_accuracy: 0.7397\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 364us/sample - loss: 0.6254 - accuracy: 0.7659 - val_loss: 0.7317 - val_accuracy: 0.7340\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 360us/sample - loss: 0.6131 - accuracy: 0.7670 - val_loss: 0.6952 - val_accuracy: 0.7438\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 360us/sample - loss: 0.6075 - accuracy: 0.7677 - val_loss: 0.6966 - val_accuracy: 0.7432\n",
      "3162/3162 - 0s - loss: 0.6966 - accuracy: 0.7432\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002239FCDEDC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002239FCDEDC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-5_dropout-0.5_epochs-10_it-6\\assets\n",
      "Model: \"sequential_86\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_172 (Conv1D)          (None, 557, 64)           384       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_172 (MaxPoolin (None, 278, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_173 (Conv1D)          (None, 274, 64)           20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_173 (MaxPoolin (None, 137, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_86 (Dropout)         (None, 137, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_86 (Flatten)         (None, 8768)              0         \n",
      "_________________________________________________________________\n",
      "dense_258 (Dense)            (None, 64)                561216    \n",
      "_________________________________________________________________\n",
      "dense_259 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_260 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 584,620\n",
      "Trainable params: 584,620\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.5027 - accuracy: 0.0101\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 441us/sample - loss: 1.4125 - accuracy: 0.5405 - val_loss: 1.1380 - val_accuracy: 0.6758\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 349us/sample - loss: 1.1024 - accuracy: 0.6995 - val_loss: 1.0863 - val_accuracy: 0.7188\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 349us/sample - loss: 1.0578 - accuracy: 0.7294 - val_loss: 1.0756 - val_accuracy: 0.7340\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 351us/sample - loss: 1.0285 - accuracy: 0.7389 - val_loss: 1.0812 - val_accuracy: 0.7381\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 362us/sample - loss: 1.0164 - accuracy: 0.7422 - val_loss: 1.0644 - val_accuracy: 0.7056\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 365us/sample - loss: 0.9946 - accuracy: 0.7515 - val_loss: 1.1397 - val_accuracy: 0.7220\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 390us/sample - loss: 0.9941 - accuracy: 0.7519 - val_loss: 1.1527 - val_accuracy: 0.7119\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 366us/sample - loss: 0.9851 - accuracy: 0.7590 - val_loss: 1.0281 - val_accuracy: 0.7435\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 355us/sample - loss: 0.9780 - accuracy: 0.7634 - val_loss: 1.0341 - val_accuracy: 0.7464\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 345us/sample - loss: 0.9709 - accuracy: 0.7661 - val_loss: 1.1026 - val_accuracy: 0.7372\n",
      "3162/3162 - 0s - loss: 1.1026 - accuracy: 0.7372\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223B31CF438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223B31CF438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-5_dropout-0.5_epochs-10_it-7\\assets\n",
      "Model: \"sequential_87\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_174 (Conv1D)          (None, 557, 64)           384       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_174 (MaxPoolin (None, 278, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_175 (Conv1D)          (None, 274, 64)           20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_175 (MaxPoolin (None, 137, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_87 (Dropout)         (None, 137, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_87 (Flatten)         (None, 8768)              0         \n",
      "_________________________________________________________________\n",
      "dense_261 (Dense)            (None, 64)                561216    \n",
      "_________________________________________________________________\n",
      "dense_262 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_263 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 584,620\n",
      "Trainable params: 584,620\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4780 - accuracy: 0.1806\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 424us/sample - loss: 0.7874 - accuracy: 0.7269 - val_loss: 0.3980 - val_accuracy: 0.8558\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 368us/sample - loss: 0.3047 - accuracy: 0.8835 - val_loss: 0.3051 - val_accuracy: 0.8874\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 368us/sample - loss: 0.2398 - accuracy: 0.9078 - val_loss: 0.2845 - val_accuracy: 0.8887\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 361us/sample - loss: 0.2094 - accuracy: 0.9222 - val_loss: 0.2523 - val_accuracy: 0.9029\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 357us/sample - loss: 0.2004 - accuracy: 0.9235 - val_loss: 0.2453 - val_accuracy: 0.9108\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 363us/sample - loss: 0.1879 - accuracy: 0.9270 - val_loss: 0.3001 - val_accuracy: 0.8909\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 367us/sample - loss: 0.1759 - accuracy: 0.9315 - val_loss: 0.2387 - val_accuracy: 0.9105\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 359us/sample - loss: 0.1737 - accuracy: 0.9327 - val_loss: 0.2302 - val_accuracy: 0.9127\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 359us/sample - loss: 0.1677 - accuracy: 0.9352 - val_loss: 0.3005 - val_accuracy: 0.8887\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 354us/sample - loss: 0.1610 - accuracy: 0.9370 - val_loss: 0.3034 - val_accuracy: 0.8931\n",
      "3162/3162 - 0s - loss: 0.3034 - accuracy: 0.8931\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223B38C4708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223B38C4708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-5_dropout-0.5_epochs-10_it-8\\assets\n",
      "Model: \"sequential_88\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_176 (Conv1D)          (None, 557, 64)           384       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_176 (MaxPoolin (None, 278, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_177 (Conv1D)          (None, 274, 64)           20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_177 (MaxPoolin (None, 137, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_88 (Dropout)         (None, 137, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_88 (Flatten)         (None, 8768)              0         \n",
      "_________________________________________________________________\n",
      "dense_264 (Dense)            (None, 64)                561216    \n",
      "_________________________________________________________________\n",
      "dense_265 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_266 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 584,620\n",
      "Trainable params: 584,620\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4769 - accuracy: 0.0901\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 416us/sample - loss: 0.6933 - accuracy: 0.7470 - val_loss: 0.3772 - val_accuracy: 0.8681\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 346us/sample - loss: 0.2983 - accuracy: 0.8921 - val_loss: 0.2963 - val_accuracy: 0.8982\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 345us/sample - loss: 0.2389 - accuracy: 0.9143 - val_loss: 0.2864 - val_accuracy: 0.8997\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 389us/sample - loss: 0.1986 - accuracy: 0.9287 - val_loss: 0.2445 - val_accuracy: 0.9149\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 381us/sample - loss: 0.1873 - accuracy: 0.9338 - val_loss: 0.2803 - val_accuracy: 0.9032\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 403us/sample - loss: 0.1851 - accuracy: 0.9331 - val_loss: 0.2243 - val_accuracy: 0.9203\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 346us/sample - loss: 0.1603 - accuracy: 0.9426 - val_loss: 0.2708 - val_accuracy: 0.9007\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 345us/sample - loss: 0.1590 - accuracy: 0.9426 - val_loss: 0.2272 - val_accuracy: 0.9200\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 344us/sample - loss: 0.1506 - accuracy: 0.9434 - val_loss: 0.2290 - val_accuracy: 0.9194\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 344us/sample - loss: 0.1466 - accuracy: 0.9479 - val_loss: 0.2410 - val_accuracy: 0.9235\n",
      "3162/3162 - 0s - loss: 0.2410 - accuracy: 0.9235\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223D4C9DEE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223D4C9DEE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-5_dropout-0.5_epochs-10_it-9\\assets\n",
      "Model: \"sequential_89\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_178 (Conv1D)          (None, 555, 64)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_178 (MaxPoolin (None, 277, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_179 (Conv1D)          (None, 271, 64)           28736     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_179 (MaxPoolin (None, 135, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_89 (Dropout)         (None, 135, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_89 (Flatten)         (None, 8640)              0         \n",
      "_________________________________________________________________\n",
      "dense_267 (Dense)            (None, 64)                553024    \n",
      "_________________________________________________________________\n",
      "dense_268 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_269 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 584,748\n",
      "Trainable params: 584,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4701 - accuracy: 0.0281\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 4s 465us/sample - loss: 1.3440 - accuracy: 0.5214 - val_loss: 1.1980 - val_accuracy: 0.5380\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 367us/sample - loss: 0.6534 - accuracy: 0.7627 - val_loss: 0.6375 - val_accuracy: 0.7783\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 403us/sample - loss: 0.5413 - accuracy: 0.8004 - val_loss: 0.6387 - val_accuracy: 0.7761\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 402us/sample - loss: 0.5238 - accuracy: 0.8051 - val_loss: 0.6003 - val_accuracy: 0.7862\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 395us/sample - loss: 0.5102 - accuracy: 0.8079 - val_loss: 0.6149 - val_accuracy: 0.7837\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 385us/sample - loss: 0.4899 - accuracy: 0.8132 - val_loss: 0.6056 - val_accuracy: 0.7815\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 386us/sample - loss: 0.4886 - accuracy: 0.8113 - val_loss: 0.6145 - val_accuracy: 0.7770\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 382us/sample - loss: 0.4809 - accuracy: 0.8155 - val_loss: 0.6532 - val_accuracy: 0.7682\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 386us/sample - loss: 0.4764 - accuracy: 0.8161 - val_loss: 0.6224 - val_accuracy: 0.7774\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 373us/sample - loss: 0.4675 - accuracy: 0.8163 - val_loss: 0.6237 - val_accuracy: 0.7796\n",
      "3162/3162 - 0s - loss: 0.6237 - accuracy: 0.7796\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223D4C9DAF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223D4C9DAF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-7_dropout-0.5_epochs-10_it-0\\assets\n",
      "Model: \"sequential_90\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_180 (Conv1D)          (None, 555, 64)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_180 (MaxPoolin (None, 277, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_181 (Conv1D)          (None, 271, 64)           28736     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_181 (MaxPoolin (None, 135, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_90 (Dropout)         (None, 135, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_90 (Flatten)         (None, 8640)              0         \n",
      "_________________________________________________________________\n",
      "dense_270 (Dense)            (None, 64)                553024    \n",
      "_________________________________________________________________\n",
      "dense_271 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_272 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 584,748\n",
      "Trainable params: 584,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4938 - accuracy: 0.0073\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 437us/sample - loss: 1.8899 - accuracy: 0.3833 - val_loss: 1.8311 - val_accuracy: 0.4383\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 364us/sample - loss: 1.7511 - accuracy: 0.4502 - val_loss: 1.7713 - val_accuracy: 0.4453\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 388us/sample - loss: 1.7383 - accuracy: 0.4577 - val_loss: 1.7621 - val_accuracy: 0.4510\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 364us/sample - loss: 1.7336 - accuracy: 0.4607 - val_loss: 1.7881 - val_accuracy: 0.4491\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 361us/sample - loss: 1.7304 - accuracy: 0.4620 - val_loss: 1.7503 - val_accuracy: 0.4475\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 365us/sample - loss: 1.7273 - accuracy: 0.4638 - val_loss: 1.7919 - val_accuracy: 0.4437\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 363us/sample - loss: 1.7247 - accuracy: 0.4649 - val_loss: 1.7614 - val_accuracy: 0.4513\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 360us/sample - loss: 1.7269 - accuracy: 0.4635 - val_loss: 1.7461 - val_accuracy: 0.4541\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 391us/sample - loss: 1.7246 - accuracy: 0.4644 - val_loss: 1.7486 - val_accuracy: 0.4510\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 401us/sample - loss: 1.7223 - accuracy: 0.4649 - val_loss: 1.7613 - val_accuracy: 0.4526\n",
      "3162/3162 - 0s - loss: 1.7613 - accuracy: 0.4526\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223E776A558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223E776A558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-7_dropout-0.5_epochs-10_it-1\\assets\n",
      "Model: \"sequential_91\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_182 (Conv1D)          (None, 555, 64)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_182 (MaxPoolin (None, 277, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_183 (Conv1D)          (None, 271, 64)           28736     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_183 (MaxPoolin (None, 135, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_91 (Dropout)         (None, 135, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_91 (Flatten)         (None, 8640)              0         \n",
      "_________________________________________________________________\n",
      "dense_273 (Dense)            (None, 64)                553024    \n",
      "_________________________________________________________________\n",
      "dense_274 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_275 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 584,748\n",
      "Trainable params: 584,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4665 - accuracy: 0.1607\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 429us/sample - loss: 1.0190 - accuracy: 0.6430 - val_loss: 0.7080 - val_accuracy: 0.7729\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 382us/sample - loss: 0.6012 - accuracy: 0.7814 - val_loss: 0.6231 - val_accuracy: 0.7963\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 379us/sample - loss: 0.5284 - accuracy: 0.8035 - val_loss: 0.6153 - val_accuracy: 0.7906\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 389us/sample - loss: 0.5028 - accuracy: 0.8154 - val_loss: 0.5840 - val_accuracy: 0.8014\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 387us/sample - loss: 0.4790 - accuracy: 0.8196 - val_loss: 0.6406 - val_accuracy: 0.7818\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 404us/sample - loss: 0.4719 - accuracy: 0.8237 - val_loss: 0.5825 - val_accuracy: 0.8014\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 361us/sample - loss: 0.4567 - accuracy: 0.8282 - val_loss: 0.5700 - val_accuracy: 0.8049\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 370us/sample - loss: 0.4454 - accuracy: 0.8299 - val_loss: 0.6737 - val_accuracy: 0.7812\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 389us/sample - loss: 0.4425 - accuracy: 0.8326 - val_loss: 0.5910 - val_accuracy: 0.8083\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 406us/sample - loss: 0.4342 - accuracy: 0.8349 - val_loss: 0.5685 - val_accuracy: 0.8083\n",
      "3162/3162 - 0s - loss: 0.5685 - accuracy: 0.8083\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223E776AB88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223E776AB88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-7_dropout-0.5_epochs-10_it-2\\assets\n",
      "Model: \"sequential_92\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_184 (Conv1D)          (None, 555, 64)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_184 (MaxPoolin (None, 277, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_185 (Conv1D)          (None, 271, 64)           28736     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_185 (MaxPoolin (None, 135, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_92 (Dropout)         (None, 135, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_92 (Flatten)         (None, 8640)              0         \n",
      "_________________________________________________________________\n",
      "dense_276 (Dense)            (None, 64)                553024    \n",
      "_________________________________________________________________\n",
      "dense_277 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_278 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 584,748\n",
      "Trainable params: 584,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4654 - accuracy: 0.0281\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 447us/sample - loss: 0.9484 - accuracy: 0.6596 - val_loss: 0.6918 - val_accuracy: 0.7429\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 396us/sample - loss: 0.6225 - accuracy: 0.7640 - val_loss: 0.6497 - val_accuracy: 0.7454\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 403us/sample - loss: 0.4623 - accuracy: 0.8290 - val_loss: 0.3142 - val_accuracy: 0.8931\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 366us/sample - loss: 0.2224 - accuracy: 0.9185 - val_loss: 0.3056 - val_accuracy: 0.8855\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 384us/sample - loss: 0.1904 - accuracy: 0.9298 - val_loss: 0.2653 - val_accuracy: 0.9042\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 378us/sample - loss: 0.1939 - accuracy: 0.9270 - val_loss: 0.3671 - val_accuracy: 0.8751\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 375us/sample - loss: 0.1824 - accuracy: 0.9287 - val_loss: 0.3004 - val_accuracy: 0.8928\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 366us/sample - loss: 0.1650 - accuracy: 0.9374 - val_loss: 0.2503 - val_accuracy: 0.9102\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 368us/sample - loss: 0.1722 - accuracy: 0.9346 - val_loss: 0.3245 - val_accuracy: 0.8887\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 359us/sample - loss: 0.1596 - accuracy: 0.9394 - val_loss: 0.2932 - val_accuracy: 0.8975\n",
      "3162/3162 - 0s - loss: 0.2932 - accuracy: 0.8975\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223E2964678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223E2964678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-7_dropout-0.5_epochs-10_it-3\\assets\n",
      "Model: \"sequential_93\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_186 (Conv1D)          (None, 555, 64)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_186 (MaxPoolin (None, 277, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_187 (Conv1D)          (None, 271, 64)           28736     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_187 (MaxPoolin (None, 135, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_93 (Dropout)         (None, 135, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_93 (Flatten)         (None, 8640)              0         \n",
      "_________________________________________________________________\n",
      "dense_279 (Dense)            (None, 64)                553024    \n",
      "_________________________________________________________________\n",
      "dense_280 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_281 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 584,748\n",
      "Trainable params: 584,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4903 - accuracy: 0.1331\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 433us/sample - loss: 1.3331 - accuracy: 0.5127 - val_loss: 1.1436 - val_accuracy: 0.5478\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 373us/sample - loss: 1.0364 - accuracy: 0.5955 - val_loss: 1.0235 - val_accuracy: 0.6009\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 370us/sample - loss: 0.9950 - accuracy: 0.6095 - val_loss: 1.0330 - val_accuracy: 0.5923\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 367us/sample - loss: 0.9835 - accuracy: 0.6126 - val_loss: 1.0865 - val_accuracy: 0.5753\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 365us/sample - loss: 0.9838 - accuracy: 0.6126 - val_loss: 1.0040 - val_accuracy: 0.6082\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 372us/sample - loss: 0.9683 - accuracy: 0.6163 - val_loss: 0.9975 - val_accuracy: 0.6056\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 362us/sample - loss: 0.9666 - accuracy: 0.6170 - val_loss: 1.0445 - val_accuracy: 0.5968\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 370us/sample - loss: 0.9639 - accuracy: 0.6179 - val_loss: 0.9843 - val_accuracy: 0.6132\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 361us/sample - loss: 0.9602 - accuracy: 0.6180 - val_loss: 1.0018 - val_accuracy: 0.6053\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 368us/sample - loss: 0.9567 - accuracy: 0.6184 - val_loss: 1.0447 - val_accuracy: 0.5908\n",
      "3162/3162 - 0s - loss: 1.0447 - accuracy: 0.5908\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223EFBA4CA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223EFBA4CA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-7_dropout-0.5_epochs-10_it-4\\assets\n",
      "Model: \"sequential_94\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_188 (Conv1D)          (None, 555, 64)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_188 (MaxPoolin (None, 277, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_189 (Conv1D)          (None, 271, 64)           28736     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_189 (MaxPoolin (None, 135, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_94 (Dropout)         (None, 135, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_94 (Flatten)         (None, 8640)              0         \n",
      "_________________________________________________________________\n",
      "dense_282 (Dense)            (None, 64)                553024    \n",
      "_________________________________________________________________\n",
      "dense_283 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_284 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 584,748\n",
      "Trainable params: 584,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.5186 - accuracy: 0.0079\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 4s 493us/sample - loss: 1.4837 - accuracy: 0.5096 - val_loss: 0.9979 - val_accuracy: 0.7211\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 439us/sample - loss: 0.7871 - accuracy: 0.7497 - val_loss: 0.7125 - val_accuracy: 0.7546\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 418us/sample - loss: 0.6743 - accuracy: 0.7681 - val_loss: 0.6692 - val_accuracy: 0.7676\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 364us/sample - loss: 0.6493 - accuracy: 0.7711 - val_loss: 0.7172 - val_accuracy: 0.7492\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 364us/sample - loss: 0.6353 - accuracy: 0.7737 - val_loss: 0.7107 - val_accuracy: 0.7410\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 362us/sample - loss: 0.6229 - accuracy: 0.7761 - val_loss: 0.7032 - val_accuracy: 0.7543\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 362us/sample - loss: 0.6147 - accuracy: 0.7811 - val_loss: 0.6456 - val_accuracy: 0.7717\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 401us/sample - loss: 0.6030 - accuracy: 0.7827 - val_loss: 0.7289 - val_accuracy: 0.7628\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 384us/sample - loss: 0.5994 - accuracy: 0.7833 - val_loss: 0.7126 - val_accuracy: 0.7511\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 399us/sample - loss: 0.5993 - accuracy: 0.7820 - val_loss: 0.6519 - val_accuracy: 0.7647\n",
      "3162/3162 - 1s - loss: 0.6519 - accuracy: 0.7647\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000022397A7EE58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000022397A7EE58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-7_dropout-0.5_epochs-10_it-5\\assets\n",
      "Model: \"sequential_95\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_190 (Conv1D)          (None, 555, 64)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_190 (MaxPoolin (None, 277, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_191 (Conv1D)          (None, 271, 64)           28736     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_191 (MaxPoolin (None, 135, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_95 (Dropout)         (None, 135, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_95 (Flatten)         (None, 8640)              0         \n",
      "_________________________________________________________________\n",
      "dense_285 (Dense)            (None, 64)                553024    \n",
      "_________________________________________________________________\n",
      "dense_286 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_287 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 584,748\n",
      "Trainable params: 584,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.5039 - accuracy: 0.0104\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 4s 483us/sample - loss: 1.4017 - accuracy: 0.6045 - val_loss: 1.1522 - val_accuracy: 0.7388\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 382us/sample - loss: 1.0705 - accuracy: 0.7474 - val_loss: 1.1623 - val_accuracy: 0.7460\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 399us/sample - loss: 1.0179 - accuracy: 0.7646 - val_loss: 1.0334 - val_accuracy: 0.7581\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 395us/sample - loss: 0.9956 - accuracy: 0.7730 - val_loss: 1.0430 - val_accuracy: 0.7679\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 366us/sample - loss: 0.9814 - accuracy: 0.7775 - val_loss: 1.0424 - val_accuracy: 0.7710\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 380us/sample - loss: 0.9716 - accuracy: 0.7824 - val_loss: 1.0319 - val_accuracy: 0.7736\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 369us/sample - loss: 0.9700 - accuracy: 0.7825 - val_loss: 1.0306 - val_accuracy: 0.7555\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 369us/sample - loss: 0.9641 - accuracy: 0.7827 - val_loss: 1.0275 - val_accuracy: 0.7581\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 360us/sample - loss: 0.9525 - accuracy: 0.7851 - val_loss: 1.0410 - val_accuracy: 0.7672\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 368us/sample - loss: 0.9566 - accuracy: 0.7860 - val_loss: 1.0388 - val_accuracy: 0.7691\n",
      "3162/3162 - 1s - loss: 1.0388 - accuracy: 0.7691\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223DF759438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223DF759438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-7_dropout-0.5_epochs-10_it-6\\assets\n",
      "Model: \"sequential_96\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_192 (Conv1D)          (None, 555, 64)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_192 (MaxPoolin (None, 277, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_193 (Conv1D)          (None, 271, 64)           28736     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_193 (MaxPoolin (None, 135, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_96 (Dropout)         (None, 135, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_96 (Flatten)         (None, 8640)              0         \n",
      "_________________________________________________________________\n",
      "dense_288 (Dense)            (None, 64)                553024    \n",
      "_________________________________________________________________\n",
      "dense_289 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_290 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 584,748\n",
      "Trainable params: 584,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4686 - accuracy: 0.1429\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 424us/sample - loss: 1.0076 - accuracy: 0.6998 - val_loss: 0.7186 - val_accuracy: 0.7710\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 368us/sample - loss: 0.6139 - accuracy: 0.8037 - val_loss: 0.3329 - val_accuracy: 0.8937\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 395us/sample - loss: 0.2414 - accuracy: 0.9163 - val_loss: 0.2764 - val_accuracy: 0.9083\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 414us/sample - loss: 0.1905 - accuracy: 0.9332 - val_loss: 0.3725 - val_accuracy: 0.8653\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 381us/sample - loss: 0.1776 - accuracy: 0.9379 - val_loss: 0.2270 - val_accuracy: 0.9228\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 382us/sample - loss: 0.1621 - accuracy: 0.9450 - val_loss: 0.3416 - val_accuracy: 0.8782\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 424us/sample - loss: 0.1520 - accuracy: 0.9466 - val_loss: 0.2452 - val_accuracy: 0.9165\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 411us/sample - loss: 0.1343 - accuracy: 0.9564 - val_loss: 0.2441 - val_accuracy: 0.9190\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 395us/sample - loss: 0.1296 - accuracy: 0.9558 - val_loss: 0.2625 - val_accuracy: 0.9149\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 375us/sample - loss: 0.1221 - accuracy: 0.9578 - val_loss: 0.2477 - val_accuracy: 0.9247\n",
      "3162/3162 - 0s - loss: 0.2477 - accuracy: 0.9247\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223B37A2798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223B37A2798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-7_dropout-0.5_epochs-10_it-7\\assets\n",
      "Model: \"sequential_97\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_194 (Conv1D)          (None, 555, 64)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_194 (MaxPoolin (None, 277, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_195 (Conv1D)          (None, 271, 64)           28736     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_195 (MaxPoolin (None, 135, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_97 (Dropout)         (None, 135, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_97 (Flatten)         (None, 8640)              0         \n",
      "_________________________________________________________________\n",
      "dense_291 (Dense)            (None, 64)                553024    \n",
      "_________________________________________________________________\n",
      "dense_292 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_293 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 584,748\n",
      "Trainable params: 584,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4901 - accuracy: 0.0503\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 435us/sample - loss: 0.6789 - accuracy: 0.7394 - val_loss: 0.3457 - val_accuracy: 0.8741\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 392us/sample - loss: 0.2950 - accuracy: 0.8900 - val_loss: 0.2928 - val_accuracy: 0.8985\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 384us/sample - loss: 0.2352 - accuracy: 0.9181 - val_loss: 0.3029 - val_accuracy: 0.8947\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 404us/sample - loss: 0.1955 - accuracy: 0.9306 - val_loss: 0.2467 - val_accuracy: 0.9149\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 384us/sample - loss: 0.1831 - accuracy: 0.9365 - val_loss: 0.2493 - val_accuracy: 0.9159\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 378us/sample - loss: 0.1650 - accuracy: 0.9431 - val_loss: 0.2491 - val_accuracy: 0.9143\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 362us/sample - loss: 0.1602 - accuracy: 0.9445 - val_loss: 0.2592 - val_accuracy: 0.9102\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 364us/sample - loss: 0.1471 - accuracy: 0.9498 - val_loss: 0.2654 - val_accuracy: 0.9096\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 366us/sample - loss: 0.1398 - accuracy: 0.9502 - val_loss: 0.2593 - val_accuracy: 0.9099\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 361us/sample - loss: 0.1362 - accuracy: 0.9522 - val_loss: 0.2843 - val_accuracy: 0.9089\n",
      "3162/3162 - 0s - loss: 0.2843 - accuracy: 0.9089\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223D48678B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223D48678B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-7_dropout-0.5_epochs-10_it-8\\assets\n",
      "Model: \"sequential_98\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_196 (Conv1D)          (None, 555, 64)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_196 (MaxPoolin (None, 277, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_197 (Conv1D)          (None, 271, 64)           28736     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_197 (MaxPoolin (None, 135, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_98 (Dropout)         (None, 135, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_98 (Flatten)         (None, 8640)              0         \n",
      "_________________________________________________________________\n",
      "dense_294 (Dense)            (None, 64)                553024    \n",
      "_________________________________________________________________\n",
      "dense_295 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_296 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 584,748\n",
      "Trainable params: 584,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4852 - accuracy: 0.0402\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 4s 496us/sample - loss: 0.7668 - accuracy: 0.7186 - val_loss: 0.4545 - val_accuracy: 0.8194\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 4s 467us/sample - loss: 0.2767 - accuracy: 0.8991 - val_loss: 0.3080 - val_accuracy: 0.8915\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 413us/sample - loss: 0.2141 - accuracy: 0.9257 - val_loss: 0.3037 - val_accuracy: 0.8922\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 379us/sample - loss: 0.1742 - accuracy: 0.9345 - val_loss: 0.2452 - val_accuracy: 0.9111\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 409us/sample - loss: 0.1646 - accuracy: 0.9399 - val_loss: 0.3112 - val_accuracy: 0.8887\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 409us/sample - loss: 0.1474 - accuracy: 0.9445 - val_loss: 0.2756 - val_accuracy: 0.9080\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 435us/sample - loss: 0.1381 - accuracy: 0.9480 - val_loss: 0.2601 - val_accuracy: 0.9058\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 390us/sample - loss: 0.1270 - accuracy: 0.9517 - val_loss: 0.2941 - val_accuracy: 0.9035\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 376us/sample - loss: 0.1185 - accuracy: 0.9539 - val_loss: 0.2286 - val_accuracy: 0.9241\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 377us/sample - loss: 0.1138 - accuracy: 0.9589 - val_loss: 0.2088 - val_accuracy: 0.9292\n",
      "3162/3162 - 0s - loss: 0.2088 - accuracy: 0.9292\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223D4E6A288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223D4E6A288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-7_dropout-0.5_epochs-10_it-9\\assets\n",
      "Model: \"sequential_99\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_198 (Conv1D)          (None, 553, 64)           640       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_198 (MaxPoolin (None, 276, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_199 (Conv1D)          (None, 268, 64)           36928     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_199 (MaxPoolin (None, 134, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_99 (Dropout)         (None, 134, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_99 (Flatten)         (None, 8576)              0         \n",
      "_________________________________________________________________\n",
      "dense_297 (Dense)            (None, 64)                548928    \n",
      "_________________________________________________________________\n",
      "dense_298 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_299 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 588,972\n",
      "Trainable params: 588,972\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4753 - accuracy: 0.1724\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 4s 495us/sample - loss: 1.2746 - accuracy: 0.5321 - val_loss: 1.0880 - val_accuracy: 0.5746\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 450us/sample - loss: 1.0486 - accuracy: 0.5877 - val_loss: 1.0520 - val_accuracy: 0.5825\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 439us/sample - loss: 1.0193 - accuracy: 0.5956 - val_loss: 1.0391 - val_accuracy: 0.5873\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 408us/sample - loss: 1.0124 - accuracy: 0.5962 - val_loss: 1.0157 - val_accuracy: 0.5939\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 395us/sample - loss: 1.0022 - accuracy: 0.6001 - val_loss: 1.0375 - val_accuracy: 0.5860\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 422us/sample - loss: 0.9983 - accuracy: 0.6032 - val_loss: 1.0104 - val_accuracy: 0.5990\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 402us/sample - loss: 0.9960 - accuracy: 0.6037 - val_loss: 1.0739 - val_accuracy: 0.5832\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 411us/sample - loss: 0.9849 - accuracy: 0.6114 - val_loss: 1.0305 - val_accuracy: 0.5974\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 408us/sample - loss: 0.9784 - accuracy: 0.6127 - val_loss: 1.0184 - val_accuracy: 0.6031\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 386us/sample - loss: 0.9732 - accuracy: 0.6132 - val_loss: 1.0128 - val_accuracy: 0.5996\n",
      "3162/3162 - 0s - loss: 1.0128 - accuracy: 0.5996\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002239220F678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002239220F678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-9_dropout-0.5_epochs-10_it-0\\assets\n",
      "Model: \"sequential_100\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_200 (Conv1D)          (None, 553, 64)           640       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_200 (MaxPoolin (None, 276, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_201 (Conv1D)          (None, 268, 64)           36928     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_201 (MaxPoolin (None, 134, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_100 (Dropout)        (None, 134, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_100 (Flatten)        (None, 8576)              0         \n",
      "_________________________________________________________________\n",
      "dense_300 (Dense)            (None, 64)                548928    \n",
      "_________________________________________________________________\n",
      "dense_301 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_302 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 588,972\n",
      "Trainable params: 588,972\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4837 - accuracy: 0.1101\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 3s 450us/sample - loss: 1.2262 - accuracy: 0.6351 - val_loss: 0.7621 - val_accuracy: 0.7615\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 401us/sample - loss: 0.7284 - accuracy: 0.7658 - val_loss: 0.7655 - val_accuracy: 0.7555\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 386us/sample - loss: 0.6618 - accuracy: 0.7744 - val_loss: 0.6954 - val_accuracy: 0.7609\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 386us/sample - loss: 0.6265 - accuracy: 0.7800 - val_loss: 0.6661 - val_accuracy: 0.7761\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 386us/sample - loss: 0.6036 - accuracy: 0.7863 - val_loss: 0.6463 - val_accuracy: 0.7676\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 393us/sample - loss: 0.5903 - accuracy: 0.7872 - val_loss: 0.6765 - val_accuracy: 0.7647\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 383us/sample - loss: 0.5864 - accuracy: 0.7869 - val_loss: 0.6801 - val_accuracy: 0.7590\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 383us/sample - loss: 0.5751 - accuracy: 0.7889 - val_loss: 0.6281 - val_accuracy: 0.7710\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 385us/sample - loss: 0.5708 - accuracy: 0.7896 - val_loss: 0.6646 - val_accuracy: 0.7615\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 385us/sample - loss: 0.5556 - accuracy: 0.7928 - val_loss: 0.6329 - val_accuracy: 0.7710\n",
      "3162/3162 - 0s - loss: 0.6329 - accuracy: 0.7710\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223EDD2A708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223EDD2A708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-9_dropout-0.5_epochs-10_it-1\\assets\n",
      "Model: \"sequential_101\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_202 (Conv1D)          (None, 553, 64)           640       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_202 (MaxPoolin (None, 276, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_203 (Conv1D)          (None, 268, 64)           36928     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_203 (MaxPoolin (None, 134, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_101 (Dropout)        (None, 134, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_101 (Flatten)        (None, 8576)              0         \n",
      "_________________________________________________________________\n",
      "dense_303 (Dense)            (None, 64)                548928    \n",
      "_________________________________________________________________\n",
      "dense_304 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_305 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 588,972\n",
      "Trainable params: 588,972\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4846 - accuracy: 0.1743\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 4s 458us/sample - loss: 1.1014 - accuracy: 0.6213 - val_loss: 0.6137 - val_accuracy: 0.8182\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 388us/sample - loss: 0.3201 - accuracy: 0.8873 - val_loss: 0.4123 - val_accuracy: 0.8590\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 388us/sample - loss: 0.2367 - accuracy: 0.9150 - val_loss: 0.2853 - val_accuracy: 0.8991\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 389us/sample - loss: 0.2128 - accuracy: 0.9244 - val_loss: 0.2726 - val_accuracy: 0.8985\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 386us/sample - loss: 0.1928 - accuracy: 0.9314 - val_loss: 0.2754 - val_accuracy: 0.9016\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 386us/sample - loss: 0.1870 - accuracy: 0.9350 - val_loss: 0.2638 - val_accuracy: 0.9073\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 399us/sample - loss: 0.1751 - accuracy: 0.9351 - val_loss: 0.2606 - val_accuracy: 0.9080\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 385us/sample - loss: 0.1665 - accuracy: 0.9387 - val_loss: 0.2739 - val_accuracy: 0.9051\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 387us/sample - loss: 0.1554 - accuracy: 0.9430 - val_loss: 0.2587 - val_accuracy: 0.9089\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 385us/sample - loss: 0.1535 - accuracy: 0.9432 - val_loss: 0.2554 - val_accuracy: 0.9108\n",
      "3162/3162 - 0s - loss: 0.2554 - accuracy: 0.9108\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223EDD64708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223EDD64708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-9_dropout-0.5_epochs-10_it-2\\assets\n",
      "Model: \"sequential_102\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_204 (Conv1D)          (None, 553, 64)           640       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_204 (MaxPoolin (None, 276, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_205 (Conv1D)          (None, 268, 64)           36928     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_205 (MaxPoolin (None, 134, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_102 (Dropout)        (None, 134, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_102 (Flatten)        (None, 8576)              0         \n",
      "_________________________________________________________________\n",
      "dense_306 (Dense)            (None, 64)                548928    \n",
      "_________________________________________________________________\n",
      "dense_307 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_308 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 588,972\n",
      "Trainable params: 588,972\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.5005 - accuracy: 0.0171\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 4s 453us/sample - loss: 0.6984 - accuracy: 0.7390 - val_loss: 0.3951 - val_accuracy: 0.8397\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 387us/sample - loss: 0.3022 - accuracy: 0.8916 - val_loss: 0.3187 - val_accuracy: 0.8931\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 389us/sample - loss: 0.2448 - accuracy: 0.9105 - val_loss: 0.2844 - val_accuracy: 0.8805\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 384us/sample - loss: 0.1990 - accuracy: 0.9275 - val_loss: 0.2502 - val_accuracy: 0.9010\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 383us/sample - loss: 0.1718 - accuracy: 0.9368 - val_loss: 0.2379 - val_accuracy: 0.9108\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 383us/sample - loss: 0.1572 - accuracy: 0.9413 - val_loss: 0.2117 - val_accuracy: 0.9244\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 384us/sample - loss: 0.1439 - accuracy: 0.9467 - val_loss: 0.2375 - val_accuracy: 0.9105\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 386us/sample - loss: 0.1368 - accuracy: 0.9503 - val_loss: 0.1972 - val_accuracy: 0.9266\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 385us/sample - loss: 0.1297 - accuracy: 0.9506 - val_loss: 0.3451 - val_accuracy: 0.8776\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 383us/sample - loss: 0.1253 - accuracy: 0.9524 - val_loss: 0.2269 - val_accuracy: 0.9206\n",
      "3162/3162 - 0s - loss: 0.2269 - accuracy: 0.9206\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223EDE2CA68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223EDE2CA68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-9_dropout-0.5_epochs-10_it-3\\assets\n",
      "Model: \"sequential_103\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_206 (Conv1D)          (None, 553, 64)           640       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_206 (MaxPoolin (None, 276, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_207 (Conv1D)          (None, 268, 64)           36928     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_207 (MaxPoolin (None, 134, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_103 (Dropout)        (None, 134, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_103 (Flatten)        (None, 8576)              0         \n",
      "_________________________________________________________________\n",
      "dense_309 (Dense)            (None, 64)                548928    \n",
      "_________________________________________________________________\n",
      "dense_310 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_311 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 588,972\n",
      "Trainable params: 588,972\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4827 - accuracy: 0.1268\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 4s 451us/sample - loss: 1.0572 - accuracy: 0.6913 - val_loss: 0.7715 - val_accuracy: 0.7549\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 389us/sample - loss: 0.6932 - accuracy: 0.7755 - val_loss: 0.7397 - val_accuracy: 0.7555\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 406us/sample - loss: 0.6398 - accuracy: 0.7811 - val_loss: 0.6691 - val_accuracy: 0.7691\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 390us/sample - loss: 0.6061 - accuracy: 0.7858 - val_loss: 0.6237 - val_accuracy: 0.7758\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 386us/sample - loss: 0.5976 - accuracy: 0.7885 - val_loss: 0.6199 - val_accuracy: 0.7786\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 385us/sample - loss: 0.5840 - accuracy: 0.7873 - val_loss: 0.6483 - val_accuracy: 0.7707\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 383us/sample - loss: 0.5790 - accuracy: 0.7890 - val_loss: 0.6137 - val_accuracy: 0.7793\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 385us/sample - loss: 0.5626 - accuracy: 0.7930 - val_loss: 0.6273 - val_accuracy: 0.7774\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 383us/sample - loss: 0.5636 - accuracy: 0.7907 - val_loss: 0.7743 - val_accuracy: 0.7410\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 384us/sample - loss: 0.5662 - accuracy: 0.7898 - val_loss: 0.6074 - val_accuracy: 0.7799\n",
      "3162/3162 - 0s - loss: 0.6074 - accuracy: 0.7799\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223EE184D38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223EE184D38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-9_dropout-0.5_epochs-10_it-4\\assets\n",
      "Model: \"sequential_104\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_208 (Conv1D)          (None, 553, 64)           640       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_208 (MaxPoolin (None, 276, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_209 (Conv1D)          (None, 268, 64)           36928     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_209 (MaxPoolin (None, 134, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_104 (Dropout)        (None, 134, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_104 (Flatten)        (None, 8576)              0         \n",
      "_________________________________________________________________\n",
      "dense_312 (Dense)            (None, 64)                548928    \n",
      "_________________________________________________________________\n",
      "dense_313 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_314 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 588,972\n",
      "Trainable params: 588,972\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4848 - accuracy: 0.1569\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 4s 457us/sample - loss: 1.0314 - accuracy: 0.6338 - val_loss: 0.7504 - val_accuracy: 0.7170\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 387us/sample - loss: 0.6528 - accuracy: 0.7522 - val_loss: 0.6493 - val_accuracy: 0.7612\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 391us/sample - loss: 0.5729 - accuracy: 0.7806 - val_loss: 0.6633 - val_accuracy: 0.7552\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 383us/sample - loss: 0.5547 - accuracy: 0.7886 - val_loss: 0.6200 - val_accuracy: 0.7777\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 383us/sample - loss: 0.5289 - accuracy: 0.7971 - val_loss: 0.6142 - val_accuracy: 0.7755\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 384us/sample - loss: 0.5162 - accuracy: 0.8019 - val_loss: 0.6251 - val_accuracy: 0.7729\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 381us/sample - loss: 0.5151 - accuracy: 0.8013 - val_loss: 0.5976 - val_accuracy: 0.7770\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 381us/sample - loss: 0.5107 - accuracy: 0.8026 - val_loss: 0.6329 - val_accuracy: 0.7647\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 384us/sample - loss: 0.4948 - accuracy: 0.8083 - val_loss: 0.6428 - val_accuracy: 0.7774\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 383us/sample - loss: 0.4981 - accuracy: 0.8055 - val_loss: 0.6354 - val_accuracy: 0.7644\n",
      "3162/3162 - 0s - loss: 0.6354 - accuracy: 0.7644\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223EE363DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223EE363DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-9_dropout-0.5_epochs-10_it-5\\assets\n",
      "Model: \"sequential_105\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_210 (Conv1D)          (None, 553, 64)           640       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_210 (MaxPoolin (None, 276, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_211 (Conv1D)          (None, 268, 64)           36928     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_211 (MaxPoolin (None, 134, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_105 (Dropout)        (None, 134, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_105 (Flatten)        (None, 8576)              0         \n",
      "_________________________________________________________________\n",
      "dense_315 (Dense)            (None, 64)                548928    \n",
      "_________________________________________________________________\n",
      "dense_316 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_317 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 588,972\n",
      "Trainable params: 588,972\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.5010 - accuracy: 0.0079\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 4s 458us/sample - loss: 1.0880 - accuracy: 0.6252 - val_loss: 0.8384 - val_accuracy: 0.6755\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 388us/sample - loss: 0.6596 - accuracy: 0.7618 - val_loss: 0.6657 - val_accuracy: 0.7609\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 394us/sample - loss: 0.5758 - accuracy: 0.7901 - val_loss: 0.6319 - val_accuracy: 0.7742\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 385us/sample - loss: 0.5398 - accuracy: 0.7948 - val_loss: 0.6451 - val_accuracy: 0.7676\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 387us/sample - loss: 0.5131 - accuracy: 0.8038 - val_loss: 0.6115 - val_accuracy: 0.7783\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 385us/sample - loss: 0.5005 - accuracy: 0.8078 - val_loss: 0.5869 - val_accuracy: 0.7830\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 384us/sample - loss: 0.4846 - accuracy: 0.8137 - val_loss: 0.5839 - val_accuracy: 0.7853\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 387us/sample - loss: 0.4836 - accuracy: 0.8129 - val_loss: 0.5791 - val_accuracy: 0.7818\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 385us/sample - loss: 0.4812 - accuracy: 0.8140 - val_loss: 0.5917 - val_accuracy: 0.7808\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 384us/sample - loss: 0.4696 - accuracy: 0.8156 - val_loss: 0.6403 - val_accuracy: 0.7774\n",
      "3162/3162 - 0s - loss: 0.6403 - accuracy: 0.7774\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223DF4413A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223DF4413A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-9_dropout-0.5_epochs-10_it-6\\assets\n",
      "Model: \"sequential_106\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_212 (Conv1D)          (None, 553, 64)           640       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_212 (MaxPoolin (None, 276, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_213 (Conv1D)          (None, 268, 64)           36928     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_213 (MaxPoolin (None, 134, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_106 (Dropout)        (None, 134, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_106 (Flatten)        (None, 8576)              0         \n",
      "_________________________________________________________________\n",
      "dense_318 (Dense)            (None, 64)                548928    \n",
      "_________________________________________________________________\n",
      "dense_319 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_320 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 588,972\n",
      "Trainable params: 588,972\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4908 - accuracy: 0.0357\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 4s 457us/sample - loss: 1.0583 - accuracy: 0.6542 - val_loss: 0.8416 - val_accuracy: 0.7619\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 388us/sample - loss: 0.6763 - accuracy: 0.8548 - val_loss: 0.7309 - val_accuracy: 0.8602\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 393us/sample - loss: 0.6157 - accuracy: 0.8947 - val_loss: 0.6582 - val_accuracy: 0.8947\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 386us/sample - loss: 0.5959 - accuracy: 0.9061 - val_loss: 0.7167 - val_accuracy: 0.8855\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 384us/sample - loss: 0.5676 - accuracy: 0.9248 - val_loss: 0.6703 - val_accuracy: 0.8978\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 386us/sample - loss: 0.5696 - accuracy: 0.9200 - val_loss: 0.6561 - val_accuracy: 0.8874\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 385us/sample - loss: 0.5548 - accuracy: 0.9328 - val_loss: 0.6865 - val_accuracy: 0.8956\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 385us/sample - loss: 0.5596 - accuracy: 0.9306 - val_loss: 0.6475 - val_accuracy: 0.8899\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 388us/sample - loss: 0.5517 - accuracy: 0.9318 - val_loss: 0.6156 - val_accuracy: 0.9048\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 396us/sample - loss: 0.5429 - accuracy: 0.9386 - val_loss: 0.6243 - val_accuracy: 0.9108\n",
      "3162/3162 - 0s - loss: 0.6243 - accuracy: 0.9108\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223E2F2A678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223E2F2A678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-9_dropout-0.5_epochs-10_it-7\\assets\n",
      "Model: \"sequential_107\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_214 (Conv1D)          (None, 553, 64)           640       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_214 (MaxPoolin (None, 276, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_215 (Conv1D)          (None, 268, 64)           36928     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_215 (MaxPoolin (None, 134, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_107 (Dropout)        (None, 134, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_107 (Flatten)        (None, 8576)              0         \n",
      "_________________________________________________________________\n",
      "dense_321 (Dense)            (None, 64)                548928    \n",
      "_________________________________________________________________\n",
      "dense_322 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_323 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 588,972\n",
      "Trainable params: 588,972\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4861 - accuracy: 0.0813\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 4s 454us/sample - loss: 0.7107 - accuracy: 0.7280 - val_loss: 0.3527 - val_accuracy: 0.8868\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 388us/sample - loss: 0.2771 - accuracy: 0.9041 - val_loss: 0.3815 - val_accuracy: 0.8602\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 390us/sample - loss: 0.2129 - accuracy: 0.9278 - val_loss: 0.2542 - val_accuracy: 0.9073\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 384us/sample - loss: 0.1946 - accuracy: 0.9327 - val_loss: 0.2749 - val_accuracy: 0.9054\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 384us/sample - loss: 0.1761 - accuracy: 0.9382 - val_loss: 0.2519 - val_accuracy: 0.9073\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 402us/sample - loss: 0.1597 - accuracy: 0.9423 - val_loss: 0.2692 - val_accuracy: 0.9039\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 389us/sample - loss: 0.1486 - accuracy: 0.9466 - val_loss: 0.2644 - val_accuracy: 0.9133\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 384us/sample - loss: 0.1450 - accuracy: 0.9467 - val_loss: 0.2560 - val_accuracy: 0.9127\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 385us/sample - loss: 0.1541 - accuracy: 0.9434 - val_loss: 0.2748 - val_accuracy: 0.9092\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 383us/sample - loss: 0.1379 - accuracy: 0.9482 - val_loss: 0.3241 - val_accuracy: 0.9010\n",
      "3162/3162 - 0s - loss: 0.3241 - accuracy: 0.9010\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223D4905558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223D4905558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-9_dropout-0.5_epochs-10_it-8\\assets\n",
      "Model: \"sequential_108\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_216 (Conv1D)          (None, 553, 64)           640       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_216 (MaxPoolin (None, 276, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_217 (Conv1D)          (None, 268, 64)           36928     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_217 (MaxPoolin (None, 134, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_108 (Dropout)        (None, 134, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_108 (Flatten)        (None, 8576)              0         \n",
      "_________________________________________________________________\n",
      "dense_324 (Dense)            (None, 64)                548928    \n",
      "_________________________________________________________________\n",
      "dense_325 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_326 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 588,972\n",
      "Trainable params: 588,972\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4981 - accuracy: 0.0082\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 4s 456us/sample - loss: 0.7776 - accuracy: 0.7131 - val_loss: 0.3681 - val_accuracy: 0.8662\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 388us/sample - loss: 0.3195 - accuracy: 0.8774 - val_loss: 0.3117 - val_accuracy: 0.8871\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 389us/sample - loss: 0.2628 - accuracy: 0.9033 - val_loss: 0.3198 - val_accuracy: 0.8833\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 386us/sample - loss: 0.2288 - accuracy: 0.9139 - val_loss: 0.2643 - val_accuracy: 0.9042\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 384us/sample - loss: 0.2063 - accuracy: 0.9228 - val_loss: 0.3698 - val_accuracy: 0.8637\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 385us/sample - loss: 0.1916 - accuracy: 0.9246 - val_loss: 0.3061 - val_accuracy: 0.8789\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 386us/sample - loss: 0.1883 - accuracy: 0.9287 - val_loss: 0.3665 - val_accuracy: 0.8643\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 391us/sample - loss: 0.1795 - accuracy: 0.9312 - val_loss: 0.2475 - val_accuracy: 0.9042\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 386us/sample - loss: 0.1747 - accuracy: 0.9314 - val_loss: 0.2470 - val_accuracy: 0.9096\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 384us/sample - loss: 0.1663 - accuracy: 0.9364 - val_loss: 0.3057 - val_accuracy: 0.8947\n",
      "3162/3162 - 0s - loss: 0.3057 - accuracy: 0.8947\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002238AF7C168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002238AF7C168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-9_dropout-0.5_epochs-10_it-9\\assets\n",
      "Model: \"sequential_109\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_218 (Conv1D)          (None, 551, 64)           768       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_218 (MaxPoolin (None, 275, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_219 (Conv1D)          (None, 265, 64)           45120     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_219 (MaxPoolin (None, 132, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_109 (Dropout)        (None, 132, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_109 (Flatten)        (None, 8448)              0         \n",
      "_________________________________________________________________\n",
      "dense_327 (Dense)            (None, 64)                540736    \n",
      "_________________________________________________________________\n",
      "dense_328 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_329 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 589,100\n",
      "Trainable params: 589,100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.5017 - accuracy: 0.0073\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 4s 504us/sample - loss: 1.2391 - accuracy: 0.5406 - val_loss: 0.8291 - val_accuracy: 0.6831\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 405us/sample - loss: 0.7856 - accuracy: 0.6949 - val_loss: 0.7994 - val_accuracy: 0.6967\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 415us/sample - loss: 0.7135 - accuracy: 0.7233 - val_loss: 0.7405 - val_accuracy: 0.7122\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 403us/sample - loss: 0.6634 - accuracy: 0.7465 - val_loss: 0.7039 - val_accuracy: 0.7283\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 405us/sample - loss: 0.6504 - accuracy: 0.7475 - val_loss: 0.7230 - val_accuracy: 0.7226\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 404us/sample - loss: 0.6296 - accuracy: 0.7559 - val_loss: 0.7268 - val_accuracy: 0.7274\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 406us/sample - loss: 0.6094 - accuracy: 0.7637 - val_loss: 0.6938 - val_accuracy: 0.7347\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 403us/sample - loss: 0.6081 - accuracy: 0.7644 - val_loss: 0.6590 - val_accuracy: 0.7498\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 405us/sample - loss: 0.5951 - accuracy: 0.7693 - val_loss: 0.7321 - val_accuracy: 0.7280\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 403us/sample - loss: 0.5944 - accuracy: 0.7679 - val_loss: 0.6967 - val_accuracy: 0.7423\n",
      "3162/3162 - 0s - loss: 0.6967 - accuracy: 0.7423\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223DFA0ECA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223DFA0ECA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-11_dropout-0.5_epochs-10_it-0\\assets\n",
      "Model: \"sequential_110\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_220 (Conv1D)          (None, 551, 64)           768       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_220 (MaxPoolin (None, 275, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_221 (Conv1D)          (None, 265, 64)           45120     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_221 (MaxPoolin (None, 132, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_110 (Dropout)        (None, 132, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_110 (Flatten)        (None, 8448)              0         \n",
      "_________________________________________________________________\n",
      "dense_330 (Dense)            (None, 64)                540736    \n",
      "_________________________________________________________________\n",
      "dense_331 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_332 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 589,100\n",
      "Trainable params: 589,100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4880 - accuracy: 0.1442\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 4s 475us/sample - loss: 0.6748 - accuracy: 0.7534 - val_loss: 0.4975 - val_accuracy: 0.7903\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 407us/sample - loss: 0.2931 - accuracy: 0.8978 - val_loss: 0.2801 - val_accuracy: 0.9073\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 410us/sample - loss: 0.2216 - accuracy: 0.9251 - val_loss: 0.2993 - val_accuracy: 0.9001\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 403us/sample - loss: 0.1953 - accuracy: 0.9319 - val_loss: 0.3019 - val_accuracy: 0.8975\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 414us/sample - loss: 0.1765 - accuracy: 0.9399 - val_loss: 0.2616 - val_accuracy: 0.9159\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 408us/sample - loss: 0.1596 - accuracy: 0.9466 - val_loss: 0.3061 - val_accuracy: 0.8985\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 402us/sample - loss: 0.1617 - accuracy: 0.9446 - val_loss: 0.2241 - val_accuracy: 0.9244\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 405us/sample - loss: 0.1470 - accuracy: 0.9498 - val_loss: 0.2481 - val_accuracy: 0.9241\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 404us/sample - loss: 0.1319 - accuracy: 0.9538 - val_loss: 0.2382 - val_accuracy: 0.9244\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 404us/sample - loss: 0.1293 - accuracy: 0.9564 - val_loss: 0.2357 - val_accuracy: 0.9247\n",
      "3162/3162 - 0s - loss: 0.2357 - accuracy: 0.9247\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223A01A40D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223A01A40D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-11_dropout-0.5_epochs-10_it-1\\assets\n",
      "Model: \"sequential_111\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_222 (Conv1D)          (None, 551, 64)           768       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_222 (MaxPoolin (None, 275, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_223 (Conv1D)          (None, 265, 64)           45120     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_223 (MaxPoolin (None, 132, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_111 (Dropout)        (None, 132, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_111 (Flatten)        (None, 8448)              0         \n",
      "_________________________________________________________________\n",
      "dense_333 (Dense)            (None, 64)                540736    \n",
      "_________________________________________________________________\n",
      "dense_334 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_335 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 589,100\n",
      "Trainable params: 589,100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4790 - accuracy: 0.1486\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 4s 485us/sample - loss: 1.0718 - accuracy: 0.6535 - val_loss: 0.8501 - val_accuracy: 0.7350\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 406us/sample - loss: 0.6858 - accuracy: 0.8527 - val_loss: 0.7530 - val_accuracy: 0.8454\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 407us/sample - loss: 0.6230 - accuracy: 0.8946 - val_loss: 0.7197 - val_accuracy: 0.8700\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 404us/sample - loss: 0.6001 - accuracy: 0.9086 - val_loss: 0.6573 - val_accuracy: 0.8703\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 402us/sample - loss: 0.5867 - accuracy: 0.9167 - val_loss: 0.6529 - val_accuracy: 0.8985\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 402us/sample - loss: 0.5771 - accuracy: 0.9211 - val_loss: 0.7151 - val_accuracy: 0.8877\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 405us/sample - loss: 0.5684 - accuracy: 0.9258 - val_loss: 0.6363 - val_accuracy: 0.8975\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 404us/sample - loss: 0.5609 - accuracy: 0.9287 - val_loss: 0.6705 - val_accuracy: 0.9001\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 401us/sample - loss: 0.5592 - accuracy: 0.9311 - val_loss: 0.6473 - val_accuracy: 0.9035\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 404us/sample - loss: 0.5565 - accuracy: 0.9301 - val_loss: 0.6708 - val_accuracy: 0.9004\n",
      "3162/3162 - 0s - loss: 0.6708 - accuracy: 0.9004\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223B38C48B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223B38C48B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-11_dropout-0.5_epochs-10_it-2\\assets\n",
      "Model: \"sequential_112\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_224 (Conv1D)          (None, 551, 64)           768       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_224 (MaxPoolin (None, 275, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_225 (Conv1D)          (None, 265, 64)           45120     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_225 (MaxPoolin (None, 132, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_112 (Dropout)        (None, 132, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_112 (Flatten)        (None, 8448)              0         \n",
      "_________________________________________________________________\n",
      "dense_336 (Dense)            (None, 64)                540736    \n",
      "_________________________________________________________________\n",
      "dense_337 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_338 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 589,100\n",
      "Trainable params: 589,100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4646 - accuracy: 0.1607\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 4s 474us/sample - loss: 0.6799 - accuracy: 0.7511 - val_loss: 0.3803 - val_accuracy: 0.8561\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 406us/sample - loss: 0.2869 - accuracy: 0.8951 - val_loss: 0.2866 - val_accuracy: 0.8906\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 412us/sample - loss: 0.2101 - accuracy: 0.9235 - val_loss: 0.3084 - val_accuracy: 0.8773\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 405us/sample - loss: 0.1875 - accuracy: 0.9300 - val_loss: 0.2343 - val_accuracy: 0.9108\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 404us/sample - loss: 0.1733 - accuracy: 0.9341 - val_loss: 0.2479 - val_accuracy: 0.9105\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 403us/sample - loss: 0.1618 - accuracy: 0.9403 - val_loss: 0.2931 - val_accuracy: 0.8928\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 405us/sample - loss: 0.1569 - accuracy: 0.9403 - val_loss: 0.2501 - val_accuracy: 0.9064\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 404us/sample - loss: 0.1458 - accuracy: 0.9417 - val_loss: 0.3272 - val_accuracy: 0.8909\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 403us/sample - loss: 0.1439 - accuracy: 0.9445 - val_loss: 0.3009 - val_accuracy: 0.8928\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 403us/sample - loss: 0.1325 - accuracy: 0.9486 - val_loss: 0.2401 - val_accuracy: 0.9152\n",
      "3162/3162 - 0s - loss: 0.2401 - accuracy: 0.9152\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223E72E5A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223E72E5A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-11_dropout-0.5_epochs-10_it-3\\assets\n",
      "Model: \"sequential_113\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_226 (Conv1D)          (None, 551, 64)           768       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_226 (MaxPoolin (None, 275, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_227 (Conv1D)          (None, 265, 64)           45120     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_227 (MaxPoolin (None, 132, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_113 (Dropout)        (None, 132, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_113 (Flatten)        (None, 8448)              0         \n",
      "_________________________________________________________________\n",
      "dense_339 (Dense)            (None, 64)                540736    \n",
      "_________________________________________________________________\n",
      "dense_340 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_341 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 589,100\n",
      "Trainable params: 589,100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4748 - accuracy: 0.0610\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 4s 475us/sample - loss: 1.2163 - accuracy: 0.6231 - val_loss: 0.7315 - val_accuracy: 0.8612\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 406us/sample - loss: 0.5949 - accuracy: 0.8705 - val_loss: 0.3419 - val_accuracy: 0.8852\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 409us/sample - loss: 0.2453 - accuracy: 0.9101 - val_loss: 0.3736 - val_accuracy: 0.8599\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 404us/sample - loss: 0.2137 - accuracy: 0.9202 - val_loss: 0.2629 - val_accuracy: 0.9029\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 404us/sample - loss: 0.2020 - accuracy: 0.9248 - val_loss: 0.2924 - val_accuracy: 0.8972\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 404us/sample - loss: 0.1869 - accuracy: 0.9271 - val_loss: 0.5424 - val_accuracy: 0.8226\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 405us/sample - loss: 0.1759 - accuracy: 0.9328 - val_loss: 0.2598 - val_accuracy: 0.9108\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 403us/sample - loss: 0.1679 - accuracy: 0.9355 - val_loss: 0.2542 - val_accuracy: 0.9061\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 405us/sample - loss: 0.1647 - accuracy: 0.9355 - val_loss: 0.3866 - val_accuracy: 0.8713\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 404us/sample - loss: 0.1674 - accuracy: 0.9347 - val_loss: 0.2895 - val_accuracy: 0.8982\n",
      "3162/3162 - 0s - loss: 0.2895 - accuracy: 0.8982\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223E72E58B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223E72E58B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-11_dropout-0.5_epochs-10_it-4\\assets\n",
      "Model: \"sequential_114\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_228 (Conv1D)          (None, 551, 64)           768       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_228 (MaxPoolin (None, 275, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_229 (Conv1D)          (None, 265, 64)           45120     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_229 (MaxPoolin (None, 132, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_114 (Dropout)        (None, 132, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_114 (Flatten)        (None, 8448)              0         \n",
      "_________________________________________________________________\n",
      "dense_342 (Dense)            (None, 64)                540736    \n",
      "_________________________________________________________________\n",
      "dense_343 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_344 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 589,100\n",
      "Trainable params: 589,100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4828 - accuracy: 0.0155\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 4s 483us/sample - loss: 0.7429 - accuracy: 0.7277 - val_loss: 0.3882 - val_accuracy: 0.8637\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 408us/sample - loss: 0.2993 - accuracy: 0.8935 - val_loss: 0.3225 - val_accuracy: 0.8855\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 410us/sample - loss: 0.2549 - accuracy: 0.9118 - val_loss: 0.2652 - val_accuracy: 0.9054\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 404us/sample - loss: 0.2098 - accuracy: 0.9260 - val_loss: 0.2521 - val_accuracy: 0.9121\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 403us/sample - loss: 0.1929 - accuracy: 0.9337 - val_loss: 0.2927 - val_accuracy: 0.8922\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 404us/sample - loss: 0.1739 - accuracy: 0.9386 - val_loss: 0.2474 - val_accuracy: 0.9152\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 403us/sample - loss: 0.1757 - accuracy: 0.9373 - val_loss: 0.2620 - val_accuracy: 0.9077\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 404us/sample - loss: 0.1627 - accuracy: 0.9390 - val_loss: 0.2487 - val_accuracy: 0.9152\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 402us/sample - loss: 0.1596 - accuracy: 0.9421 - val_loss: 0.3236 - val_accuracy: 0.8963\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 403us/sample - loss: 0.1485 - accuracy: 0.9461 - val_loss: 0.3702 - val_accuracy: 0.8738\n",
      "3162/3162 - 0s - loss: 0.3702 - accuracy: 0.8738\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223B39F9EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223B39F9EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-11_dropout-0.5_epochs-10_it-5\\assets\n",
      "Model: \"sequential_115\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_230 (Conv1D)          (None, 551, 64)           768       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_230 (MaxPoolin (None, 275, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_231 (Conv1D)          (None, 265, 64)           45120     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_231 (MaxPoolin (None, 132, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_115 (Dropout)        (None, 132, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_115 (Flatten)        (None, 8448)              0         \n",
      "_________________________________________________________________\n",
      "dense_345 (Dense)            (None, 64)                540736    \n",
      "_________________________________________________________________\n",
      "dense_346 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_347 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 589,100\n",
      "Trainable params: 589,100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4812 - accuracy: 0.0942\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 4s 472us/sample - loss: 0.7017 - accuracy: 0.7433 - val_loss: 0.3463 - val_accuracy: 0.8814\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 407us/sample - loss: 0.2860 - accuracy: 0.9002 - val_loss: 0.3105 - val_accuracy: 0.8858\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 411us/sample - loss: 0.2267 - accuracy: 0.9209 - val_loss: 0.3017 - val_accuracy: 0.8912\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 404us/sample - loss: 0.1949 - accuracy: 0.9316 - val_loss: 0.2487 - val_accuracy: 0.9187\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 402us/sample - loss: 0.1713 - accuracy: 0.9418 - val_loss: 0.2347 - val_accuracy: 0.9260\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 403us/sample - loss: 0.1682 - accuracy: 0.9427 - val_loss: 0.2763 - val_accuracy: 0.9096\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 407us/sample - loss: 0.1588 - accuracy: 0.9454 - val_loss: 0.2532 - val_accuracy: 0.9178\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 413us/sample - loss: 0.1498 - accuracy: 0.9488 - val_loss: 0.3006 - val_accuracy: 0.9013\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 415us/sample - loss: 0.1390 - accuracy: 0.9508 - val_loss: 0.2794 - val_accuracy: 0.9102\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 427us/sample - loss: 0.1392 - accuracy: 0.9516 - val_loss: 0.2219 - val_accuracy: 0.9285\n",
      "3162/3162 - 1s - loss: 0.2219 - accuracy: 0.9285\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002239FAB9948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002239FAB9948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-11_dropout-0.5_epochs-10_it-6\\assets\n",
      "Model: \"sequential_116\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_232 (Conv1D)          (None, 551, 64)           768       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_232 (MaxPoolin (None, 275, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_233 (Conv1D)          (None, 265, 64)           45120     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_233 (MaxPoolin (None, 132, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_116 (Dropout)        (None, 132, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_116 (Flatten)        (None, 8448)              0         \n",
      "_________________________________________________________________\n",
      "dense_348 (Dense)            (None, 64)                540736    \n",
      "_________________________________________________________________\n",
      "dense_349 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_350 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 589,100\n",
      "Trainable params: 589,100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4873 - accuracy: 0.1290\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 4s 514us/sample - loss: 1.1098 - accuracy: 0.6593 - val_loss: 0.7893 - val_accuracy: 0.7397\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 423us/sample - loss: 0.7494 - accuracy: 0.7507 - val_loss: 0.7196 - val_accuracy: 0.7574\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 430us/sample - loss: 0.6804 - accuracy: 0.7654 - val_loss: 0.7203 - val_accuracy: 0.7445\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 405us/sample - loss: 0.6587 - accuracy: 0.7654 - val_loss: 0.7000 - val_accuracy: 0.7492\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 407us/sample - loss: 0.6427 - accuracy: 0.7666 - val_loss: 0.6725 - val_accuracy: 0.7590\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 431us/sample - loss: 0.6240 - accuracy: 0.7713 - val_loss: 0.7100 - val_accuracy: 0.7441\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 405us/sample - loss: 0.6209 - accuracy: 0.7698 - val_loss: 0.6818 - val_accuracy: 0.7476\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 406us/sample - loss: 0.6175 - accuracy: 0.7699 - val_loss: 0.6720 - val_accuracy: 0.7555\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 406us/sample - loss: 0.6103 - accuracy: 0.7713 - val_loss: 0.7457 - val_accuracy: 0.7356\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 405us/sample - loss: 0.6066 - accuracy: 0.7724 - val_loss: 0.6693 - val_accuracy: 0.7571\n",
      "3162/3162 - 0s - loss: 0.6693 - accuracy: 0.7571\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223B39F99D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223B39F99D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-11_dropout-0.5_epochs-10_it-7\\assets\n",
      "Model: \"sequential_117\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_234 (Conv1D)          (None, 551, 64)           768       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_234 (MaxPoolin (None, 275, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_235 (Conv1D)          (None, 265, 64)           45120     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_235 (MaxPoolin (None, 132, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_117 (Dropout)        (None, 132, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_117 (Flatten)        (None, 8448)              0         \n",
      "_________________________________________________________________\n",
      "dense_351 (Dense)            (None, 64)                540736    \n",
      "_________________________________________________________________\n",
      "dense_352 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_353 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 589,100\n",
      "Trainable params: 589,100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4763 - accuracy: 0.0380\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 4s 486us/sample - loss: 0.9881 - accuracy: 0.6421 - val_loss: 0.7005 - val_accuracy: 0.7631\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 414us/sample - loss: 0.6119 - accuracy: 0.7793 - val_loss: 0.6251 - val_accuracy: 0.7732\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 430us/sample - loss: 0.5512 - accuracy: 0.7945 - val_loss: 0.6101 - val_accuracy: 0.7853\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 416us/sample - loss: 0.5181 - accuracy: 0.8073 - val_loss: 0.5744 - val_accuracy: 0.7922\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 445us/sample - loss: 0.5044 - accuracy: 0.8105 - val_loss: 0.5802 - val_accuracy: 0.7935\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 409us/sample - loss: 0.4878 - accuracy: 0.8163 - val_loss: 0.5817 - val_accuracy: 0.7976\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 403us/sample - loss: 0.4810 - accuracy: 0.8196 - val_loss: 0.5700 - val_accuracy: 0.7925\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 408us/sample - loss: 0.4699 - accuracy: 0.8227 - val_loss: 0.5701 - val_accuracy: 0.7992\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 405us/sample - loss: 0.4555 - accuracy: 0.8273 - val_loss: 0.5835 - val_accuracy: 0.7865\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 410us/sample - loss: 0.4538 - accuracy: 0.8263 - val_loss: 0.6933 - val_accuracy: 0.7710\n",
      "3162/3162 - 0s - loss: 0.6933 - accuracy: 0.7710\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223A002F798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223A002F798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-11_dropout-0.5_epochs-10_it-8\\assets\n",
      "Model: \"sequential_118\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_236 (Conv1D)          (None, 551, 64)           768       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_236 (MaxPoolin (None, 275, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_237 (Conv1D)          (None, 265, 64)           45120     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_237 (MaxPoolin (None, 132, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_118 (Dropout)        (None, 132, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_118 (Flatten)        (None, 8448)              0         \n",
      "_________________________________________________________________\n",
      "dense_354 (Dense)            (None, 64)                540736    \n",
      "_________________________________________________________________\n",
      "dense_355 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_356 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 589,100\n",
      "Trainable params: 589,100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4805 - accuracy: 0.1524\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7767/7767 [==============================] - 4s 483us/sample - loss: 0.6835 - accuracy: 0.7434 - val_loss: 0.3753 - val_accuracy: 0.8605\n",
      "Epoch 2/10\n",
      "7767/7767 [==============================] - 3s 412us/sample - loss: 0.2622 - accuracy: 0.9054 - val_loss: 0.2738 - val_accuracy: 0.8972\n",
      "Epoch 3/10\n",
      "7767/7767 [==============================] - 3s 424us/sample - loss: 0.1904 - accuracy: 0.9329 - val_loss: 0.2172 - val_accuracy: 0.9257\n",
      "Epoch 4/10\n",
      "7767/7767 [==============================] - 3s 403us/sample - loss: 0.1619 - accuracy: 0.9427 - val_loss: 0.2238 - val_accuracy: 0.9178\n",
      "Epoch 5/10\n",
      "7767/7767 [==============================] - 3s 405us/sample - loss: 0.1400 - accuracy: 0.9502 - val_loss: 0.1917 - val_accuracy: 0.9361\n",
      "Epoch 6/10\n",
      "7767/7767 [==============================] - 3s 403us/sample - loss: 0.1292 - accuracy: 0.9551 - val_loss: 0.1941 - val_accuracy: 0.9330\n",
      "Epoch 7/10\n",
      "7767/7767 [==============================] - 3s 402us/sample - loss: 0.1156 - accuracy: 0.9594 - val_loss: 0.2336 - val_accuracy: 0.9187\n",
      "Epoch 8/10\n",
      "7767/7767 [==============================] - 3s 407us/sample - loss: 0.1103 - accuracy: 0.9594 - val_loss: 0.2548 - val_accuracy: 0.9140\n",
      "Epoch 9/10\n",
      "7767/7767 [==============================] - 3s 402us/sample - loss: 0.1041 - accuracy: 0.9652 - val_loss: 0.2489 - val_accuracy: 0.9184\n",
      "Epoch 10/10\n",
      "7767/7767 [==============================] - 3s 403us/sample - loss: 0.0959 - accuracy: 0.9669 - val_loss: 0.2792 - val_accuracy: 0.9099\n",
      "3162/3162 - 0s - loss: 0.2792 - accuracy: 0.9099\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223D4EE7318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223D4EE7318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-11_dropout-0.5_epochs-10_it-9\\assets\n"
     ]
    }
   ],
   "source": [
    "kernel_size_data = runner.test_param(kernel_size = [2,3,5,7,9,11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#runner.print_results(kernel_size_data, 'kernel_size')\n",
    "runner.plot_results(kernel_size_data, 'kernel_size')\n",
    "plt.savefig(\"plots/kernel-size-2-3-5-7-9-11.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no data type selected, running default...\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-0\n",
      "3162/3162 - 1s - loss: 0.6135 - accuracy: 0.9247\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-1\n",
      "3162/3162 - 1s - loss: 0.5921 - accuracy: 0.7875\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-2\n",
      "3162/3162 - 1s - loss: 0.2480 - accuracy: 0.9187\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-3\n",
      "3162/3162 - 1s - loss: 0.9100 - accuracy: 0.6610\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-4\n",
      "3162/3162 - 1s - loss: 0.6608 - accuracy: 0.8877\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-5\n",
      "3162/3162 - 1s - loss: 0.7964 - accuracy: 0.7239\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-6\n",
      "3162/3162 - 1s - loss: 0.6462 - accuracy: 0.7612\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-7\n",
      "3162/3162 - 1s - loss: 1.0570 - accuracy: 0.7375\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-8\n",
      "3162/3162 - 1s - loss: 1.0262 - accuracy: 0.6195\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-9\n",
      "3162/3162 - 1s - loss: 0.2868 - accuracy: 0.9130\n"
     ]
    }
   ],
   "source": [
    "default_data = runner.test_param()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "runner.plot_results(default_data, 'default')\n",
    "plt.savefig(\"plots/default-f64-ks3-do0.5-epch10.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-5_it-0\n",
      "3162/3162 - 1s - loss: 0.7084 - accuracy: 0.7489\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-5_it-1\n",
      "3162/3162 - 1s - loss: 0.3023 - accuracy: 0.8877\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-5_it-2\n",
      "3162/3162 - 1s - loss: 0.6280 - accuracy: 0.8997\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-5_it-3\n",
      "3162/3162 - 1s - loss: 1.0441 - accuracy: 0.6306\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-5_it-4\n",
      "3162/3162 - 1s - loss: 0.3040 - accuracy: 0.8830\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-5_it-5\n",
      "3162/3162 - 1s - loss: 0.2685 - accuracy: 0.9061\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-5_it-6\n",
      "3162/3162 - 1s - loss: 0.6354 - accuracy: 0.7653\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-5_it-7\n",
      "3162/3162 - 1s - loss: 1.0074 - accuracy: 0.6097\n",
      "Model: \"sequential_128\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_256 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_256 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_257 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_257 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_128 (Dropout)        (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_128 (Flatten)        (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_384 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_385 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_386 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4831 - accuracy: 0.0522\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/5\n",
      "7767/7767 [==============================] - 3s 427us/sample - loss: 1.4113 - accuracy: 0.5590 - val_loss: 1.2094 - val_accuracy: 0.6015\n",
      "Epoch 2/5\n",
      "7767/7767 [==============================] - 3s 344us/sample - loss: 1.0850 - accuracy: 0.6261 - val_loss: 1.0870 - val_accuracy: 0.6072\n",
      "Epoch 3/5\n",
      "7767/7767 [==============================] - 3s 356us/sample - loss: 0.7814 - accuracy: 0.7183 - val_loss: 0.6528 - val_accuracy: 0.7676\n",
      "Epoch 4/5\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.5603 - accuracy: 0.7869 - val_loss: 0.6150 - val_accuracy: 0.7796\n",
      "Epoch 5/5\n",
      "7767/7767 [==============================] - 3s 340us/sample - loss: 0.5366 - accuracy: 0.7961 - val_loss: 0.6203 - val_accuracy: 0.7688\n",
      "3162/3162 - 0s - loss: 0.6203 - accuracy: 0.7688\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223D3F6FCA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223D3F6FCA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-5_it-8\\assets\n",
      "Model: \"sequential_129\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_258 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_258 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_259 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_259 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_129 (Dropout)        (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_129 (Flatten)        (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_387 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_388 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_389 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4980 - accuracy: 0.0130\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/5\n",
      "7767/7767 [==============================] - 3s 440us/sample - loss: 0.9567 - accuracy: 0.6618 - val_loss: 0.6905 - val_accuracy: 0.7559\n",
      "Epoch 2/5\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.6090 - accuracy: 0.7780 - val_loss: 0.6052 - val_accuracy: 0.7891\n",
      "Epoch 3/5\n",
      "7767/7767 [==============================] - 3s 347us/sample - loss: 0.5297 - accuracy: 0.8035 - val_loss: 0.5891 - val_accuracy: 0.7992\n",
      "Epoch 4/5\n",
      "7767/7767 [==============================] - 3s 351us/sample - loss: 0.4922 - accuracy: 0.8163 - val_loss: 0.5974 - val_accuracy: 0.8011\n",
      "Epoch 5/5\n",
      "7767/7767 [==============================] - 3s 346us/sample - loss: 0.4852 - accuracy: 0.8192 - val_loss: 0.5538 - val_accuracy: 0.8080\n",
      "3162/3162 - 0s - loss: 0.5538 - accuracy: 0.8080\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223D3EE7E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223D3EE7E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-5_it-9\\assets\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-0\n",
      "3162/3162 - 1s - loss: 0.6135 - accuracy: 0.9247\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-1\n",
      "3162/3162 - 1s - loss: 0.5921 - accuracy: 0.7875\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-2\n",
      "3162/3162 - 1s - loss: 0.2480 - accuracy: 0.9187\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-3\n",
      "3162/3162 - 1s - loss: 0.9100 - accuracy: 0.6610\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-4\n",
      "3162/3162 - 1s - loss: 0.6608 - accuracy: 0.8877\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-5\n",
      "3162/3162 - 1s - loss: 0.7964 - accuracy: 0.7239\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-6\n",
      "3162/3162 - 1s - loss: 0.6462 - accuracy: 0.7612\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-7\n",
      "3162/3162 - 1s - loss: 1.0570 - accuracy: 0.7375\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-8\n",
      "3162/3162 - 1s - loss: 1.0262 - accuracy: 0.6195\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-9\n",
      "3162/3162 - 1s - loss: 0.2868 - accuracy: 0.9130\n",
      "Model: \"sequential_130\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_260 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_260 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_261 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_261 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_130 (Dropout)        (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_130 (Flatten)        (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_390 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_391 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_392 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4961 - accuracy: 0.0063\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/15\n",
      "7767/7767 [==============================] - 3s 414us/sample - loss: 1.1115 - accuracy: 0.6405 - val_loss: 0.8099 - val_accuracy: 0.6945\n",
      "Epoch 2/15\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.6271 - accuracy: 0.7715 - val_loss: 0.6918 - val_accuracy: 0.7366\n",
      "Epoch 3/15\n",
      "7767/7767 [==============================] - 3s 333us/sample - loss: 0.5630 - accuracy: 0.7914 - val_loss: 0.6327 - val_accuracy: 0.7736\n",
      "Epoch 4/15\n",
      "7767/7767 [==============================] - 3s 344us/sample - loss: 0.5248 - accuracy: 0.8012 - val_loss: 0.6139 - val_accuracy: 0.7698\n",
      "Epoch 5/15\n",
      "7767/7767 [==============================] - 3s 341us/sample - loss: 0.5055 - accuracy: 0.8106 - val_loss: 0.5824 - val_accuracy: 0.7862\n",
      "Epoch 6/15\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.4930 - accuracy: 0.8129 - val_loss: 0.5692 - val_accuracy: 0.7913\n",
      "Epoch 7/15\n",
      "7767/7767 [==============================] - 3s 358us/sample - loss: 0.4842 - accuracy: 0.8124 - val_loss: 0.6503 - val_accuracy: 0.7650\n",
      "Epoch 8/15\n",
      "7767/7767 [==============================] - 3s 344us/sample - loss: 0.4670 - accuracy: 0.8195 - val_loss: 0.5999 - val_accuracy: 0.7783\n",
      "Epoch 9/15\n",
      "7767/7767 [==============================] - 3s 349us/sample - loss: 0.4631 - accuracy: 0.8212 - val_loss: 0.5693 - val_accuracy: 0.7916\n",
      "Epoch 10/15\n",
      "7767/7767 [==============================] - 3s 342us/sample - loss: 0.4616 - accuracy: 0.8223 - val_loss: 0.5828 - val_accuracy: 0.7881\n",
      "Epoch 11/15\n",
      "7767/7767 [==============================] - 3s 346us/sample - loss: 0.4605 - accuracy: 0.8195 - val_loss: 0.5774 - val_accuracy: 0.7856\n",
      "Epoch 12/15\n",
      "7767/7767 [==============================] - 3s 361us/sample - loss: 0.4509 - accuracy: 0.8221 - val_loss: 0.5776 - val_accuracy: 0.7891\n",
      "Epoch 13/15\n",
      "7767/7767 [==============================] - 3s 364us/sample - loss: 0.4445 - accuracy: 0.8257 - val_loss: 0.5559 - val_accuracy: 0.7938\n",
      "Epoch 14/15\n",
      "7767/7767 [==============================] - 3s 347us/sample - loss: 0.4367 - accuracy: 0.8282 - val_loss: 0.5732 - val_accuracy: 0.7884\n",
      "Epoch 15/15\n",
      "7767/7767 [==============================] - 3s 352us/sample - loss: 0.4436 - accuracy: 0.8259 - val_loss: 0.5924 - val_accuracy: 0.7846\n",
      "3162/3162 - 0s - loss: 0.5924 - accuracy: 0.7846\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002240BA56168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002240BA56168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-15_it-0\\assets\n",
      "Model: \"sequential_131\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_262 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_262 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_263 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_263 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_131 (Dropout)        (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_131 (Flatten)        (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_393 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_394 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_395 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4899 - accuracy: 0.0136\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/15\n",
      "7767/7767 [==============================] - 3s 401us/sample - loss: 1.1655 - accuracy: 0.6577 - val_loss: 0.7767 - val_accuracy: 0.7495\n",
      "Epoch 2/15\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.6893 - accuracy: 0.7783 - val_loss: 0.7248 - val_accuracy: 0.7473\n",
      "Epoch 3/15\n",
      "7767/7767 [==============================] - 3s 342us/sample - loss: 0.6453 - accuracy: 0.7815 - val_loss: 0.6322 - val_accuracy: 0.7755\n",
      "Epoch 4/15\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.6128 - accuracy: 0.7876 - val_loss: 0.6758 - val_accuracy: 0.7622\n",
      "Epoch 5/15\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.2712 - accuracy: 0.9087 - val_loss: 0.2859 - val_accuracy: 0.8997\n",
      "Epoch 6/15\n",
      "7767/7767 [==============================] - 3s 333us/sample - loss: 0.1851 - accuracy: 0.9336 - val_loss: 0.2788 - val_accuracy: 0.9026\n",
      "Epoch 7/15\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.1701 - accuracy: 0.9372 - val_loss: 0.2308 - val_accuracy: 0.9184\n",
      "Epoch 8/15\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.1626 - accuracy: 0.9399 - val_loss: 0.3084 - val_accuracy: 0.8944\n",
      "Epoch 9/15\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 0.1541 - accuracy: 0.9415 - val_loss: 0.2702 - val_accuracy: 0.9121\n",
      "Epoch 10/15\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.1492 - accuracy: 0.9453 - val_loss: 0.2841 - val_accuracy: 0.9023\n",
      "Epoch 11/15\n",
      "7767/7767 [==============================] - 3s 333us/sample - loss: 0.1528 - accuracy: 0.9432 - val_loss: 0.2757 - val_accuracy: 0.9121\n",
      "Epoch 12/15\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.1483 - accuracy: 0.9435 - val_loss: 0.2880 - val_accuracy: 0.9023\n",
      "Epoch 13/15\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 0.1458 - accuracy: 0.9462 - val_loss: 0.2517 - val_accuracy: 0.9140\n",
      "Epoch 14/15\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.1425 - accuracy: 0.9463 - val_loss: 0.2465 - val_accuracy: 0.9118\n",
      "Epoch 15/15\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.1366 - accuracy: 0.9480 - val_loss: 0.2507 - val_accuracy: 0.9159\n",
      "3162/3162 - 0s - loss: 0.2507 - accuracy: 0.9159\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002240BB66048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002240BB66048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-15_it-1\\assets\n",
      "Model: \"sequential_132\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_264 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_264 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_265 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_265 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_132 (Dropout)        (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_132 (Flatten)        (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_396 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_397 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_398 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4873 - accuracy: 0.1331\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/15\n",
      "7767/7767 [==============================] - 3s 407us/sample - loss: 1.0507 - accuracy: 0.6875 - val_loss: 0.7894 - val_accuracy: 0.7676\n",
      "Epoch 2/15\n",
      "7767/7767 [==============================] - 3s 339us/sample - loss: 0.6797 - accuracy: 0.7854 - val_loss: 0.6600 - val_accuracy: 0.7713\n",
      "Epoch 3/15\n",
      "7767/7767 [==============================] - 3s 341us/sample - loss: 0.6290 - accuracy: 0.7885 - val_loss: 0.6687 - val_accuracy: 0.7774\n",
      "Epoch 4/15\n",
      "7767/7767 [==============================] - 3s 344us/sample - loss: 0.5790 - accuracy: 0.8003 - val_loss: 0.6324 - val_accuracy: 0.7802\n",
      "Epoch 5/15\n",
      "7767/7767 [==============================] - 3s 339us/sample - loss: 0.5596 - accuracy: 0.8007 - val_loss: 0.6637 - val_accuracy: 0.7682\n",
      "Epoch 6/15\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.5584 - accuracy: 0.8025 - val_loss: 0.6711 - val_accuracy: 0.7729\n",
      "Epoch 7/15\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.5469 - accuracy: 0.8024 - val_loss: 0.6726 - val_accuracy: 0.7732\n",
      "Epoch 8/15\n",
      "7767/7767 [==============================] - 3s 333us/sample - loss: 0.5382 - accuracy: 0.8022 - val_loss: 0.6347 - val_accuracy: 0.7783\n",
      "Epoch 9/15\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.5242 - accuracy: 0.8089 - val_loss: 0.6514 - val_accuracy: 0.7783\n",
      "Epoch 10/15\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.5273 - accuracy: 0.8056 - val_loss: 0.6350 - val_accuracy: 0.7751\n",
      "Epoch 11/15\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 0.5215 - accuracy: 0.8080 - val_loss: 0.6005 - val_accuracy: 0.7887\n",
      "Epoch 12/15\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 0.5114 - accuracy: 0.8078 - val_loss: 0.6398 - val_accuracy: 0.7840\n",
      "Epoch 13/15\n",
      "7767/7767 [==============================] - 3s 332us/sample - loss: 0.5082 - accuracy: 0.8088 - val_loss: 0.5915 - val_accuracy: 0.7922\n",
      "Epoch 14/15\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 0.5103 - accuracy: 0.8097 - val_loss: 0.6242 - val_accuracy: 0.7812\n",
      "Epoch 15/15\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.5083 - accuracy: 0.8080 - val_loss: 0.6298 - val_accuracy: 0.7881\n",
      "3162/3162 - 0s - loss: 0.6298 - accuracy: 0.7881\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000022412B66E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000022412B66E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-15_it-2\\assets\n",
      "Model: \"sequential_133\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_266 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_266 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_267 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_267 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_133 (Dropout)        (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_133 (Flatten)        (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_399 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_400 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_401 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4945 - accuracy: 0.0361\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/15\n",
      "7767/7767 [==============================] - 3s 409us/sample - loss: 1.1890 - accuracy: 0.5762 - val_loss: 0.8424 - val_accuracy: 0.6603\n",
      "Epoch 2/15\n",
      "7767/7767 [==============================] - 3s 339us/sample - loss: 0.7511 - accuracy: 0.7131 - val_loss: 0.8066 - val_accuracy: 0.6676\n",
      "Epoch 3/15\n",
      "7767/7767 [==============================] - 3s 339us/sample - loss: 0.6773 - accuracy: 0.7394 - val_loss: 0.7351 - val_accuracy: 0.7113\n",
      "Epoch 4/15\n",
      "7767/7767 [==============================] - 3s 347us/sample - loss: 0.6581 - accuracy: 0.7452 - val_loss: 0.7039 - val_accuracy: 0.7309\n",
      "Epoch 5/15\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.6348 - accuracy: 0.7525 - val_loss: 0.7204 - val_accuracy: 0.7226\n",
      "Epoch 6/15\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.6277 - accuracy: 0.7551 - val_loss: 0.7396 - val_accuracy: 0.7090\n",
      "Epoch 7/15\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.6323 - accuracy: 0.7541 - val_loss: 0.6857 - val_accuracy: 0.7404\n",
      "Epoch 8/15\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.6209 - accuracy: 0.7574 - val_loss: 0.7402 - val_accuracy: 0.7154\n",
      "Epoch 9/15\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.6038 - accuracy: 0.7627 - val_loss: 0.6736 - val_accuracy: 0.7391\n",
      "Epoch 10/15\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.6007 - accuracy: 0.7631 - val_loss: 0.6847 - val_accuracy: 0.7410\n",
      "Epoch 11/15\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.5961 - accuracy: 0.7630 - val_loss: 0.6670 - val_accuracy: 0.7438\n",
      "Epoch 12/15\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.5987 - accuracy: 0.7618 - val_loss: 0.8043 - val_accuracy: 0.7065\n",
      "Epoch 13/15\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.5967 - accuracy: 0.7636 - val_loss: 0.7159 - val_accuracy: 0.7261\n",
      "Epoch 14/15\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.5863 - accuracy: 0.7671 - val_loss: 0.6918 - val_accuracy: 0.7372\n",
      "Epoch 15/15\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.5844 - accuracy: 0.7681 - val_loss: 0.6763 - val_accuracy: 0.7419\n",
      "3162/3162 - 0s - loss: 0.6763 - accuracy: 0.7419\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223FF6DF168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223FF6DF168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-15_it-3\\assets\n",
      "Model: \"sequential_134\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_268 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_268 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_269 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_269 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_134 (Dropout)        (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_134 (Flatten)        (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_402 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_403 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_404 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.5234 - accuracy: 0.0085\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/15\n",
      "7767/7767 [==============================] - 3s 413us/sample - loss: 1.3527 - accuracy: 0.5944 - val_loss: 1.1208 - val_accuracy: 0.6281\n",
      "Epoch 2/15\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 1.0377 - accuracy: 0.6489 - val_loss: 1.0418 - val_accuracy: 0.6331\n",
      "Epoch 3/15\n",
      "7767/7767 [==============================] - 3s 349us/sample - loss: 0.9786 - accuracy: 0.6524 - val_loss: 1.0347 - val_accuracy: 0.6271\n",
      "Epoch 4/15\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.9482 - accuracy: 0.6529 - val_loss: 1.0044 - val_accuracy: 0.6335\n",
      "Epoch 5/15\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.9380 - accuracy: 0.6537 - val_loss: 1.0083 - val_accuracy: 0.6360\n",
      "Epoch 6/15\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.9254 - accuracy: 0.6550 - val_loss: 0.9903 - val_accuracy: 0.6344\n",
      "Epoch 7/15\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.9200 - accuracy: 0.6539 - val_loss: 1.0067 - val_accuracy: 0.6354\n",
      "Epoch 8/15\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.9150 - accuracy: 0.6537 - val_loss: 1.0097 - val_accuracy: 0.6338\n",
      "Epoch 9/15\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.9088 - accuracy: 0.6546 - val_loss: 0.9924 - val_accuracy: 0.6341\n",
      "Epoch 10/15\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.9065 - accuracy: 0.6548 - val_loss: 1.0642 - val_accuracy: 0.6135\n",
      "Epoch 11/15\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.9023 - accuracy: 0.6546 - val_loss: 1.0463 - val_accuracy: 0.6104\n",
      "Epoch 12/15\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.9006 - accuracy: 0.6552 - val_loss: 0.9971 - val_accuracy: 0.6297\n",
      "Epoch 13/15\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.8955 - accuracy: 0.6552 - val_loss: 0.9982 - val_accuracy: 0.6312\n",
      "Epoch 14/15\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.8993 - accuracy: 0.6548 - val_loss: 0.9900 - val_accuracy: 0.6341\n",
      "Epoch 15/15\n",
      "7767/7767 [==============================] - 3s 339us/sample - loss: 0.8926 - accuracy: 0.6553 - val_loss: 1.0132 - val_accuracy: 0.6325\n",
      "3162/3162 - 0s - loss: 1.0132 - accuracy: 0.6325\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223EE1EAD38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223EE1EAD38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-15_it-4\\assets\n",
      "Model: \"sequential_135\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_270 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_270 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_271 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_271 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_135 (Dropout)        (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_135 (Flatten)        (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_405 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_406 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_407 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4796 - accuracy: 0.0674\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/15\n",
      "7767/7767 [==============================] - 3s 419us/sample - loss: 0.6964 - accuracy: 0.7381 - val_loss: 0.3428 - val_accuracy: 0.8789\n",
      "Epoch 2/15\n",
      "7767/7767 [==============================] - 3s 339us/sample - loss: 0.2911 - accuracy: 0.8915 - val_loss: 0.2767 - val_accuracy: 0.9058\n",
      "Epoch 3/15\n",
      "7767/7767 [==============================] - 3s 343us/sample - loss: 0.2045 - accuracy: 0.9273 - val_loss: 0.2456 - val_accuracy: 0.9105\n",
      "Epoch 4/15\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.1747 - accuracy: 0.9358 - val_loss: 0.2234 - val_accuracy: 0.9203\n",
      "Epoch 5/15\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.1558 - accuracy: 0.9439 - val_loss: 0.2114 - val_accuracy: 0.9257\n",
      "Epoch 6/15\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 0.1468 - accuracy: 0.9491 - val_loss: 0.2255 - val_accuracy: 0.9254\n",
      "Epoch 7/15\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.1240 - accuracy: 0.9573 - val_loss: 0.2369 - val_accuracy: 0.9200\n",
      "Epoch 8/15\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.1225 - accuracy: 0.9553 - val_loss: 0.2098 - val_accuracy: 0.9276\n",
      "Epoch 9/15\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.1196 - accuracy: 0.9561 - val_loss: 0.1822 - val_accuracy: 0.9390\n",
      "Epoch 10/15\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.1132 - accuracy: 0.9591 - val_loss: 0.2204 - val_accuracy: 0.9285\n",
      "Epoch 11/15\n",
      "7767/7767 [==============================] - 3s 339us/sample - loss: 0.0992 - accuracy: 0.9652 - val_loss: 0.2689 - val_accuracy: 0.9200\n",
      "Epoch 12/15\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.0989 - accuracy: 0.9638 - val_loss: 0.2434 - val_accuracy: 0.9260\n",
      "Epoch 13/15\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.0984 - accuracy: 0.9641 - val_loss: 0.2052 - val_accuracy: 0.9339\n",
      "Epoch 14/15\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.0890 - accuracy: 0.9665 - val_loss: 0.2118 - val_accuracy: 0.9317\n",
      "Epoch 15/15\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.0862 - accuracy: 0.9677 - val_loss: 0.2555 - val_accuracy: 0.9244\n",
      "3162/3162 - 0s - loss: 0.2555 - accuracy: 0.9244\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002237B087EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002237B087EE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-15_it-5\\assets\n",
      "Model: \"sequential_136\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_272 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_272 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_273 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_273 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_136 (Dropout)        (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_136 (Flatten)        (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_408 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_409 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_410 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4835 - accuracy: 0.0952\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/15\n",
      "7767/7767 [==============================] - 3s 410us/sample - loss: 0.7390 - accuracy: 0.7187 - val_loss: 0.3347 - val_accuracy: 0.8966\n",
      "Epoch 2/15\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.2757 - accuracy: 0.9015 - val_loss: 0.2676 - val_accuracy: 0.8963\n",
      "Epoch 3/15\n",
      "7767/7767 [==============================] - 3s 347us/sample - loss: 0.1871 - accuracy: 0.9331 - val_loss: 0.2217 - val_accuracy: 0.9222\n",
      "Epoch 4/15\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.1526 - accuracy: 0.9412 - val_loss: 0.2149 - val_accuracy: 0.9187\n",
      "Epoch 5/15\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.1394 - accuracy: 0.9471 - val_loss: 0.2222 - val_accuracy: 0.9181\n",
      "Epoch 6/15\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.1218 - accuracy: 0.9547 - val_loss: 0.2131 - val_accuracy: 0.9228\n",
      "Epoch 7/15\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.1086 - accuracy: 0.9614 - val_loss: 0.3163 - val_accuracy: 0.9029\n",
      "Epoch 8/15\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 0.1100 - accuracy: 0.9602 - val_loss: 0.2398 - val_accuracy: 0.9181\n",
      "Epoch 9/15\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.0918 - accuracy: 0.9654 - val_loss: 0.2256 - val_accuracy: 0.9197\n",
      "Epoch 10/15\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.0918 - accuracy: 0.9663 - val_loss: 0.2842 - val_accuracy: 0.9086\n",
      "Epoch 11/15\n",
      "7767/7767 [==============================] - 3s 344us/sample - loss: 0.0872 - accuracy: 0.9667 - val_loss: 0.2289 - val_accuracy: 0.9231\n",
      "Epoch 12/15\n",
      "7767/7767 [==============================] - 3s 351us/sample - loss: 0.0842 - accuracy: 0.9690 - val_loss: 0.2320 - val_accuracy: 0.9301\n",
      "Epoch 13/15\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.0717 - accuracy: 0.9728 - val_loss: 0.2236 - val_accuracy: 0.9266\n",
      "Epoch 14/15\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.0711 - accuracy: 0.9750 - val_loss: 0.2369 - val_accuracy: 0.9269\n",
      "Epoch 15/15\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.0643 - accuracy: 0.9757 - val_loss: 0.2131 - val_accuracy: 0.9326\n",
      "3162/3162 - 0s - loss: 0.2131 - accuracy: 0.9326\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002240AF10A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002240AF10A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-15_it-6\\assets\n",
      "Model: \"sequential_137\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_274 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_274 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_275 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_275 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_137 (Dropout)        (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_137 (Flatten)        (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_411 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_412 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_413 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4894 - accuracy: 0.0987\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/15\n",
      "7767/7767 [==============================] - 3s 413us/sample - loss: 1.1236 - accuracy: 0.6023 - val_loss: 0.8408 - val_accuracy: 0.6907\n",
      "Epoch 2/15\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.3241 - accuracy: 0.8844 - val_loss: 0.2745 - val_accuracy: 0.9070\n",
      "Epoch 3/15\n",
      "7767/7767 [==============================] - 3s 347us/sample - loss: 0.2375 - accuracy: 0.9146 - val_loss: 0.2771 - val_accuracy: 0.9032\n",
      "Epoch 4/15\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 0.2074 - accuracy: 0.9249 - val_loss: 0.2425 - val_accuracy: 0.9140\n",
      "Epoch 5/15\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.1948 - accuracy: 0.9293 - val_loss: 0.2650 - val_accuracy: 0.9042\n",
      "Epoch 6/15\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.1789 - accuracy: 0.9354 - val_loss: 0.2406 - val_accuracy: 0.9152\n",
      "Epoch 7/15\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.1558 - accuracy: 0.9454 - val_loss: 0.2488 - val_accuracy: 0.9156\n",
      "Epoch 8/15\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.1595 - accuracy: 0.9431 - val_loss: 0.2533 - val_accuracy: 0.9108\n",
      "Epoch 9/15\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.1416 - accuracy: 0.9459 - val_loss: 0.2784 - val_accuracy: 0.9048\n",
      "Epoch 10/15\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.1422 - accuracy: 0.9498 - val_loss: 0.2699 - val_accuracy: 0.9165\n",
      "Epoch 11/15\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 0.1280 - accuracy: 0.9558 - val_loss: 0.2556 - val_accuracy: 0.9175\n",
      "Epoch 12/15\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.1201 - accuracy: 0.9592 - val_loss: 0.2462 - val_accuracy: 0.9216\n",
      "Epoch 13/15\n",
      "7767/7767 [==============================] - 3s 362us/sample - loss: 0.1107 - accuracy: 0.9621 - val_loss: 0.2571 - val_accuracy: 0.9219\n",
      "Epoch 14/15\n",
      "7767/7767 [==============================] - 3s 357us/sample - loss: 0.1136 - accuracy: 0.9605 - val_loss: 0.2744 - val_accuracy: 0.9162\n",
      "Epoch 15/15\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.1102 - accuracy: 0.9621 - val_loss: 0.3000 - val_accuracy: 0.9111\n",
      "3162/3162 - 0s - loss: 0.3000 - accuracy: 0.9111\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223EB814D38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223EB814D38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-15_it-7\\assets\n",
      "Model: \"sequential_138\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_276 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_276 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_277 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_277 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_138 (Dropout)        (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_138 (Flatten)        (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_414 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_415 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_416 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4752 - accuracy: 0.0727\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/15\n",
      "7767/7767 [==============================] - 3s 417us/sample - loss: 0.6542 - accuracy: 0.7608 - val_loss: 0.3472 - val_accuracy: 0.8824\n",
      "Epoch 2/15\n",
      "7767/7767 [==============================] - 3s 346us/sample - loss: 0.2676 - accuracy: 0.8998 - val_loss: 0.2962 - val_accuracy: 0.8786\n",
      "Epoch 3/15\n",
      "7767/7767 [==============================] - 3s 350us/sample - loss: 0.2036 - accuracy: 0.9207 - val_loss: 0.2413 - val_accuracy: 0.9070\n",
      "Epoch 4/15\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.1655 - accuracy: 0.9379 - val_loss: 0.3077 - val_accuracy: 0.9042\n",
      "Epoch 5/15\n",
      "7767/7767 [==============================] - 3s 340us/sample - loss: 0.1461 - accuracy: 0.9484 - val_loss: 0.2414 - val_accuracy: 0.9165\n",
      "Epoch 6/15\n",
      "7767/7767 [==============================] - 3s 339us/sample - loss: 0.1338 - accuracy: 0.9542 - val_loss: 0.2101 - val_accuracy: 0.9257\n",
      "Epoch 7/15\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.1231 - accuracy: 0.9570 - val_loss: 0.2282 - val_accuracy: 0.9238\n",
      "Epoch 8/15\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.1176 - accuracy: 0.9583 - val_loss: 0.2633 - val_accuracy: 0.9092\n",
      "Epoch 9/15\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.1078 - accuracy: 0.9627 - val_loss: 0.2612 - val_accuracy: 0.9149\n",
      "Epoch 10/15\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.1015 - accuracy: 0.9638 - val_loss: 0.2399 - val_accuracy: 0.9190\n",
      "Epoch 11/15\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.1005 - accuracy: 0.9643 - val_loss: 0.3231 - val_accuracy: 0.9035\n",
      "Epoch 12/15\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.0938 - accuracy: 0.9676 - val_loss: 0.2485 - val_accuracy: 0.9260\n",
      "Epoch 13/15\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.0913 - accuracy: 0.9670 - val_loss: 0.2217 - val_accuracy: 0.9254\n",
      "Epoch 14/15\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.0913 - accuracy: 0.9665 - val_loss: 0.2693 - val_accuracy: 0.9197\n",
      "Epoch 15/15\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.0874 - accuracy: 0.9659 - val_loss: 0.2189 - val_accuracy: 0.9355\n",
      "3162/3162 - 0s - loss: 0.2189 - accuracy: 0.9355\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223D4196828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223D4196828> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-15_it-8\\assets\n",
      "Model: \"sequential_139\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_278 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_278 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_279 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_279 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_139 (Dropout)        (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_139 (Flatten)        (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_417 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_418 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_419 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4744 - accuracy: 0.0702\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/15\n",
      "7767/7767 [==============================] - 3s 407us/sample - loss: 0.6882 - accuracy: 0.7524 - val_loss: 0.3542 - val_accuracy: 0.8748\n",
      "Epoch 2/15\n",
      "7767/7767 [==============================] - 3s 339us/sample - loss: 0.2915 - accuracy: 0.8943 - val_loss: 0.3060 - val_accuracy: 0.8941\n",
      "Epoch 3/15\n",
      "7767/7767 [==============================] - 3s 349us/sample - loss: 0.2184 - accuracy: 0.9239 - val_loss: 0.2492 - val_accuracy: 0.9086\n",
      "Epoch 4/15\n",
      "7767/7767 [==============================] - 3s 339us/sample - loss: 0.1547 - accuracy: 0.9466 - val_loss: 0.2175 - val_accuracy: 0.9231\n",
      "Epoch 5/15\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.1268 - accuracy: 0.9543 - val_loss: 0.2210 - val_accuracy: 0.9219\n",
      "Epoch 6/15\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.1145 - accuracy: 0.9592 - val_loss: 0.2323 - val_accuracy: 0.9152\n",
      "Epoch 7/15\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.1100 - accuracy: 0.9597 - val_loss: 0.1928 - val_accuracy: 0.9276\n",
      "Epoch 8/15\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.0858 - accuracy: 0.9692 - val_loss: 0.2082 - val_accuracy: 0.9295\n",
      "Epoch 9/15\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.0856 - accuracy: 0.9700 - val_loss: 0.1993 - val_accuracy: 0.9304\n",
      "Epoch 10/15\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.0814 - accuracy: 0.9722 - val_loss: 0.2766 - val_accuracy: 0.9190\n",
      "Epoch 11/15\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.0687 - accuracy: 0.9743 - val_loss: 0.4021 - val_accuracy: 0.8944\n",
      "Epoch 12/15\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.0707 - accuracy: 0.9743 - val_loss: 0.2423 - val_accuracy: 0.9304\n",
      "Epoch 13/15\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.0731 - accuracy: 0.9708 - val_loss: 0.2080 - val_accuracy: 0.9307\n",
      "Epoch 14/15\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.0652 - accuracy: 0.9755 - val_loss: 0.2093 - val_accuracy: 0.9330\n",
      "Epoch 15/15\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.0590 - accuracy: 0.9777 - val_loss: 0.1836 - val_accuracy: 0.9431\n",
      "3162/3162 - 0s - loss: 0.1836 - accuracy: 0.9431\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223B74B9948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223B74B9948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-15_it-9\\assets\n",
      "Model: \"sequential_140\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_280 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_280 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_281 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_281 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_140 (Dropout)        (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_140 (Flatten)        (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_420 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_421 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_422 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4762 - accuracy: 0.0300\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/20\n",
      "7767/7767 [==============================] - 3s 414us/sample - loss: 1.0576 - accuracy: 0.6525 - val_loss: 0.8028 - val_accuracy: 0.7783\n",
      "Epoch 2/20\n",
      "7767/7767 [==============================] - 3s 341us/sample - loss: 0.6576 - accuracy: 0.8488 - val_loss: 0.6659 - val_accuracy: 0.8586\n",
      "Epoch 3/20\n",
      "7767/7767 [==============================] - 3s 343us/sample - loss: 0.5879 - accuracy: 0.8988 - val_loss: 0.6525 - val_accuracy: 0.8725\n",
      "Epoch 4/20\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.5726 - accuracy: 0.9122 - val_loss: 0.6413 - val_accuracy: 0.9045\n",
      "Epoch 5/20\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 0.5526 - accuracy: 0.9242 - val_loss: 0.6252 - val_accuracy: 0.9020\n",
      "Epoch 6/20\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.5368 - accuracy: 0.9388 - val_loss: 0.6060 - val_accuracy: 0.9118\n",
      "Epoch 7/20\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.5347 - accuracy: 0.9358 - val_loss: 0.7053 - val_accuracy: 0.8934\n",
      "Epoch 8/20\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.5193 - accuracy: 0.9450 - val_loss: 0.6368 - val_accuracy: 0.9197\n",
      "Epoch 9/20\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.5206 - accuracy: 0.9453 - val_loss: 0.5993 - val_accuracy: 0.9152\n",
      "Epoch 10/20\n",
      "7767/7767 [==============================] - 3s 341us/sample - loss: 0.5139 - accuracy: 0.9488 - val_loss: 0.6180 - val_accuracy: 0.9168\n",
      "Epoch 11/20\n",
      "7767/7767 [==============================] - 3s 352us/sample - loss: 0.5065 - accuracy: 0.9522 - val_loss: 0.6265 - val_accuracy: 0.9235\n",
      "Epoch 12/20\n",
      "7767/7767 [==============================] - 3s 345us/sample - loss: 0.5031 - accuracy: 0.9560 - val_loss: 0.6237 - val_accuracy: 0.9228\n",
      "Epoch 13/20\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.4978 - accuracy: 0.9564 - val_loss: 0.6153 - val_accuracy: 0.9266\n",
      "Epoch 14/20\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.4997 - accuracy: 0.9569 - val_loss: 0.6630 - val_accuracy: 0.8798\n",
      "Epoch 15/20\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.4947 - accuracy: 0.9565 - val_loss: 0.6204 - val_accuracy: 0.9213\n",
      "Epoch 16/20\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.4883 - accuracy: 0.9597 - val_loss: 0.6037 - val_accuracy: 0.9266\n",
      "Epoch 17/20\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.4857 - accuracy: 0.9607 - val_loss: 0.6246 - val_accuracy: 0.9200\n",
      "Epoch 18/20\n",
      "7767/7767 [==============================] - 3s 339us/sample - loss: 0.4919 - accuracy: 0.9603 - val_loss: 0.6715 - val_accuracy: 0.9140\n",
      "Epoch 19/20\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.4817 - accuracy: 0.9642 - val_loss: 0.6780 - val_accuracy: 0.9137\n",
      "Epoch 20/20\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.4865 - accuracy: 0.9619 - val_loss: 0.6769 - val_accuracy: 0.9042\n",
      "3162/3162 - 0s - loss: 0.6769 - accuracy: 0.9042\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223B74B9AF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223B74B9AF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-20_it-0\\assets\n",
      "Model: \"sequential_141\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_282 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_282 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_283 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_283 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_141 (Dropout)        (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_141 (Flatten)        (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_423 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_424 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_425 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4870 - accuracy: 0.0092\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/20\n",
      "7767/7767 [==============================] - 3s 412us/sample - loss: 1.3501 - accuracy: 0.5780 - val_loss: 1.1313 - val_accuracy: 0.6388\n",
      "Epoch 2/20\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 1.0518 - accuracy: 0.6392 - val_loss: 1.0317 - val_accuracy: 0.6376\n",
      "Epoch 3/20\n",
      "7767/7767 [==============================] - 3s 346us/sample - loss: 1.0008 - accuracy: 0.6443 - val_loss: 0.9969 - val_accuracy: 0.6436\n",
      "Epoch 4/20\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.9634 - accuracy: 0.6465 - val_loss: 0.9866 - val_accuracy: 0.6452\n",
      "Epoch 5/20\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.9437 - accuracy: 0.6484 - val_loss: 1.0149 - val_accuracy: 0.6398\n",
      "Epoch 6/20\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.9376 - accuracy: 0.6492 - val_loss: 1.0266 - val_accuracy: 0.6439\n",
      "Epoch 7/20\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.9248 - accuracy: 0.6511 - val_loss: 1.0281 - val_accuracy: 0.6221\n",
      "Epoch 8/20\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.9177 - accuracy: 0.6503 - val_loss: 1.0521 - val_accuracy: 0.6275\n",
      "Epoch 9/20\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.9133 - accuracy: 0.6522 - val_loss: 1.0448 - val_accuracy: 0.6331\n",
      "Epoch 10/20\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.9121 - accuracy: 0.6511 - val_loss: 0.9784 - val_accuracy: 0.6379\n",
      "Epoch 11/20\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.8987 - accuracy: 0.6540 - val_loss: 0.9711 - val_accuracy: 0.6376\n",
      "Epoch 12/20\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.9036 - accuracy: 0.6542 - val_loss: 0.9731 - val_accuracy: 0.6388\n",
      "Epoch 13/20\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.8972 - accuracy: 0.6547 - val_loss: 1.0220 - val_accuracy: 0.6354\n",
      "Epoch 14/20\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 0.9002 - accuracy: 0.6530 - val_loss: 0.9650 - val_accuracy: 0.6420\n",
      "Epoch 15/20\n",
      "7767/7767 [==============================] - 3s 347us/sample - loss: 0.8904 - accuracy: 0.6552 - val_loss: 1.0374 - val_accuracy: 0.6322\n",
      "Epoch 16/20\n",
      "7767/7767 [==============================] - 3s 339us/sample - loss: 0.8928 - accuracy: 0.6551 - val_loss: 1.0947 - val_accuracy: 0.6233\n",
      "Epoch 17/20\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.8880 - accuracy: 0.6544 - val_loss: 0.9986 - val_accuracy: 0.6319\n",
      "Epoch 18/20\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.8918 - accuracy: 0.6538 - val_loss: 1.0179 - val_accuracy: 0.6344\n",
      "Epoch 19/20\n",
      "7767/7767 [==============================] - 3s 339us/sample - loss: 0.8870 - accuracy: 0.6548 - val_loss: 1.0001 - val_accuracy: 0.6407\n",
      "Epoch 20/20\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.8825 - accuracy: 0.6556 - val_loss: 1.0001 - val_accuracy: 0.6417\n",
      "3162/3162 - 0s - loss: 1.0001 - accuracy: 0.6417\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223F240A3A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223F240A3A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-20_it-1\\assets\n",
      "Model: \"sequential_142\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_284 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_284 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_285 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_285 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_142 (Dropout)        (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_142 (Flatten)        (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_426 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_427 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_428 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4943 - accuracy: 0.0155\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/20\n",
      "7767/7767 [==============================] - 3s 409us/sample - loss: 0.7627 - accuracy: 0.7291 - val_loss: 0.4020 - val_accuracy: 0.8542\n",
      "Epoch 2/20\n",
      "7767/7767 [==============================] - 3s 339us/sample - loss: 0.2889 - accuracy: 0.8958 - val_loss: 0.3153 - val_accuracy: 0.8836\n",
      "Epoch 3/20\n",
      "7767/7767 [==============================] - 3s 344us/sample - loss: 0.2264 - accuracy: 0.9226 - val_loss: 0.3794 - val_accuracy: 0.8586\n",
      "Epoch 4/20\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 0.2015 - accuracy: 0.9325 - val_loss: 0.2529 - val_accuracy: 0.9162\n",
      "Epoch 5/20\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.1755 - accuracy: 0.9413 - val_loss: 0.2259 - val_accuracy: 0.9231\n",
      "Epoch 6/20\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.1611 - accuracy: 0.9449 - val_loss: 0.2753 - val_accuracy: 0.9042\n",
      "Epoch 7/20\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.1497 - accuracy: 0.9495 - val_loss: 0.2568 - val_accuracy: 0.9178\n",
      "Epoch 8/20\n",
      "7767/7767 [==============================] - 3s 332us/sample - loss: 0.1466 - accuracy: 0.9499 - val_loss: 0.3030 - val_accuracy: 0.9080\n",
      "Epoch 9/20\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 0.1446 - accuracy: 0.9511 - val_loss: 0.2353 - val_accuracy: 0.9194\n",
      "Epoch 10/20\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.1348 - accuracy: 0.9538 - val_loss: 0.2661 - val_accuracy: 0.9111\n",
      "Epoch 11/20\n",
      "7767/7767 [==============================] - 3s 332us/sample - loss: 0.1294 - accuracy: 0.9543 - val_loss: 0.2746 - val_accuracy: 0.9159\n",
      "Epoch 12/20\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 0.1265 - accuracy: 0.9556 - val_loss: 0.2553 - val_accuracy: 0.9219\n",
      "Epoch 13/20\n",
      "7767/7767 [==============================] - 3s 333us/sample - loss: 0.1187 - accuracy: 0.9578 - val_loss: 0.2663 - val_accuracy: 0.9200\n",
      "Epoch 14/20\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.1151 - accuracy: 0.9575 - val_loss: 0.2438 - val_accuracy: 0.9285\n",
      "Epoch 15/20\n",
      "7767/7767 [==============================] - 3s 360us/sample - loss: 0.1128 - accuracy: 0.9583 - val_loss: 0.2857 - val_accuracy: 0.9178\n",
      "Epoch 16/20\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.1168 - accuracy: 0.9565 - val_loss: 0.3162 - val_accuracy: 0.9080\n",
      "Epoch 17/20\n",
      "7767/7767 [==============================] - 3s 332us/sample - loss: 0.1118 - accuracy: 0.9612 - val_loss: 0.2425 - val_accuracy: 0.9250\n",
      "Epoch 18/20\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.1055 - accuracy: 0.9609 - val_loss: 0.2544 - val_accuracy: 0.9225\n",
      "Epoch 19/20\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 0.1067 - accuracy: 0.9628 - val_loss: 0.2860 - val_accuracy: 0.9156\n",
      "Epoch 20/20\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.1044 - accuracy: 0.9618 - val_loss: 0.3311 - val_accuracy: 0.9118\n",
      "3162/3162 - 0s - loss: 0.3311 - accuracy: 0.9118\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223EDD15A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223EDD15A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-20_it-2\\assets\n",
      "Model: \"sequential_143\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_286 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_286 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_287 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_287 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_143 (Dropout)        (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_143 (Flatten)        (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_429 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_430 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_431 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.5087 - accuracy: 0.0079\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/20\n",
      "7767/7767 [==============================] - 3s 419us/sample - loss: 0.8174 - accuracy: 0.7075 - val_loss: 0.4495 - val_accuracy: 0.8447\n",
      "Epoch 2/20\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.2967 - accuracy: 0.8944 - val_loss: 0.3529 - val_accuracy: 0.8621\n",
      "Epoch 3/20\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.2408 - accuracy: 0.9146 - val_loss: 0.2977 - val_accuracy: 0.8918\n",
      "Epoch 4/20\n",
      "7767/7767 [==============================] - 3s 341us/sample - loss: 0.2142 - accuracy: 0.9230 - val_loss: 0.2740 - val_accuracy: 0.9058\n",
      "Epoch 5/20\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.1969 - accuracy: 0.9367 - val_loss: 0.2836 - val_accuracy: 0.9092\n",
      "Epoch 6/20\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.1747 - accuracy: 0.9427 - val_loss: 0.2744 - val_accuracy: 0.9070\n",
      "Epoch 7/20\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.1606 - accuracy: 0.9462 - val_loss: 0.3175 - val_accuracy: 0.9007\n",
      "Epoch 8/20\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 0.1640 - accuracy: 0.9421 - val_loss: 0.2303 - val_accuracy: 0.9216\n",
      "Epoch 9/20\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.1470 - accuracy: 0.9489 - val_loss: 0.2665 - val_accuracy: 0.9152\n",
      "Epoch 10/20\n",
      "7767/7767 [==============================] - 3s 333us/sample - loss: 0.1438 - accuracy: 0.9506 - val_loss: 0.3778 - val_accuracy: 0.8884\n",
      "Epoch 11/20\n",
      "7767/7767 [==============================] - 3s 333us/sample - loss: 0.1469 - accuracy: 0.9471 - val_loss: 0.2902 - val_accuracy: 0.9061\n",
      "Epoch 12/20\n",
      "7767/7767 [==============================] - 3s 333us/sample - loss: 0.1302 - accuracy: 0.9533 - val_loss: 0.2646 - val_accuracy: 0.9159\n",
      "Epoch 13/20\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.1268 - accuracy: 0.9558 - val_loss: 0.2469 - val_accuracy: 0.9203\n",
      "Epoch 14/20\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.1311 - accuracy: 0.9521 - val_loss: 0.2981 - val_accuracy: 0.9089\n",
      "Epoch 15/20\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.1263 - accuracy: 0.9548 - val_loss: 0.2819 - val_accuracy: 0.9190\n",
      "Epoch 16/20\n",
      "7767/7767 [==============================] - 3s 341us/sample - loss: 0.1391 - accuracy: 0.9499 - val_loss: 0.3004 - val_accuracy: 0.9054\n",
      "Epoch 17/20\n",
      "7767/7767 [==============================] - 3s 333us/sample - loss: 0.1164 - accuracy: 0.9575 - val_loss: 0.2686 - val_accuracy: 0.9156\n",
      "Epoch 18/20\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.1207 - accuracy: 0.9561 - val_loss: 0.4417 - val_accuracy: 0.8871\n",
      "Epoch 19/20\n",
      "7767/7767 [==============================] - 3s 345us/sample - loss: 0.1145 - accuracy: 0.9596 - val_loss: 0.2747 - val_accuracy: 0.9175\n",
      "Epoch 20/20\n",
      "7767/7767 [==============================] - 3s 331us/sample - loss: 0.1153 - accuracy: 0.9578 - val_loss: 0.2445 - val_accuracy: 0.9194\n",
      "3162/3162 - 0s - loss: 0.2445 - accuracy: 0.9194\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000022401783318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x0000022401783318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-20_it-3\\assets\n",
      "Model: \"sequential_144\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_288 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_288 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_289 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_289 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_144 (Dropout)        (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_144 (Flatten)        (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_432 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_433 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_434 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.5055 - accuracy: 0.0089\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/20\n",
      "7767/7767 [==============================] - 3s 400us/sample - loss: 1.1485 - accuracy: 0.6453 - val_loss: 0.7930 - val_accuracy: 0.7426\n",
      "Epoch 2/20\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 0.5939 - accuracy: 0.8043 - val_loss: 0.3246 - val_accuracy: 0.8792\n",
      "Epoch 3/20\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.2642 - accuracy: 0.9007 - val_loss: 0.2944 - val_accuracy: 0.8887\n",
      "Epoch 4/20\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.2265 - accuracy: 0.9148 - val_loss: 0.3772 - val_accuracy: 0.8703\n",
      "Epoch 5/20\n",
      "7767/7767 [==============================] - 3s 329us/sample - loss: 0.2033 - accuracy: 0.9211 - val_loss: 0.2529 - val_accuracy: 0.9026\n",
      "Epoch 6/20\n",
      "7767/7767 [==============================] - 3s 329us/sample - loss: 0.2001 - accuracy: 0.9240 - val_loss: 0.2585 - val_accuracy: 0.9035\n",
      "Epoch 7/20\n",
      "7767/7767 [==============================] - 3s 329us/sample - loss: 0.1929 - accuracy: 0.9243 - val_loss: 0.2701 - val_accuracy: 0.9010\n",
      "Epoch 8/20\n",
      "7767/7767 [==============================] - 3s 329us/sample - loss: 0.1804 - accuracy: 0.9302 - val_loss: 0.3330 - val_accuracy: 0.8757\n",
      "Epoch 9/20\n",
      "7767/7767 [==============================] - 3s 329us/sample - loss: 0.1771 - accuracy: 0.9316 - val_loss: 0.3084 - val_accuracy: 0.8953\n",
      "Epoch 10/20\n",
      "7767/7767 [==============================] - 3s 330us/sample - loss: 0.1692 - accuracy: 0.9346 - val_loss: 0.2827 - val_accuracy: 0.8985\n",
      "Epoch 11/20\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 0.1758 - accuracy: 0.9312 - val_loss: 0.2826 - val_accuracy: 0.8988\n",
      "Epoch 12/20\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 0.1673 - accuracy: 0.9355 - val_loss: 0.2772 - val_accuracy: 0.9016\n",
      "Epoch 13/20\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 0.1593 - accuracy: 0.9365 - val_loss: 0.2776 - val_accuracy: 0.8997\n",
      "Epoch 14/20\n",
      "7767/7767 [==============================] - 3s 333us/sample - loss: 0.1561 - accuracy: 0.9399 - val_loss: 0.2500 - val_accuracy: 0.9105\n",
      "Epoch 15/20\n",
      "7767/7767 [==============================] - 3s 332us/sample - loss: 0.1591 - accuracy: 0.9377 - val_loss: 0.2414 - val_accuracy: 0.9099\n",
      "Epoch 16/20\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.1615 - accuracy: 0.9382 - val_loss: 0.2970 - val_accuracy: 0.9001\n",
      "Epoch 17/20\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 0.1557 - accuracy: 0.9397 - val_loss: 0.2489 - val_accuracy: 0.9121\n",
      "Epoch 18/20\n",
      "7767/7767 [==============================] - 3s 330us/sample - loss: 0.1525 - accuracy: 0.9397 - val_loss: 0.2623 - val_accuracy: 0.9073\n",
      "Epoch 19/20\n",
      "7767/7767 [==============================] - 3s 344us/sample - loss: 0.1495 - accuracy: 0.9419 - val_loss: 0.2805 - val_accuracy: 0.9051\n",
      "Epoch 20/20\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.1513 - accuracy: 0.9410 - val_loss: 0.3194 - val_accuracy: 0.9039\n",
      "3162/3162 - 0s - loss: 0.3194 - accuracy: 0.9039\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223F23DF4C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223F23DF4C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-20_it-4\\assets\n",
      "Model: \"sequential_145\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_290 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_290 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_291 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_291 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_145 (Dropout)        (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_145 (Flatten)        (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_435 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_436 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_437 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4912 - accuracy: 0.0841\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/20\n",
      "7767/7767 [==============================] - 3s 402us/sample - loss: 0.7069 - accuracy: 0.7532 - val_loss: 0.3568 - val_accuracy: 0.8646\n",
      "Epoch 2/20\n",
      "7767/7767 [==============================] - 3s 331us/sample - loss: 0.2791 - accuracy: 0.8953 - val_loss: 0.3359 - val_accuracy: 0.8602\n",
      "Epoch 3/20\n",
      "7767/7767 [==============================] - 3s 335us/sample - loss: 0.2424 - accuracy: 0.9079 - val_loss: 0.3453 - val_accuracy: 0.8697\n",
      "Epoch 4/20\n",
      "7767/7767 [==============================] - 3s 330us/sample - loss: 0.2183 - accuracy: 0.9172 - val_loss: 0.3512 - val_accuracy: 0.8751\n",
      "Epoch 5/20\n",
      "7767/7767 [==============================] - 3s 329us/sample - loss: 0.2031 - accuracy: 0.9238 - val_loss: 0.3256 - val_accuracy: 0.8792\n",
      "Epoch 6/20\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 0.1954 - accuracy: 0.9260 - val_loss: 0.3247 - val_accuracy: 0.8884\n",
      "Epoch 7/20\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 0.1866 - accuracy: 0.9285 - val_loss: 0.2838 - val_accuracy: 0.8944\n",
      "Epoch 8/20\n",
      "7767/7767 [==============================] - 3s 329us/sample - loss: 0.1726 - accuracy: 0.9331 - val_loss: 0.3187 - val_accuracy: 0.8925\n",
      "Epoch 9/20\n",
      "7767/7767 [==============================] - 3s 330us/sample - loss: 0.1792 - accuracy: 0.9311 - val_loss: 0.4459 - val_accuracy: 0.8729\n",
      "Epoch 10/20\n",
      "7767/7767 [==============================] - 3s 329us/sample - loss: 0.1682 - accuracy: 0.9358 - val_loss: 0.3488 - val_accuracy: 0.8839\n",
      "Epoch 11/20\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.1633 - accuracy: 0.9367 - val_loss: 0.2852 - val_accuracy: 0.8966\n",
      "Epoch 12/20\n",
      "7767/7767 [==============================] - 3s 329us/sample - loss: 0.1591 - accuracy: 0.9399 - val_loss: 0.3366 - val_accuracy: 0.8896\n",
      "Epoch 13/20\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 0.1611 - accuracy: 0.9377 - val_loss: 0.3257 - val_accuracy: 0.8925\n",
      "Epoch 14/20\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 0.1559 - accuracy: 0.9388 - val_loss: 0.2743 - val_accuracy: 0.9023\n",
      "Epoch 15/20\n",
      "7767/7767 [==============================] - 3s 329us/sample - loss: 0.1520 - accuracy: 0.9394 - val_loss: 0.2854 - val_accuracy: 0.9016\n",
      "Epoch 16/20\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 0.1470 - accuracy: 0.9428 - val_loss: 0.3101 - val_accuracy: 0.9020\n",
      "Epoch 17/20\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 0.1439 - accuracy: 0.9432 - val_loss: 0.2806 - val_accuracy: 0.9048\n",
      "Epoch 18/20\n",
      "7767/7767 [==============================] - 3s 329us/sample - loss: 0.1401 - accuracy: 0.9463 - val_loss: 0.4070 - val_accuracy: 0.8795\n",
      "Epoch 19/20\n",
      "7767/7767 [==============================] - 3s 329us/sample - loss: 0.1366 - accuracy: 0.9457 - val_loss: 0.2558 - val_accuracy: 0.9105\n",
      "Epoch 20/20\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 0.1450 - accuracy: 0.9428 - val_loss: 0.3091 - val_accuracy: 0.8969\n",
      "3162/3162 - 0s - loss: 0.3091 - accuracy: 0.8969\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002237E8343A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002237E8343A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-20_it-5\\assets\n",
      "Model: \"sequential_146\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_292 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_292 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_293 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_293 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_146 (Dropout)        (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_146 (Flatten)        (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_438 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_439 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_440 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4876 - accuracy: 0.1569\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/20\n",
      "7767/7767 [==============================] - 3s 406us/sample - loss: 1.4616 - accuracy: 0.5079 - val_loss: 1.2288 - val_accuracy: 0.5699\n",
      "Epoch 2/20\n",
      "7767/7767 [==============================] - 3s 330us/sample - loss: 1.1774 - accuracy: 0.5704 - val_loss: 1.1458 - val_accuracy: 0.5727\n",
      "Epoch 3/20\n",
      "7767/7767 [==============================] - 3s 331us/sample - loss: 1.1355 - accuracy: 0.5782 - val_loss: 1.2327 - val_accuracy: 0.5364\n",
      "Epoch 4/20\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 1.1170 - accuracy: 0.5810 - val_loss: 1.2095 - val_accuracy: 0.5572\n",
      "Epoch 5/20\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 1.1023 - accuracy: 0.5814 - val_loss: 1.1761 - val_accuracy: 0.5519\n",
      "Epoch 6/20\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 1.0936 - accuracy: 0.5845 - val_loss: 1.1224 - val_accuracy: 0.5794\n",
      "Epoch 7/20\n",
      "7767/7767 [==============================] - 3s 329us/sample - loss: 1.0824 - accuracy: 0.5886 - val_loss: 1.1924 - val_accuracy: 0.5547\n",
      "Epoch 8/20\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 1.0671 - accuracy: 0.5920 - val_loss: 1.1123 - val_accuracy: 0.5775\n",
      "Epoch 9/20\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 1.0616 - accuracy: 0.5922 - val_loss: 1.1238 - val_accuracy: 0.5759\n",
      "Epoch 10/20\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 1.0539 - accuracy: 0.5933 - val_loss: 1.1812 - val_accuracy: 0.5633\n",
      "Epoch 11/20\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 1.0571 - accuracy: 0.5928 - val_loss: 1.1592 - val_accuracy: 0.5667\n",
      "Epoch 12/20\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 1.0550 - accuracy: 0.5938 - val_loss: 1.1653 - val_accuracy: 0.5667\n",
      "Epoch 13/20\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 1.0593 - accuracy: 0.5926 - val_loss: 1.0931 - val_accuracy: 0.5803\n",
      "Epoch 14/20\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 1.0402 - accuracy: 0.5946 - val_loss: 1.1184 - val_accuracy: 0.5762\n",
      "Epoch 15/20\n",
      "7767/7767 [==============================] - 3s 329us/sample - loss: 1.0422 - accuracy: 0.5952 - val_loss: 1.1146 - val_accuracy: 0.5775\n",
      "Epoch 16/20\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 1.0397 - accuracy: 0.5961 - val_loss: 1.1163 - val_accuracy: 0.5794\n",
      "Epoch 17/20\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 1.0360 - accuracy: 0.5951 - val_loss: 1.1259 - val_accuracy: 0.5743\n",
      "Epoch 18/20\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 1.0363 - accuracy: 0.5952 - val_loss: 1.1501 - val_accuracy: 0.5674\n",
      "Epoch 19/20\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 1.0357 - accuracy: 0.5952 - val_loss: 1.1172 - val_accuracy: 0.5775\n",
      "Epoch 20/20\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 1.0336 - accuracy: 0.5951 - val_loss: 1.1371 - val_accuracy: 0.5746\n",
      "3162/3162 - 0s - loss: 1.1371 - accuracy: 0.5746\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002237E8343A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002237E8343A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-20_it-6\\assets\n",
      "Model: \"sequential_147\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_294 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_294 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_295 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_295 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_147 (Dropout)        (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_147 (Flatten)        (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_441 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_442 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_443 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4782 - accuracy: 0.1818\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/20\n",
      "7767/7767 [==============================] - 3s 397us/sample - loss: 1.1953 - accuracy: 0.6286 - val_loss: 0.8356 - val_accuracy: 0.7239\n",
      "Epoch 2/20\n",
      "7767/7767 [==============================] - 3s 332us/sample - loss: 0.7585 - accuracy: 0.7493 - val_loss: 0.7435 - val_accuracy: 0.7464\n",
      "Epoch 3/20\n",
      "7767/7767 [==============================] - 3s 333us/sample - loss: 0.6958 - accuracy: 0.7569 - val_loss: 0.7514 - val_accuracy: 0.7381\n",
      "Epoch 4/20\n",
      "7767/7767 [==============================] - 3s 341us/sample - loss: 0.6735 - accuracy: 0.7601 - val_loss: 0.7308 - val_accuracy: 0.7359\n",
      "Epoch 5/20\n",
      "7767/7767 [==============================] - 3s 334us/sample - loss: 0.6566 - accuracy: 0.7621 - val_loss: 0.7203 - val_accuracy: 0.7366\n",
      "Epoch 6/20\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.6400 - accuracy: 0.7654 - val_loss: 0.6972 - val_accuracy: 0.7432\n",
      "Epoch 7/20\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.6399 - accuracy: 0.7625 - val_loss: 0.7011 - val_accuracy: 0.7470\n",
      "Epoch 8/20\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.6317 - accuracy: 0.7645 - val_loss: 0.7323 - val_accuracy: 0.7347\n",
      "Epoch 9/20\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 0.6307 - accuracy: 0.7661 - val_loss: 0.7555 - val_accuracy: 0.7302\n",
      "Epoch 10/20\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.6244 - accuracy: 0.7652 - val_loss: 0.6942 - val_accuracy: 0.7435\n",
      "Epoch 11/20\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.6224 - accuracy: 0.7643 - val_loss: 0.7449 - val_accuracy: 0.7255\n",
      "Epoch 12/20\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.6193 - accuracy: 0.7657 - val_loss: 0.6969 - val_accuracy: 0.7372\n",
      "Epoch 13/20\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.6205 - accuracy: 0.7653 - val_loss: 0.7496 - val_accuracy: 0.7299\n",
      "Epoch 14/20\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 0.6107 - accuracy: 0.7659 - val_loss: 0.7776 - val_accuracy: 0.7268\n",
      "Epoch 15/20\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.6126 - accuracy: 0.7668 - val_loss: 0.7055 - val_accuracy: 0.7410\n",
      "Epoch 16/20\n",
      "7767/7767 [==============================] - 3s 325us/sample - loss: 0.6120 - accuracy: 0.7666 - val_loss: 0.6998 - val_accuracy: 0.7435\n",
      "Epoch 17/20\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.6112 - accuracy: 0.7671 - val_loss: 0.7265 - val_accuracy: 0.7312\n",
      "Epoch 18/20\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.6088 - accuracy: 0.7664 - val_loss: 0.7296 - val_accuracy: 0.7375\n",
      "Epoch 19/20\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.6061 - accuracy: 0.7683 - val_loss: 0.7074 - val_accuracy: 0.7416\n",
      "Epoch 20/20\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.6047 - accuracy: 0.7675 - val_loss: 0.7363 - val_accuracy: 0.7369\n",
      "3162/3162 - 0s - loss: 0.7363 - accuracy: 0.7369\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223C8206DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223C8206DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-20_it-7\\assets\n",
      "Model: \"sequential_148\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_296 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_296 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_297 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_297 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_148 (Dropout)        (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_148 (Flatten)        (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_444 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_445 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_446 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4737 - accuracy: 0.1762\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/20\n",
      "7767/7767 [==============================] - 3s 401us/sample - loss: 0.7236 - accuracy: 0.7355 - val_loss: 0.3760 - val_accuracy: 0.8621\n",
      "Epoch 2/20\n",
      "7767/7767 [==============================] - 3s 329us/sample - loss: 0.2923 - accuracy: 0.8930 - val_loss: 0.3256 - val_accuracy: 0.8861\n",
      "Epoch 3/20\n",
      "7767/7767 [==============================] - 3s 329us/sample - loss: 0.2347 - accuracy: 0.9185 - val_loss: 0.2728 - val_accuracy: 0.9073\n",
      "Epoch 4/20\n",
      "7767/7767 [==============================] - 3s 336us/sample - loss: 0.1985 - accuracy: 0.9311 - val_loss: 0.4667 - val_accuracy: 0.8346\n",
      "Epoch 5/20\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 0.1923 - accuracy: 0.9305 - val_loss: 0.3085 - val_accuracy: 0.8874\n",
      "Epoch 6/20\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.1714 - accuracy: 0.9372 - val_loss: 0.2433 - val_accuracy: 0.9118\n",
      "Epoch 7/20\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.1644 - accuracy: 0.9417 - val_loss: 0.2599 - val_accuracy: 0.9089\n",
      "Epoch 8/20\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.1570 - accuracy: 0.9436 - val_loss: 0.2475 - val_accuracy: 0.9114\n",
      "Epoch 9/20\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.1511 - accuracy: 0.9443 - val_loss: 0.2436 - val_accuracy: 0.9130\n",
      "Epoch 10/20\n",
      "7767/7767 [==============================] - 3s 325us/sample - loss: 0.1495 - accuracy: 0.9440 - val_loss: 0.2259 - val_accuracy: 0.9181\n",
      "Epoch 11/20\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.1372 - accuracy: 0.9495 - val_loss: 0.3057 - val_accuracy: 0.9048\n",
      "Epoch 12/20\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 0.1354 - accuracy: 0.9506 - val_loss: 0.2571 - val_accuracy: 0.9130\n",
      "Epoch 13/20\n",
      "7767/7767 [==============================] - 3s 329us/sample - loss: 0.1404 - accuracy: 0.9486 - val_loss: 0.3049 - val_accuracy: 0.9083\n",
      "Epoch 14/20\n",
      "7767/7767 [==============================] - 3s 329us/sample - loss: 0.1306 - accuracy: 0.9521 - val_loss: 0.2390 - val_accuracy: 0.9190\n",
      "Epoch 15/20\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 0.1271 - accuracy: 0.9516 - val_loss: 0.2408 - val_accuracy: 0.9235\n",
      "Epoch 16/20\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.1292 - accuracy: 0.9516 - val_loss: 0.2878 - val_accuracy: 0.9111\n",
      "Epoch 17/20\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 0.1251 - accuracy: 0.9535 - val_loss: 0.2604 - val_accuracy: 0.9181\n",
      "Epoch 18/20\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.1223 - accuracy: 0.9521 - val_loss: 0.4199 - val_accuracy: 0.8944\n",
      "Epoch 19/20\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.1203 - accuracy: 0.9535 - val_loss: 0.2643 - val_accuracy: 0.9184\n",
      "Epoch 20/20\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.1127 - accuracy: 0.9571 - val_loss: 0.2408 - val_accuracy: 0.9197\n",
      "3162/3162 - 0s - loss: 0.2408 - accuracy: 0.9197\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223C83160D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223C83160D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-20_it-8\\assets\n",
      "Model: \"sequential_149\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_298 (Conv1D)          (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_298 (MaxPoolin (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_299 (Conv1D)          (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_299 (MaxPoolin (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_149 (Dropout)        (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_149 (Flatten)        (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_447 (Dense)            (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_448 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_449 (Dense)            (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4775 - accuracy: 0.0041\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/20\n",
      "7767/7767 [==============================] - 3s 404us/sample - loss: 0.6636 - accuracy: 0.7689 - val_loss: 0.3288 - val_accuracy: 0.8896\n",
      "Epoch 2/20\n",
      "7767/7767 [==============================] - 3s 339us/sample - loss: 0.2799 - accuracy: 0.9002 - val_loss: 0.2675 - val_accuracy: 0.9035\n",
      "Epoch 3/20\n",
      "7767/7767 [==============================] - 3s 337us/sample - loss: 0.2231 - accuracy: 0.9215 - val_loss: 0.2702 - val_accuracy: 0.9051\n",
      "Epoch 4/20\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.1978 - accuracy: 0.9312 - val_loss: 0.2346 - val_accuracy: 0.9178\n",
      "Epoch 5/20\n",
      "7767/7767 [==============================] - 3s 329us/sample - loss: 0.1806 - accuracy: 0.9363 - val_loss: 0.2450 - val_accuracy: 0.9118\n",
      "Epoch 6/20\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.1740 - accuracy: 0.9361 - val_loss: 0.2769 - val_accuracy: 0.9086\n",
      "Epoch 7/20\n",
      "7767/7767 [==============================] - 3s 331us/sample - loss: 0.1639 - accuracy: 0.9421 - val_loss: 0.2654 - val_accuracy: 0.9086\n",
      "Epoch 8/20\n",
      "7767/7767 [==============================] - 3s 350us/sample - loss: 0.1586 - accuracy: 0.9415 - val_loss: 0.2574 - val_accuracy: 0.9127\n",
      "Epoch 9/20\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 0.1525 - accuracy: 0.9452 - val_loss: 0.2527 - val_accuracy: 0.9146\n",
      "Epoch 10/20\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.1558 - accuracy: 0.9418 - val_loss: 0.2306 - val_accuracy: 0.9241\n",
      "Epoch 11/20\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.1426 - accuracy: 0.9477 - val_loss: 0.2422 - val_accuracy: 0.9197\n",
      "Epoch 12/20\n",
      "7767/7767 [==============================] - 3s 325us/sample - loss: 0.1297 - accuracy: 0.9504 - val_loss: 0.2511 - val_accuracy: 0.9206\n",
      "Epoch 13/20\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.1326 - accuracy: 0.9509 - val_loss: 0.2685 - val_accuracy: 0.9105\n",
      "Epoch 14/20\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.1370 - accuracy: 0.9476 - val_loss: 0.2656 - val_accuracy: 0.9143\n",
      "Epoch 15/20\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.1284 - accuracy: 0.9515 - val_loss: 0.2778 - val_accuracy: 0.9137\n",
      "Epoch 16/20\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.1254 - accuracy: 0.9520 - val_loss: 0.2680 - val_accuracy: 0.9118\n",
      "Epoch 17/20\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.1179 - accuracy: 0.9546 - val_loss: 0.3354 - val_accuracy: 0.9067\n",
      "Epoch 18/20\n",
      "7767/7767 [==============================] - 3s 326us/sample - loss: 0.1227 - accuracy: 0.9543 - val_loss: 0.3895 - val_accuracy: 0.8868\n",
      "Epoch 19/20\n",
      "7767/7767 [==============================] - 3s 327us/sample - loss: 0.1193 - accuracy: 0.9542 - val_loss: 0.2856 - val_accuracy: 0.9194\n",
      "Epoch 20/20\n",
      "7767/7767 [==============================] - 3s 328us/sample - loss: 0.1197 - accuracy: 0.9526 - val_loss: 0.3361 - val_accuracy: 0.9130\n",
      "3162/3162 - 0s - loss: 0.3361 - accuracy: 0.9130\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223C8574288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x00000223C8574288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-20_it-9\\assets\n"
     ]
    }
   ],
   "source": [
    "epoch_data = runner.test_param(epochs=[5,10,15,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "runner.plot_results(epoch_data, 'epochs')\n",
    "plt.savefig('plots/epoch-5-10-15-20.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
