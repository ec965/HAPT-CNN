{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#activity labels as defined in activity_labels.txt\n",
    "activity_labels = ['WALKING', 'WALKING_UPSTAIRS', 'WALKING_DOWNSTAIRS', 'SITTING', 'STANDING', 'LAYING', 'STAND_TO_SIT', 'SIT_TO_STAND', 'SIT_TO_LIE', 'LIE_TO_SIT', 'STAND_TO_LIE', 'LIE_TO_STAND']\n",
    "#activity_labels = {k:v for k,v in enumerate(activity_labels, start=1)}\n",
    "#print(activity_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshaping data...\n",
      "adjusting labels...\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "def load_data(path):\n",
    "    data = pd.read_csv(path, header=None, delim_whitespace=True)\n",
    "    return data.values\n",
    "\n",
    "def load_set(path, x, y):\n",
    "    data = load_data(path+x)\n",
    "    labels = load_data(path+y)\n",
    "    return data, labels\n",
    "\n",
    "#reduce the labels by 1 to match with the activity_labels and also to start labels at 0 to 11 instead of from 1 to 12\n",
    "def adjust_labels (labels):\n",
    "    for i in range(len(labels)-1):\n",
    "        labels[i][0] -= 1\n",
    "    return labels\n",
    "\n",
    "train_data, train_labels = load_set('HAPT Data Set/Train/', 'X_train.txt', 'y_train.txt')\n",
    "test_data, test_labels = load_set('HAPT Data Set/Test/', 'X_test.txt', 'y_test.txt')\n",
    "\n",
    "print('reshaping data...')\n",
    "#reshape the data to add a features dimension (features = 1)\n",
    "#https://stackoverflow.com/questions/43396572/dimension-of-shape-in-conv1d\n",
    "train_data = np.expand_dims(train_data, axis=2)\n",
    "test_data = np.expand_dims(test_data, axis=2)\n",
    "\n",
    "print('adjusting labels...')\n",
    "train_labels = adjust_labels(train_labels);\n",
    "test_labels = adjust_labels(test_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get time of epochs to record training time\n",
    "#https://stackoverflow.com/questions/43178668/record-the-computation-time-for-each-epoch-in-keras-during-model-fit\n",
    "class TimeHistory(callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out n number (pred_range) of predicted values and compare them with test labels\n",
    "def predict(pred_range, pred_outs, test_labels):\n",
    "    #test if the label matches the prediction\n",
    "    false_pred = 0\n",
    "    true_pred = 0\n",
    "    #look at predictions for the first 25 values\n",
    "    for i in range(pred_range):\n",
    "        if not (0 <= pred_outs[i] or pred_outs[i] <= 11):\n",
    "            print('prediction out of bounds')\n",
    "            break\n",
    "\n",
    "        print(f'Test label: {activity_labels[test_labels[i][0]]}')\n",
    "        print(f'Predicted label:{activity_labels[pred_outs[i]]}')\n",
    "\n",
    "        if pred_outs[i]==test_labels[i][0]:\n",
    "            print('true\\n')\n",
    "            true_pred += 1\n",
    "        else:\n",
    "            print('false\\n')\n",
    "            false_pred += 1\n",
    "    print(f'False predictions:{false_pred}')\n",
    "    print(f'True predictions:{true_pred}')\n",
    "    print(f'Prediction accuraccy for first 25 values: {true_pred/pred_range}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(test_data, test_labels, train_data, train_labels, filters, kernel_size, dropout, epochs, it='', predict=True):\n",
    "    save_path = f'filters-{filters}_kernel_size-{kernel_size}_dropout-{dropout}_epochs-{epochs}_it-{it}'\n",
    "    saved_model_path = f'saved_models\\\\{save_path}'\n",
    "    checkpoint_path = f'checkpoints\\\\{save_path}.ckpt'\n",
    "    training_time=-1\n",
    "    \n",
    "    current_directory = os.path.abspath(os.getcwd())\n",
    "    \n",
    "    if os.path.exists(os.path.join(current_directory,saved_model_path)) :\n",
    "        print(f'found saved model, loading from: {saved_model_path}')\n",
    "        model = models.load_model(saved_model_path)\n",
    "        test_loss,test_acc = model.evaluate( test_data, test_labels, verbose=2)\n",
    "    #elif os.path.exists(os.path.join(current_directory,checkpoint_path+'.index')) :\n",
    "     #   print(f'found checkpoint for model, loading from :{checkpoint_path}')\n",
    "        \n",
    "      #  model.load_weights(checkpoint_path)\n",
    "       # test_loss,test_acc = model.evaluate( test_data, test_labels, verbose=2)\n",
    "    else:\n",
    "        #input shape\n",
    "        timesteps = train_data.shape[1] #561 timesteps\n",
    "        features = train_data.shape[2] #1 feature\n",
    "\n",
    "        #model\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Conv1D(filters=filters, kernel_size=kernel_size, strides=1, activation='relu', input_shape=(timesteps,features)))\n",
    "        model.add(layers.MaxPooling1D(pool_size=2))\n",
    "        model.add(layers.Conv1D(filters=filters, kernel_size=kernel_size, strides=1, activation='relu'))\n",
    "        model.add(layers.MaxPooling1D(pool_size=2))\n",
    "        model.add(layers.Dropout(dropout))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(64, activation='relu'))\n",
    "        model.add(layers.Dense(32, activation='relu'))\n",
    "        model.add(layers.Dense(12, activation='relu'))\n",
    "        model.summary()\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(optimizer='adam',\n",
    "                 loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                 metrics=['accuracy'])\n",
    "        #evaluate model\n",
    "        test_loss,test_acc = model.evaluate(test_data, test_labels, verbose=2)\n",
    "\n",
    "        if predict:\n",
    "            #predict\n",
    "            pred_outs = model.predict_classes(test_data)\n",
    "            #display predictions\n",
    "            predict(10, pred_outs, test_labels)\n",
    "\n",
    "        #train the model\n",
    "        #set up timing callback\n",
    "        time_callback = TimeHistory()\n",
    "        #setup checkpoint callback\n",
    "        cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                        save_weights_only=True,\n",
    "                                                        verbose=1)\n",
    "        \n",
    "        if os.path.exists(os.path.join(current_directory,checkpoint_path+'.index')) :\n",
    "            print(f'found checkpoint for model, loading from :{checkpoint_path}')\n",
    "            model.load_weights(checkpoint_path)\n",
    "\n",
    "        model.fit(train_data, \n",
    "                  train_labels, \n",
    "                  epochs=epochs, \n",
    "                  validation_data=(test_data, test_labels),\n",
    "                callbacks=[time_callback, cp_callback])\n",
    "\n",
    "        test_loss,test_acc = model.evaluate( test_data, test_labels, verbose=2)\n",
    "\n",
    "        training_time = sum(time_callback.times)\n",
    "\n",
    "        model.save(saved_model_path)\n",
    "    \n",
    "    return test_loss, test_acc, training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_unit_string(time):\n",
    "    return f\"Total training time: {math.floor(time/1)}s {math.floor(time%1 * 1000)}ms {math.ceil(time%(1/1000)*1000)}us\"\n",
    "\n",
    "class RunTests: \n",
    "    n_tests = 10\n",
    "    d_epochs = 10\n",
    "    d_filters = 64\n",
    "    d_kernel_size=3\n",
    "    d_dropout=0.5\n",
    "    \n",
    "    def test_param(self, filters=d_filters, kernel_size=d_kernel_size, dropout=d_dropout, epochs=d_epochs):\n",
    "        if isinstance(filters,list):\n",
    "            data = filters\n",
    "            data_type = 'filters'\n",
    "        elif isinstance(kernel_size,list):\n",
    "            data = kernel_size\n",
    "            data_type = 'kernel_size'\n",
    "        elif isinstance(dropout,list):\n",
    "            data = dropout\n",
    "            data_type = 'dropout'\n",
    "        elif isinstance(epochs,list):\n",
    "            data = epochs\n",
    "            data_type = 'epochs'\n",
    "        else:\n",
    "            print('no data type selected, running default...')\n",
    "            data = [1]\n",
    "            data_type = 'default'\n",
    "        \n",
    "        model_test_data = []\n",
    "        for index, item in enumerate(data):\n",
    "            model_test_data.append([])\n",
    "            for i in range(0,self.n_tests):\n",
    "                if data_type == 'filters':\n",
    "                    loss, acc, time = run_model(test_data, test_labels, train_data, train_labels, predict=False,\n",
    "                                                kernel_size=kernel_size, \n",
    "                                                filters=item, \n",
    "                                                dropout=dropout,\n",
    "                                                epochs=epochs,\n",
    "                                                it=i)\n",
    "                elif data_type == 'kernel_size':\n",
    "                    loss, acc, time = run_model(test_data, test_labels, train_data, train_labels, predict=False,\n",
    "                                                kernel_size=item, \n",
    "                                                filters=filters, \n",
    "                                                dropout=dropout,  \n",
    "                                                epochs=epochs,\n",
    "                                                it=i)\n",
    "                elif data_type == 'dropout':\n",
    "                    loss, acc, time = run_model(test_data, test_labels, train_data, train_labels, predict=False,\n",
    "                                                kernel_size=kernel_size, \n",
    "                                                filters=filters, \n",
    "                                                dropout=item,  \n",
    "                                                epochs=epochs,\n",
    "                                                it=i)\n",
    "                elif data_type == 'epochs':\n",
    "                    loss, acc, time = run_model(test_data, test_labels, train_data, train_labels, predict=False,\n",
    "                                                kernel_size=kernel_size, \n",
    "                                                filters=filters, \n",
    "                                                dropout=dropout,  \n",
    "                                                epochs=item,\n",
    "                                                it=i)\n",
    "                else:\n",
    "                    loss, acc, time = run_model(test_data, test_labels, train_data, train_labels, predict=False,\n",
    "                                                kernel_size=kernel_size, \n",
    "                                                filters=filters, \n",
    "                                                dropout=dropout,  \n",
    "                                                epochs=epochs,\n",
    "                                                it=i)\n",
    "                test_output = {'loss': loss, 'acc': acc, 'time': time, 'test parameter': item}\n",
    "                model_test_data[index].append(test_output)\n",
    "        return model_test_data\n",
    "\n",
    "    #data is a two-dimensional list\n",
    "    def print_results(self,data, data_name):\n",
    "        print(f\"{data_name} test data:\")\n",
    "        for test in data:\n",
    "            for i in range(0,self.n_tests):\n",
    "                print(f\"{data_name}: {test[i].get('test parameter')}\")\n",
    "                print(f\"\\tloss: {test[i].get('loss')}\")\n",
    "                print(f\"\\taccuracy: {test[i].get('acc')}\")\n",
    "            print(\"\\n\")\n",
    "    \n",
    "    def plot_results(self, data, data_name):\n",
    "        loss=[]\n",
    "        acc=[]\n",
    "        param=[]\n",
    "        for index, test in enumerate(data):\n",
    "            param.append(test[0].get('test parameter'))\n",
    "            loss.append([])\n",
    "            acc.append([])\n",
    "            for i in range(0,self.n_tests):\n",
    "                loss[index].append(test[i].get('loss'))\n",
    "                acc[index].append(test[i].get('acc'))\n",
    "        \n",
    "        fig, axs = plt.subplots(2)\n",
    "        axs[0].set_title(f'{data_name} loss')\n",
    "        axs[0].set(xlabel=data_name, ylabel='Loss')\n",
    "        axs[0].boxplot(loss)\n",
    "        axs[0].set_xticklabels(param)\n",
    "        \n",
    "        axs[1].set_title(f'{data_name} accuracy')\n",
    "        axs[1].set(xlabel=data_name, ylabel='Accuracy')\n",
    "        axs[1].boxplot(acc)\n",
    "        axs[1].set_xticklabels(param)\n",
    "        \n",
    "        fig.subplots_adjust(hspace=0.8)\n",
    "        \n",
    "        plt.show\n",
    "        \n",
    "runner = RunTests() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found saved model, loading from: saved_models\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-0\n",
      "3162/3162 - 0s - loss: 0.2155 - accuracy: 0.9244\n",
      "found saved model, loading from: saved_models\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-1\n",
      "3162/3162 - 1s - loss: 0.3336 - accuracy: 0.8861\n",
      "found saved model, loading from: saved_models\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-2\n",
      "3162/3162 - 0s - loss: 1.0572 - accuracy: 0.5765\n",
      "found saved model, loading from: saved_models\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-3\n",
      "3162/3162 - 0s - loss: 0.6840 - accuracy: 0.7495\n",
      "found saved model, loading from: saved_models\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-4\n",
      "3162/3162 - 0s - loss: 1.0180 - accuracy: 0.6078\n",
      "found saved model, loading from: saved_models\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-5\n",
      "3162/3162 - 0s - loss: 0.6288 - accuracy: 0.7846\n",
      "found saved model, loading from: saved_models\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-6\n",
      "3162/3162 - 0s - loss: 0.6670 - accuracy: 0.8893\n",
      "found saved model, loading from: saved_models\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-7\n",
      "3162/3162 - 1s - loss: 0.6989 - accuracy: 0.7407\n",
      "found saved model, loading from: saved_models\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-8\n",
      "3162/3162 - 0s - loss: 1.3816 - accuracy: 0.4870\n",
      "found saved model, loading from: saved_models\\filters-32_kernel_size-3_dropout-0.5_epochs-10_it-9\n",
      "3162/3162 - 0s - loss: 0.2525 - accuracy: 0.9067\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-0\n",
      "3162/3162 - 1s - loss: 0.6135 - accuracy: 0.9247\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-1\n",
      "3162/3162 - 1s - loss: 0.5921 - accuracy: 0.7875\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-2\n",
      "3162/3162 - 1s - loss: 0.2480 - accuracy: 0.9187\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-3\n",
      "3162/3162 - 1s - loss: 0.9100 - accuracy: 0.6610\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-4\n",
      "3162/3162 - 1s - loss: 0.6608 - accuracy: 0.8877\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-5\n",
      "3162/3162 - 1s - loss: 0.7964 - accuracy: 0.7239\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-6\n",
      "3162/3162 - 1s - loss: 0.6462 - accuracy: 0.7612\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-7\n",
      "3162/3162 - 1s - loss: 1.0570 - accuracy: 0.7375\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-8\n",
      "3162/3162 - 1s - loss: 1.0262 - accuracy: 0.6195\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0.5_epochs-10_it-9\n",
      "3162/3162 - 1s - loss: 0.2868 - accuracy: 0.9130\n",
      "found saved model, loading from: saved_models\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-0\n",
      "3162/3162 - 1s - loss: 0.6770 - accuracy: 0.7619\n",
      "found saved model, loading from: saved_models\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-1\n",
      "3162/3162 - 1s - loss: 0.6732 - accuracy: 0.7508\n",
      "found saved model, loading from: saved_models\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-2\n",
      "3162/3162 - 1s - loss: 0.6245 - accuracy: 0.7682\n",
      "found saved model, loading from: saved_models\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-3\n",
      "3162/3162 - 1s - loss: 0.6810 - accuracy: 0.8899\n",
      "found saved model, loading from: saved_models\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-4\n",
      "3162/3162 - 1s - loss: 0.1867 - accuracy: 0.9399\n",
      "found saved model, loading from: saved_models\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-5\n",
      "3162/3162 - 1s - loss: 0.2326 - accuracy: 0.9326\n",
      "found saved model, loading from: saved_models\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-6\n",
      "3162/3162 - 1s - loss: 0.2673 - accuracy: 0.9175\n",
      "found saved model, loading from: saved_models\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-7\n",
      "3162/3162 - 1s - loss: 1.8709 - accuracy: 0.4307\n",
      "found saved model, loading from: saved_models\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-8\n",
      "3162/3162 - 1s - loss: 0.9894 - accuracy: 0.7685\n",
      "found saved model, loading from: saved_models\\filters-128_kernel_size-3_dropout-0.5_epochs-10_it-9\n",
      "3162/3162 - 1s - loss: 0.3629 - accuracy: 0.9010\n"
     ]
    }
   ],
   "source": [
    "filters_data = runner.test_param(filters=[32, 64, 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#runner.print_results(filters_data, 'filters')\n",
    "runner.plot_results(filters_data, 'filters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0_epochs-10_it-0\n",
      "3162/3162 - 1s - loss: 0.3003 - accuracy: 0.9010\n",
      "found saved model, loading from: saved_models\\filters-64_kernel_size-3_dropout-0_epochs-10_it-1\n",
      "3162/3162 - 1s - loss: 0.6750 - accuracy: 0.7634\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4862 - accuracy: 0.1569\n",
      "found checkpoint for model, loading from :checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-2.ckpt\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7584/7767 [============================>.] - ETA: 0s - loss: 0.5691 - accuracy: 0.7728\n",
      "Epoch 00001: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 3s 428us/sample - loss: 0.5734 - accuracy: 0.7710 - val_loss: 0.7192 - val_accuracy: 0.7315\n",
      "Epoch 2/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.5718 - accuracy: 0.7711\n",
      "Epoch 00002: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 3s 353us/sample - loss: 0.5716 - accuracy: 0.7712 - val_loss: 0.7119 - val_accuracy: 0.7359\n",
      "Epoch 3/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 0.5728 - accuracy: 0.7697\n",
      "Epoch 00003: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 3s 363us/sample - loss: 0.5735 - accuracy: 0.7694 - val_loss: 0.7261 - val_accuracy: 0.7318\n",
      "Epoch 4/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 0.5674 - accuracy: 0.7726\n",
      "Epoch 00004: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 3s 343us/sample - loss: 0.5673 - accuracy: 0.7726 - val_loss: 0.8418 - val_accuracy: 0.7103\n",
      "Epoch 5/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.5692 - accuracy: 0.7733\n",
      "Epoch 00005: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 3s 363us/sample - loss: 0.5704 - accuracy: 0.7728 - val_loss: 0.7291 - val_accuracy: 0.7255\n",
      "Epoch 6/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 0.5660 - accuracy: 0.7731\n",
      "Epoch 00006: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 3s 390us/sample - loss: 0.5654 - accuracy: 0.7735 - val_loss: 0.7402 - val_accuracy: 0.7359\n",
      "Epoch 7/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.5740 - accuracy: 0.7719\n",
      "Epoch 00007: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 3s 392us/sample - loss: 0.5735 - accuracy: 0.7721 - val_loss: 0.7968 - val_accuracy: 0.7214\n",
      "Epoch 8/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 0.5629 - accuracy: 0.7738\n",
      "Epoch 00008: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 3s 433us/sample - loss: 0.5631 - accuracy: 0.7737 - val_loss: 0.7781 - val_accuracy: 0.7290\n",
      "Epoch 9/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.5639 - accuracy: 0.7742\n",
      "Epoch 00009: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 3s 365us/sample - loss: 0.5628 - accuracy: 0.7747 - val_loss: 0.7335 - val_accuracy: 0.7353\n",
      "Epoch 10/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.5581 - accuracy: 0.7756\n",
      "Epoch 00010: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-2.ckpt\n",
      "7767/7767 [==============================] - 3s 351us/sample - loss: 0.5594 - accuracy: 0.7751 - val_loss: 0.7303 - val_accuracy: 0.7375\n",
      "3162/3162 - 0s - loss: 0.7303 - accuracy: 0.7375\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002237EAA3798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002237EAA3798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From C:\\Users\\enoch\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0_epochs-10_it-2\\assets\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4650 - accuracy: 0.0674\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.9760 - accuracy: 0.6962\n",
      "Epoch 00001: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-3.ckpt\n",
      "7767/7767 [==============================] - 3s 412us/sample - loss: 0.9743 - accuracy: 0.6963 - val_loss: 0.7046 - val_accuracy: 0.7546\n",
      "Epoch 2/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.6397 - accuracy: 0.7788\n",
      "Epoch 00002: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-3.ckpt\n",
      "7767/7767 [==============================] - 3s 353us/sample - loss: 0.6385 - accuracy: 0.7791 - val_loss: 0.7368 - val_accuracy: 0.7404\n",
      "Epoch 3/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.5963 - accuracy: 0.7832\n",
      "Epoch 00003: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-3.ckpt\n",
      "7767/7767 [==============================] - 3s 356us/sample - loss: 0.5950 - accuracy: 0.7838 - val_loss: 0.6550 - val_accuracy: 0.7584\n",
      "Epoch 4/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.5859 - accuracy: 0.7820\n",
      "Epoch 00004: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-3.ckpt\n",
      "7767/7767 [==============================] - 3s 360us/sample - loss: 0.5817 - accuracy: 0.7836 - val_loss: 0.6717 - val_accuracy: 0.7524\n",
      "Epoch 5/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.5696 - accuracy: 0.7840\n",
      "Epoch 00005: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-3.ckpt\n",
      "7767/7767 [==============================] - 3s 355us/sample - loss: 0.5698 - accuracy: 0.7838 - val_loss: 0.6591 - val_accuracy: 0.7584\n",
      "Epoch 6/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.5610 - accuracy: 0.7846\n",
      "Epoch 00006: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-3.ckpt\n",
      "7767/7767 [==============================] - 3s 352us/sample - loss: 0.5612 - accuracy: 0.7846 - val_loss: 0.6603 - val_accuracy: 0.7622\n",
      "Epoch 7/10\n",
      "7584/7767 [============================>.] - ETA: 0s - loss: 0.5502 - accuracy: 0.7865\n",
      "Epoch 00007: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-3.ckpt\n",
      "7767/7767 [==============================] - 3s 359us/sample - loss: 0.5507 - accuracy: 0.7864 - val_loss: 0.6828 - val_accuracy: 0.7631\n",
      "Epoch 8/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.5521 - accuracy: 0.7855\n",
      "Epoch 00008: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-3.ckpt\n",
      "7767/7767 [==============================] - 3s 348us/sample - loss: 0.5519 - accuracy: 0.7856 - val_loss: 0.6468 - val_accuracy: 0.7688\n",
      "Epoch 9/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 0.5478 - accuracy: 0.7869\n",
      "Epoch 00009: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-3.ckpt\n",
      "7767/7767 [==============================] - 3s 356us/sample - loss: 0.5484 - accuracy: 0.7867 - val_loss: 0.6515 - val_accuracy: 0.7603\n",
      "Epoch 10/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 0.5419 - accuracy: 0.7878\n",
      "Epoch 00010: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-3.ckpt\n",
      "7767/7767 [==============================] - 3s 353us/sample - loss: 0.5432 - accuracy: 0.7872 - val_loss: 0.7088 - val_accuracy: 0.7641\n",
      "3162/3162 - 0s - loss: 0.7088 - accuracy: 0.7641\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002237EA30AF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002237EA30AF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0_epochs-10_it-3\\assets\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_4 (Conv1D)            (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4696 - accuracy: 0.1942\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 0.6914 - accuracy: 0.7570\n",
      "Epoch 00001: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-4.ckpt\n",
      "7767/7767 [==============================] - 3s 424us/sample - loss: 0.6901 - accuracy: 0.7572 - val_loss: 0.3225 - val_accuracy: 0.8871\n",
      "Epoch 2/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.2094 - accuracy: 0.9277\n",
      "Epoch 00002: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-4.ckpt\n",
      "7767/7767 [==============================] - 3s 357us/sample - loss: 0.2097 - accuracy: 0.9279 - val_loss: 0.3173 - val_accuracy: 0.8890\n",
      "Epoch 3/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.1285 - accuracy: 0.9548\n",
      "Epoch 00003: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-4.ckpt\n",
      "7767/7767 [==============================] - 3s 361us/sample - loss: 0.1283 - accuracy: 0.9548 - val_loss: 0.2208 - val_accuracy: 0.9190\n",
      "Epoch 4/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.0936 - accuracy: 0.9645\n",
      "Epoch 00004: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-4.ckpt\n",
      "7767/7767 [==============================] - 3s 356us/sample - loss: 0.0937 - accuracy: 0.9642 - val_loss: 0.2409 - val_accuracy: 0.9133\n",
      "Epoch 5/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.0798 - accuracy: 0.9685\n",
      "Epoch 00005: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-4.ckpt\n",
      "7767/7767 [==============================] - 3s 376us/sample - loss: 0.0795 - accuracy: 0.9686 - val_loss: 0.2319 - val_accuracy: 0.9184\n",
      "Epoch 6/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.0636 - accuracy: 0.9741\n",
      "Epoch 00006: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-4.ckpt\n",
      "7767/7767 [==============================] - 3s 371us/sample - loss: 0.0637 - accuracy: 0.9741 - val_loss: 0.2397 - val_accuracy: 0.9162\n",
      "Epoch 7/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.0596 - accuracy: 0.9775\n",
      "Epoch 00007: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-4.ckpt\n",
      "7767/7767 [==============================] - 3s 379us/sample - loss: 0.0597 - accuracy: 0.9772 - val_loss: 0.2289 - val_accuracy: 0.9273\n",
      "Epoch 8/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.0456 - accuracy: 0.9824\n",
      "Epoch 00008: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-4.ckpt\n",
      "7767/7767 [==============================] - 3s 423us/sample - loss: 0.0456 - accuracy: 0.9825 - val_loss: 0.2356 - val_accuracy: 0.9292\n",
      "Epoch 9/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 0.0371 - accuracy: 0.9854\n",
      "Epoch 00009: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-4.ckpt\n",
      "7767/7767 [==============================] - 3s 441us/sample - loss: 0.0373 - accuracy: 0.9852 - val_loss: 0.2397 - val_accuracy: 0.9307\n",
      "Epoch 10/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 0.0334 - accuracy: 0.9865 ETA: 0s - los\n",
      "Epoch 00010: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-4.ckpt\n",
      "7767/7767 [==============================] - 3s 447us/sample - loss: 0.0331 - accuracy: 0.9867 - val_loss: 0.2099 - val_accuracy: 0.9355\n",
      "3162/3162 - 0s - loss: 0.2099 - accuracy: 0.9355\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002237BA21318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002237BA21318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0_epochs-10_it-4\\assets\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4938 - accuracy: 0.0054\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 1.0623 - accuracy: 0.6869\n",
      "Epoch 00001: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-5.ckpt\n",
      "7767/7767 [==============================] - 3s 425us/sample - loss: 1.0608 - accuracy: 0.6874 - val_loss: 0.7200 - val_accuracy: 0.8213\n",
      "Epoch 2/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 0.6085 - accuracy: 0.8914\n",
      "Epoch 00002: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-5.ckpt\n",
      "7767/7767 [==============================] - 3s 378us/sample - loss: 0.6081 - accuracy: 0.8917 - val_loss: 0.6537 - val_accuracy: 0.8937\n",
      "Epoch 3/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.5573 - accuracy: 0.9229\n",
      "Epoch 00003: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-5.ckpt\n",
      "7767/7767 [==============================] - 3s 369us/sample - loss: 0.5573 - accuracy: 0.9228 - val_loss: 0.7181 - val_accuracy: 0.8899\n",
      "Epoch 4/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.5402 - accuracy: 0.9320\n",
      "Epoch 00004: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-5.ckpt\n",
      "7767/7767 [==============================] - 3s 362us/sample - loss: 0.5412 - accuracy: 0.9319 - val_loss: 0.6174 - val_accuracy: 0.9105\n",
      "Epoch 5/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 0.5231 - accuracy: 0.9408\n",
      "Epoch 00005: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-5.ckpt\n",
      "7767/7767 [==============================] - 3s 368us/sample - loss: 0.5251 - accuracy: 0.9401 - val_loss: 0.6307 - val_accuracy: 0.9035\n",
      "Epoch 6/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 0.5142 - accuracy: 0.9480\n",
      "Epoch 00006: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-5.ckpt\n",
      "7767/7767 [==============================] - 3s 352us/sample - loss: 0.5141 - accuracy: 0.9481 - val_loss: 0.6459 - val_accuracy: 0.9108\n",
      "Epoch 7/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.5003 - accuracy: 0.9548\n",
      "Epoch 00007: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-5.ckpt\n",
      "7767/7767 [==============================] - 3s 369us/sample - loss: 0.5010 - accuracy: 0.9546 - val_loss: 0.6516 - val_accuracy: 0.8922\n",
      "Epoch 8/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.5047 - accuracy: 0.9525\n",
      "Epoch 00008: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-5.ckpt\n",
      "7767/7767 [==============================] - 3s 372us/sample - loss: 0.5056 - accuracy: 0.9520 - val_loss: 0.6219 - val_accuracy: 0.9039\n",
      "Epoch 9/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.4955 - accuracy: 0.9565\n",
      "Epoch 00009: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-5.ckpt\n",
      "7767/7767 [==============================] - 3s 340us/sample - loss: 0.4984 - accuracy: 0.9562 - val_loss: 0.6195 - val_accuracy: 0.9118\n",
      "Epoch 10/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.4916 - accuracy: 0.9563\n",
      "Epoch 00010: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-5.ckpt\n",
      "7767/7767 [==============================] - 3s 347us/sample - loss: 0.4929 - accuracy: 0.9565 - val_loss: 0.6161 - val_accuracy: 0.9263\n",
      "3162/3162 - 0s - loss: 0.6161 - accuracy: 0.9263\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002235ECF2318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002235ECF2318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0_epochs-10_it-5\\assets\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_8 (Conv1D)            (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.5063 - accuracy: 0.0133\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 1.0191 - accuracy: 0.6400\n",
      "Epoch 00001: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-6.ckpt\n",
      "7767/7767 [==============================] - 3s 400us/sample - loss: 1.0116 - accuracy: 0.6426 - val_loss: 0.7611 - val_accuracy: 0.7337\n",
      "Epoch 2/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 0.5919 - accuracy: 0.7761\n",
      "Epoch 00002: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-6.ckpt\n",
      "7767/7767 [==============================] - 3s 339us/sample - loss: 0.5940 - accuracy: 0.7753 - val_loss: 0.6159 - val_accuracy: 0.7830\n",
      "Epoch 3/10\n",
      "7584/7767 [============================>.] - ETA: 0s - loss: 0.5393 - accuracy: 0.8001\n",
      "Epoch 00003: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-6.ckpt\n",
      "7767/7767 [==============================] - 3s 355us/sample - loss: 0.5387 - accuracy: 0.8002 - val_loss: 0.6228 - val_accuracy: 0.7853\n",
      "Epoch 4/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.4877 - accuracy: 0.8161\n",
      "Epoch 00004: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-6.ckpt\n",
      "7767/7767 [==============================] - 3s 347us/sample - loss: 0.4880 - accuracy: 0.8160 - val_loss: 0.6150 - val_accuracy: 0.7802\n",
      "Epoch 5/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.4720 - accuracy: 0.8196\n",
      "Epoch 00005: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-6.ckpt\n",
      "7767/7767 [==============================] - 3s 354us/sample - loss: 0.4721 - accuracy: 0.8196 - val_loss: 0.5805 - val_accuracy: 0.7944\n",
      "Epoch 6/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.4580 - accuracy: 0.8219\n",
      "Epoch 00006: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-6.ckpt\n",
      "7767/7767 [==============================] - 3s 359us/sample - loss: 0.4605 - accuracy: 0.8212 - val_loss: 0.5872 - val_accuracy: 0.7913\n",
      "Epoch 7/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.4558 - accuracy: 0.8236\n",
      "Epoch 00007: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-6.ckpt\n",
      "7767/7767 [==============================] - 3s 341us/sample - loss: 0.4561 - accuracy: 0.8234 - val_loss: 0.5953 - val_accuracy: 0.7944\n",
      "Epoch 8/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 0.4490 - accuracy: 0.8254\n",
      "Epoch 00008: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-6.ckpt\n",
      "7767/7767 [==============================] - 3s 351us/sample - loss: 0.4483 - accuracy: 0.8257 - val_loss: 0.6224 - val_accuracy: 0.7938\n",
      "Epoch 9/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.4446 - accuracy: 0.8260\n",
      "Epoch 00009: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-6.ckpt\n",
      "7767/7767 [==============================] - 3s 356us/sample - loss: 0.4452 - accuracy: 0.8258 - val_loss: 0.5912 - val_accuracy: 0.7919\n",
      "Epoch 10/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.4320 - accuracy: 0.8297\n",
      "Epoch 00010: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-6.ckpt\n",
      "7767/7767 [==============================] - 3s 355us/sample - loss: 0.4345 - accuracy: 0.8288 - val_loss: 0.6994 - val_accuracy: 0.7793\n",
      "3162/3162 - 0s - loss: 0.6994 - accuracy: 0.7793\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002237B6AA5E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000002237B6AA5E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Assets written to: saved_models\\filters-64_kernel_size-3_dropout-0_epochs-10_it-6\\assets\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 559, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 279, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 277, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 138, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8832)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 64)                565312    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 580,396\n",
      "Trainable params: 580,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3162/3162 - 1s - loss: 2.4864 - accuracy: 0.0655\n",
      "Train on 7767 samples, validate on 3162 samples\n",
      "Epoch 1/10\n",
      "7616/7767 [============================>.] - ETA: 0s - loss: 1.0580 - accuracy: 0.6245\n",
      "Epoch 00001: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-7.ckpt\n",
      "7767/7767 [==============================] - 3s 410us/sample - loss: 1.0532 - accuracy: 0.6255 - val_loss: 0.7498 - val_accuracy: 0.7163\n",
      "Epoch 2/10\n",
      "7712/7767 [============================>.] - ETA: 0s - loss: 0.6579 - accuracy: 0.7435\n",
      "Epoch 00002: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-7.ckpt\n",
      "7767/7767 [==============================] - 3s 342us/sample - loss: 0.6564 - accuracy: 0.7440 - val_loss: 0.6804 - val_accuracy: 0.7315\n",
      "Epoch 3/10\n",
      "7680/7767 [============================>.] - ETA: 0s - loss: 0.6014 - accuracy: 0.7638\n",
      "Epoch 00003: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-7.ckpt\n",
      "7767/7767 [==============================] - 3s 359us/sample - loss: 0.6004 - accuracy: 0.7641 - val_loss: 0.7088 - val_accuracy: 0.7293\n",
      "Epoch 4/10\n",
      "7744/7767 [============================>.] - ETA: 0s - loss: 0.5833 - accuracy: 0.7655\n",
      "Epoch 00004: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-7.ckpt\n",
      "7767/7767 [==============================] - 3s 340us/sample - loss: 0.5839 - accuracy: 0.7653 - val_loss: 0.6778 - val_accuracy: 0.7413\n",
      "Epoch 5/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.5728 - accuracy: 0.7741\n",
      "Epoch 00005: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-7.ckpt\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.5709 - accuracy: 0.7748 - val_loss: 0.6538 - val_accuracy: 0.7479\n",
      "Epoch 6/10\n",
      "7648/7767 [============================>.] - ETA: 0s - loss: 0.5627 - accuracy: 0.7765\n",
      "Epoch 00006: saving model to checkpoints\\filters-64_kernel_size-3_dropout-0_epochs-10_it-7.ckpt\n",
      "7767/7767 [==============================] - 3s 338us/sample - loss: 0.5609 - accuracy: 0.7773 - val_loss: 0.6454 - val_accuracy: 0.7508\n",
      "Epoch 7/10\n",
      "6048/7767 [======================>.......] - ETA: 0s - loss: 0.5480 - accuracy: 0.7814"
     ]
    }
   ],
   "source": [
    "dropout_data = runner.test_param(dropout = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runner.print_results(dropout_data, 'dropout')\n",
    "runner.plot_results(dropout_data, 'dropout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kernel_size_data = runner.test_param(kernel_size = [2,3,5,7,9,11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runner.print_results(kernel_size_data, 'kernel_size')\n",
    "runner.plot_results(kernel_size_data, 'kernel_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_data = runner.test_param()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.plot_results(default_data, 'default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
